[{"title":"ã€è®ºæ–‡ç¬”è®°ã€‘Modeling and Simulation of Radar Sea Clutter Using K-distribution","path":"/2024/04/17/SeaClutter/ã€è®ºæ–‡ç¬”è®°ã€‘Modeling and Simulation of Radar Sea Clutter Using K-distribution/","content":"Abstract æœ¬æ–‡è®¨è®ºäº†kåˆ†å¸ƒæµ·æ‚æ³¢çš„å»ºæ¨¡ä¸ä»¿çœŸï¼Œä»¥å¸®åŠ©ä»ç»Ÿè®¡çš„è§’åº¦ç†è§£æ‚æ³¢ç‰¹å¾ï¼Œè¿™ç§æ¨¡æ‹Ÿå°†å¯¼è‡´ä¼˜åŒ–å›ºå®šé˜ˆå€¼ä»¥æé«˜æ£€æµ‹æ€§èƒ½çš„æ–¹æ³•ã€‚ Introduction ä¼ ç»Ÿçš„åŸºäºé«˜æ–¯åˆ†å¸ƒçš„æ–¹æ³•ï¼Œå› ä¸ºç®€åŒ–å‡è®¾ï¼Œåœ¨å¾ˆå¤šå®é™…æƒ…å¢ƒä¸‹éƒ½å¤±æ•ˆäº†ï¼Œç‰¹åˆ«æ˜¯è¿™ç§æµ·æ´‹ç¯å¢ƒã€‚å› ä¸ºæ‚æ³¢æ¦‚ç‡å¯†åº¦å‡½æ•°(PDF)çš„æŒ¯å¹…è¡¨ç°å‡ºè¾ƒé•¿çš„å°¾å·´ã€‚ åœ¨è¿™æ ·çš„ç¯å¢ƒä¸‹ï¼Œæå‡ºäº†ä¸€ç§è€ƒè™‘åˆ†å¸ƒé•¿å°¾çš„åŒå‚æ•°æ¨¡å‹ï¼Œé€šå¸¸ç§°ä¸ºKåˆ†å¸ƒæ¨¡å‹[2ï¼Œ3]ã€‚é™¤äº†æŒ¯å¹…ç»Ÿè®¡å¤–ï¼ŒKåˆ†å¸ƒæµ·æ‚æ³¢æ¨¡å‹è¿˜å¯ä»¥è€ƒè™‘æ—¶é—´å’Œç©ºé—´ç›¸å…³ç‰¹å¾ã€‚ä¹Ÿæ­£æ˜¯å› ä¸ºè¿™äº›ä¼˜ç‚¹ï¼Œç›®å‰å¯¹ä¼ ç»Ÿæ¨¡å‹çš„ç ”ç©¶ä¹Ÿä½¿ç”¨äº† K åˆ†å¸ƒæ¨¡å‹ã€‚ æœ¬ç ”ç©¶çš„ç›®çš„æ˜¯æ¢ç©¶é«˜æ–¯è¿‡ç¨‹æ¨¡å‹åœ¨è¿™äº›åº”ç”¨ä¸­çš„å±€é™æ€§ä»¥åŠ K åˆ†å¸ƒæ¨¡å‹å¯¹æµ·æ‚æ³¢å¹…åº¦çš„å¯ç”¨æ€§ã€‚ Theoretical Background é›·è¾¾æ‚æ³¢çš„ç»Ÿè®¡å»ºæ¨¡å¯¹äºåœ¨ä»»ä½•æƒ…å†µä¸‹è·å¾—é›·è¾¾çš„ä¼˜åŒ–æ“ä½œéå¸¸é‡è¦ã€‚ å¯¹äºç©ºé—´åˆ†è¾¨ç‡è¾ƒä½çš„é›·è¾¾ï¼Œåˆ†è¾¨ç‡å•å…ƒå°ºå¯¸ä¸€èˆ¬è¿œå¤§äºæµ·è†¨èƒ€æ³¢é•¿ï¼Œå¯¹äºå¤§äº10åº¦çš„æ è§’ï¼Œä¼—æ‰€å‘¨çŸ¥æ‚æ³¢æŒ¯å¹…æ˜¯ç‘åˆ©åˆ†å¸ƒçš„ã€‚æ­¤å¤–ï¼Œæ‚æ³¢å›æ³¢å…·æœ‰ç›¸å½“çŸ­çš„æ—¶é—´å»ç›¸å…³å‘¨æœŸï¼Œé€šå¸¸ä¸º10msçš„æ•°é‡çº§ï¼Œå¹¶ä¸”ä»ä¸€ä¸ªè„‰å†²åˆ°å¦ä¸€ä¸ªè„‰å†²æ˜¯å®Œå…¨å»ç›¸å…³çš„ã€‚éšç€é›·è¾¾åˆ†è¾¨ç‡çš„æé«˜å’Œæ è§’çš„å‡å°ï¼Œæ‚æ³¢æŒ¯å¹…åˆ†å¸ƒä¼šå½¢æˆé•¿å°¾ï¼Œå›æ³¢é€šå¸¸è¢«æè¿°ä¸ºå˜å¾—â€œå°–å³°â€ã€‚æ‚æ³¢çš„æ—¶é—´å’Œç©ºé—´ç›¸å…³ç‰¹æ€§ä¹Ÿä¼šå‘ç”Ÿå˜åŒ–ã€‚ ç”±äºæµ·æ´‹åº”ç”¨ä¸­ä½¿ç”¨çš„é›·è¾¾è¿”å›çš„æ˜¯åæ–œçš„é•¿å°¾åˆ†å¸ƒï¼Œå› æ­¤é‡‡ç”¨è§„åˆ™ç‘åˆ©æ–¹æ³•è¿›è¡Œå»ºæ¨¡å¤±è´¥ã€‚å¯¹æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç±»ä¼¼Kåˆ†å¸ƒçš„é•¿å°¾åˆ†å¸ƒæ¥å¯¹ä¸Šè¿°æ‚æ³¢è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†åœ¨æœ¬èŠ‚ä¸­è¯¦ç»†è®¨è®ºã€‚ å¦‚å‰æ‰€è¿°ï¼Œä»å¹¿æ³›æ¡ä»¶ä¸‹çš„å®é™…æµ‹é‡ä¸­å‘ç°ï¼Œé«˜åˆ†è¾¨ç‡é›·è¾¾çš„æ‚æ³¢å›æ³¢å¯ä»¥ç”±ä¸¤ä¸ªåˆ†é‡å¾ˆå¥½åœ°å»ºæ¨¡[4]ã€‚ç¬¬ä¸€ä¸ªåˆ†é‡å…·æœ‰è¾ƒé•¿çš„å»ç›¸å…³æ—¶é—´ï¼Œçº¦ä¸ºç§’ï¼Œå¹¶ä¸”ä¸å—é¢‘ç‡æ·å˜çš„å½±å“ï¼Œè¿™ä¸ªç¼“æ…¢å˜åŒ–çš„åˆ†é‡å¯ä»¥ç”¨ä¼½ç›åˆ†å¸ƒè¡¨ç¤ºï¼Œå¹¶æ˜¾ç¤ºæ‚æ³¢çš„åŸºæœ¬å¹³å‡æ°´å¹³ï¼ˆÏƒ0\\sigma^0Ïƒ0â€‹ï¼‰ã€‚ç¬¬äºŒä¸ªåˆ†é‡è¢«ç§°ä¸ºâ€œæ•£æ–‘â€(speckle)åˆ†é‡ï¼Œå…¶ç»Ÿè®¡æ•°æ®å¯ä»¥ç”¨ç‘åˆ©åˆ†å¸ƒè¡¨ç¤ºã€‚è¯¥æ•£æ–‘åˆ†é‡å…·æœ‰ç”±æ‚æ³¢æ¨¡å‹çš„ç¬¬ä¸€åˆ†é‡ç¡®å®šçš„å¹³å‡æ°´å¹³ã€‚å› æ­¤ï¼Œè¯¥æ¨¡å‹å‡è®¾ç‘åˆ©åˆ†å¸ƒçš„å¿«é€Ÿæ³¢åŠ¨åˆ†é‡ç”±ç¼“æ…¢æ³¢åŠ¨çš„ä¼½é©¬åˆ†å¸ƒåˆ†é‡è°ƒåˆ¶ï¼Œè¿™ç»„æˆäº†å¤åˆKåˆ†å¸ƒã€‚ é€šè¿‡å¯¹å¹³å‡æ°´å¹³çš„æ‰€æœ‰å¯èƒ½å€¼ä¸Šçš„æ•£æ–‘åˆ†é‡æ±‚å¹³å‡å€¼ï¼Œå¾—å‡ºKåˆ†å¸ƒ[4]ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š(The K-distribution is derived [4], as follows, by averaging the speckle component over all possible values of the mean level:) p(x)=âˆ«0âˆp(y)p(xâˆ£y)â€‰dyp(x) = \\int_{0}^{\\infty} p(y) p(x \\mid y) \\, dy p(x)=âˆ«0âˆâ€‹p(y)p(xâˆ£y)dy p(x)p(x)p(x)æ˜¯æ‚æ³¢è¿”å›çš„æ€»ä½“PDF p(y)p(y)p(y)æ˜¯æ‚æ³¢å¹³å‡æ°´å¹³çš„PDF p(x/y)p(x/y)p(x/y) æ˜¯æ•£æ–‘(speckle)åˆ†é‡çš„PDF ç°åœ¨ï¼Œæˆ‘ä»¬å‘ç°p(y)p(y)p(y)å¾ˆé€‚åˆä¼½ç›åˆ†å¸ƒæ—ï¼Œå› æ­¤: p(y)=2bÎ“(Î½)(by)2yâˆ’1expâ¡(âˆ’b2y2)p(y) = \\frac{2b}{\\Gamma( u)} (by)^{2y-1} \\exp(-b^2 y^2) p(y)=Î“(Î½)2bâ€‹(by)2yâˆ’1exp(âˆ’b2y2) å…¶ä¸­,bæ˜¯scale parameterï¼ŒÎ½ uÎ½ æ˜¯shape parameterï¼ŒÎ“(â‹…)\\Gamma(\\cdot)Î“(â‹…) æ˜¯ä¼½é©¬å‡½æ•°ã€‚Î½ uÎ½ å–å€¼å–å†³äºrangeï¼Œgrazing angleï¼Œaspect angleï¼Œsea conditionsä»¥åŠradar parametersï¼Œæ ¹æ®ç»éªŒÎ½ uÎ½åŸºæœ¬åœ¨è¿™ä¸ªèŒƒå›´å†…ï¼š 0&lt;1Î½&lt;100 &lt; \\frac{1}{ u} &lt; 10 0&lt;Î½1â€‹&lt;10 æ•£æ–‘åˆ†é‡p(xâˆ£y)p(x|y)p(xâˆ£y)ç”±ç‘åˆ©åˆ†å¸ƒå»ºæ¨¡ï¼Œå› æ­¤ï¼š p(xâˆ£y)=Ï€x2y2expâ¡(âˆ’Ï€x24y2)p(x \\mid y) = \\frac{\\pi x}{2y^2} \\exp\\left(-\\frac{\\pi x^2}{4y^2}\\right) p(xâˆ£y)=2y2Ï€xâ€‹exp(âˆ’4y2Ï€x2â€‹) æ ¹æ®ä¸Šé¢çš„ç§¯åˆ†å¼å­å¯ä»¥è®¡ç®—å‡ºï¼š p(x)=2cÎ“(Î½)(cx2)Î½KÎ½âˆ’1(cx)(xâ‰¥0)p(x) = \\frac{2c}{\\Gamma( u)} \\left( \\frac{cx}{2} \\right)^ u K_{ u-1}(cx) \\qquad (x \\geq 0) p(x)=Î“(Î½)2câ€‹(2cxâ€‹)Î½KÎ½âˆ’1â€‹(cx)(xâ‰¥0) å…¶ä¸­ï¼Œc=2bÏ€/4c=2b\\sqrt{\\pi/4}c=2bÏ€/4â€‹æ˜¯scale parameter(c&gt;0),Î½ uÎ½å’Œä¹‹å‰ä¸€æ ·æ˜¯shape parameterã€‚KÎ½(â‹…)K_ u(\\cdot)KÎ½â€‹(â‹…)æ˜¯vé˜¶ä¿®æ­£ç¬¬äºŒç±»è´å¡å°”å‡½æ•°ã€‚ yyyçš„ç¬¬nnnä¸ªçŸ©ç”±ä¸‹å¼ç»™å‡ºï¼š ynâ€¾=1bnÎ“(Î½+n2)Î“(Î½)\\overline{y^n} = \\frac{1}{b^n} \\frac{\\Gamma\\left( u + \\frac{n}{2}\\right)}{\\Gamma( u)} ynâ€‹=bn1â€‹Î“(Î½)Î“(Î½+2nâ€‹)â€‹ è€ŒKåˆ†å¸ƒçš„ç¬¬nä¸ªçŸ©ç”±ä¸‹å¼ç»™å‡º: xnâ€¾=1cnÎ“(Î½+n2)Î“(Î½)Î“(n2+1)\\overline{x^n} = \\frac{1}{c^n} \\frac{\\Gamma\\left( u + \\frac{n}{2}\\right)}{\\Gamma( u)} \\Gamma\\left(\\frac{n}{2} + 1\\right) xn=cn1â€‹Î“(Î½)Î“(Î½+2nâ€‹)â€‹Î“(2nâ€‹+1) Kåˆ†å¸ƒçš„ç´¯ç§¯æ¦‚ç‡ç”±ä¸‹å¼ç»™å‡º: P(x&gt;t)=âˆ«tâˆ4cÎ“(Î½)(cx)Î½KÎ½âˆ’1(2cx)â€‰dxP(x &gt; t) = \\int_{t}^{\\infty} \\frac{4c}{\\Gamma( u)} (cx)^ u K_{ u-1}(2cx) \\, dx P(x&gt;t)=âˆ«tâˆâ€‹Î“(Î½)4câ€‹(cx)Î½KÎ½âˆ’1â€‹(2cx)dx P(x&gt;t)==2cÎ½Î“(Î½)tÎ½KÎ½(2ct)P(x &gt; t) = = \\frac{2c^ u}{\\Gamma( u)} t^ u K_ u(2ct) P(x&gt;t)==Î“(Î½)2cÎ½â€‹tÎ½KÎ½â€‹(2ct) å¤§é‡çš„æ‚æ³¢å·²è¢«è¯æ˜èƒ½å¤Ÿåˆ†é…åˆ° K åˆ†å¸ƒä¸Šï¼Œå…¶ä¸­å½“Î½=âˆ u=\\inftyÎ½=âˆ,æ‚æ³¢åˆ†å¸ƒæ¥è¿‘Rayleigh-distributedï¼Œå½“Î½=0.1 u=0.1Î½=0.1â€‹æ—¶æ‚æ³¢åˆ†å¸ƒæ¥è¿‘long-tailed spiky distribution Simulation Results æ¨¡æ‹Ÿæµ·æ‚æ³¢çš„æœ‰æ•ˆæ–¹æ³•æ˜¯åœ¨é›·è¾¾è·ç¦»æ–¹ç¨‹ä¸­æ‰¾åˆ°å•ä½é¢ç§¯æ‚æ³¢æˆªé¢çš„å€¼Ïƒ0\\sigma^0Ïƒ0ã€‚Ïƒ0\\sigma^0Ïƒ0çš„å˜åŒ–åº”æ ¹æ®p(x)p(x)p(x)â€‹. æ›´é‡è¦çš„æ˜¯ï¼Œè¡¨å¾æ‚æ³¢çš„å‚æ•°èŒƒå›´æ˜¯å·²çŸ¥çš„ã€‚æˆ‘ä»¬å°†åœ¨ä»¥ä¸‹éƒ¨åˆ†ä¸­æè¿°æ£€ç´¢æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚ An empirical model for Î½ uÎ½ ä¸ºäº†å®ç°ä¸Šä¸€èŠ‚ä¸­ä»‹ç»çš„æ•°å­¦æ¨¡å‹çš„åº”ç”¨ï¼Œæœ‰å¿…è¦äº†è§£ä¸Šè¿°æ¨¡å‹ä¸­å„ç§å‚æ•°å¦‚ä½•éšæµ·æ´‹æ¡ä»¶å’Œé›·è¾¾å‚æ•°è€Œå˜åŒ–ã€‚è¿™äº›çŸ¥è¯†å°†æœ‰åŠ©äºæ¨¡æ‹Ÿæ‚æ³¢æ•°æ®ã€‚å‡è®¾å·²çŸ¥å¹³å‡å›æ³¢åŒºåŸŸï¼Œå¾…ç¡®å®šçš„ä¸‹ä¸€ä¸ªå‚æ•°æ˜¯å½¢çŠ¶æˆ– v å‚æ•°ã€‚å®ƒæä¾›æœ‰å…³å¹…åº¦ç»Ÿè®¡çš„ä¿¡æ¯ä»¥åŠä¸€äº›ç›¸å…³å±æ€§ã€‚ æ ¹æ®å®éªŒç»“æœ[6]ï¼Œè§‚å¯Ÿåˆ°ä»¥ä¸‹ç»“è®º: æ‰€æœ‰ä¸€èµ·æ‹æ‘„çš„ç»“æœè¡¨æ˜ï¼Œè¾ƒå°çš„grazing angle Î¦\\PhiÎ¦ æ„å‘³ç€è¾ƒå°çš„ Î½ uÎ½â€‹ã€‚ æµ·æ€æ²¡æœ‰å¼ºçƒˆçš„è¶‹åŠ¿ï¼Œå¦‚å¹³å‡åŠŸç‡è¿”å›æ‰€ç¤ºã€‚ çºµæ¨ªè§’çš„å˜åŒ–å–å†³äºæµªæ¶Œå’Œé•¿æ³¢æµ·æµªçš„æµ·è°±å«é‡ã€‚ç›¸å½“å¤§çš„è†¨èƒ€é‡ï¼ˆSwell Contentï¼‰æ„å‘³ç€ä»°è§’ä¾èµ–äº: ä¸Šä¸‹Swellï¼Œæ›´å°çš„Î½ uÎ½ Across Swell, æ›´å¤§çš„Î½ uÎ½ åœ¨ä¸¤ä¸ªæ–¹å‘ä¹‹é—´ï¼Œä¸­é—´çš„Î½ uÎ½ åœ¨ä¸åŒçš„é‡ç¨‹ï¼Œè·¨é‡ç¨‹çš„patchå¤§å°æ˜¯ä¸åŒçš„ã€‚éšç€patchå¤§å°çš„å¢åŠ ï¼Œvå€¼æœ‰æ˜æ˜¾çš„å¢åŠ è¶‹åŠ¿ã€‚ æ ¹æ®æ‰€è¿›è¡Œçš„å®éªŒï¼Œæµ‹é‡ä¸Šè¿°æ‰€æœ‰è¶‹åŠ¿å¯ä»¥å¾—åˆ°ä»¥ä¸‹å¯¹æ•°å°ºåº¦ä¸Šçš„ç»éªŒå…³ç³»ã€‚ logâ¡v=âˆ’23logâ¡Ï•+58logâ¡Î”+Î¾âˆ’k\\log v = -\\frac{2}{3} \\log \\phi + \\frac{5}{8} \\log \\Delta + \\xi - k logv=âˆ’32â€‹logÏ•+85â€‹logÎ”+Î¾âˆ’k å…¶ä¸­ï¼ŒÏ•\\phiÏ•æ˜¯grazing angleï¼ˆåº¦ï¼‰ï¼ŒÎ”\\DeltaÎ”æ˜¯across-ranges resolutionï¼ˆç±³ï¼‰ã€‚Î¾=âˆ’1/3\\xi=-1/3Î¾=âˆ’1/3 å¯¹äºup or down swell directions, Î¾=1/3\\xi=1/3Î¾=1/3 å¯¹äºacross swell directions,0 å¯¹äº intermediate directions or no swell existsã€‚k=1k=1k=1å¯¹äºvertical polarizationï¼Œk=1.7k=1.7k=1.7â€‹å¯¹äºhorizontal polarization å°†ç»éªŒå…¬å¼ä¸ç»“æœçš„æ•£ç‚¹è¿›è¡Œæ¯”è¾ƒï¼Œå¾—å‡ºçš„å‡æ–¹æ ¹è¯¯å·®ä¸ºlog vçš„0.24ã€‚æ³¨æ„ä¸Šå¼æ˜¯å•é›·è¾¾æµ‹é‡å¾—åˆ°çš„ï¼ŒÎ½ uÎ½ä¼¼ä¹åº”è¯¥éšæµ·å†µæœ‰ä¸€å®šçš„å˜åŒ–ï¼Œå› ä¸ºå®éªŒè¡¨æ˜æµ·æ‚æ³¢çš„æ¦‚ç‡å¯†åº¦å‡½æ•°éšæµ·å†µè€Œå˜åŒ–[7]ã€‚ä¸è¿‡,ä¸Šå¼å¯ç”¨äºäº†è§£é›·è¾¾å„å‚æ•°ä¸æµ·å†µä¹‹é—´ç›¸äº’å…³ç³»çš„å…¬å…çŸ¥è¯†ã€‚åœ¨ä»»ä½•å…¶ä»–æƒ…å†µä¸‹ï¼Œæƒ…å†µå°†ä¸ä¸Šå¼ç•¥æœ‰ä¸åŒã€‚è™½ç„¶ä»¥ä¸Šå¤§éƒ¨åˆ†ä¿¡æ¯æ˜¯åŸºäºXæ³¢æ®µçš„æ•°æ®ï¼Œä½†åœ¨Sæ³¢æ®µå’ŒKæ³¢æ®µä¹Ÿè§‚å¯Ÿåˆ°å‚æ•°Î½ uÎ½çš„ç±»ä¼¼è¡Œä¸º[8]ã€‚ Experimental Results æœ¬æ®µä¸»è¦è®¨è®ºäº†é›·è¾¾ç³»ç»Ÿæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯ä½¿ç”¨Kåˆ†å¸ƒæ¨¡å‹åœ¨æµ·æ´‹åœºæ™¯ä¸­å¯¹æµ·æ‚æ³¢çš„æ¨¡æ‹Ÿã€‚æ–‡ç« æŒ‡å‡ºä½¿ç”¨é«˜åˆ†è¾¨ç‡é›·è¾¾é€šå¸¸èƒ½å¾—åˆ°æ›´å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ä¿æŒKåˆ†å¸ƒæ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ã€‚æµ·æ‚æ³¢çš„æŒ¯å¹…å¯ä»¥æ ¹æ®æ–¹ç¨‹5æ¨¡æ‹Ÿä¸åŒçš„æµ·æ´‹ç¯å¢ƒã€‚å‚æ•°vçš„å€’æ•°ï¼ˆ1/vï¼‰çš„å€¼åŸŸæ˜¯ä»0åˆ°10ï¼Œè€Œå‚æ•°cä»…æè¿°å¹³å‡åŠŸç‡å›æ³¢å¹¶å‡è®¾ä¸º1ã€‚æ–‡ç« ä¸­çš„å›¾2å±•ç¤ºäº†æ¨¡æ‹Ÿçš„æŒ¯å¹…æ‚æ³¢æ•°æ®çš„ç›´æ–¹å›¾å’Œå¯¹äºè¾ƒå°vå€¼çš„ç†è®ºæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰ï¼Œå‡è®¾v=0.5æ¥è¿‘ä¼¼æ›´å°çš„å…¥å°„è§’åº¦ã€‚å¦‚æœæ¶Œæµªæ—¢ä¸æ˜¯é¡ºæµä¹Ÿä¸æ˜¯æ¨ªæµï¼ˆå³ä»‹äºä¸¤è€…ä¹‹é—´çš„æ–¹å‘ï¼‰ï¼Œå®ƒå¯¹åº”äºä¸­ç­‰vå€¼ã€‚å›¾3å±•ç¤ºäº†ç‰¹å®šæƒ…å†µä¸‹v=5çš„æ¨¡æ‹Ÿæƒ…å†µã€‚å›¾4å±•ç¤ºäº†è¾ƒå¤§vå€¼å¯¹åº”çš„æ¨ªæµåŠè¾ƒå¤§æ–‘å—å°ºå¯¸çš„æƒ…æ™¯ï¼Œè¿™é‡Œv=10ã€‚æ¨¡æ‹Ÿçš„æŒ¯å¹…æ ·æœ¬æ•°ï¼ˆNï¼‰æ˜¯1000ï¼Œä½†å¯ä»¥æ ¹æ®åº”ç”¨åœºæ™¯è°ƒæ•´ã€‚åœ¨é›·è¾¾æ¡ˆä¾‹ä¸­ï¼ŒNçš„å€¼æ˜¯181ï¼Œç”¨æ¥è¦†ç›–ä»-90åº¦åˆ°+90åº¦çš„æ–¹ä½è§’ï¼Œæ¯ä¸ªè·ç¦»å•å…ƒã€‚ Data Validation åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºç¡®ä¿ç”Ÿæˆæ•°æ®æ ·æœ¬çš„åº•å±‚åˆ†å¸ƒçš„æ–¹å¼ã€‚æ¦‚ç‡å»ºæ¨¡å’Œæµ‹è¯•ç¨‹åºéœ€è¦ä¸€ä¸ªç»Ÿè®¡ä¸Šæ˜¾ç€ä¸”ç»Ÿè®¡ä¸Šç‹¬ç«‹çš„æ ·æœ¬æ•°æ®åº“ã€‚ä¸ºäº†æ»¡è¶³è¿™ä¸€è¦æ±‚ï¼Œå¿…é¡»é‡‡å–è¶³å¤Ÿçš„æ•°æ®æ ·æœ¬æ¥å‡†ç¡®è¡¨ç¤ºæ•°æ®åº“ï¼Œå¹¶ä¸”åœ¨è¿ç»­çš„æ•°æ®æ ·æœ¬ä¹‹é—´å¯èƒ½ä¸å­˜åœ¨æ˜¾è‘—çš„ç›¸å…³æ€§ã€‚å¦‚æœæ•°æ®å¯ä»¥é™å®šä¸ºå¹³ç¨³ï¼Œåˆ™å¯ä»¥ä½¿ç”¨æ—¶é—´è‡ªç›¸å…³å‡½æ•°æ¥ä¼°è®¡æ—¶é—´æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ç¨‹åº¦ã€‚å¦‚æœå‘ç°å­˜åœ¨æ˜¾ç€ç›¸å…³æ€§ï¼Œåˆ™å¯ä»¥é€šè¿‡å°†æ•°æ®åº“é‡‡æ ·ä¸ºç”±æœ€å°ç›¸å…³æ—¶é—´åˆ†éš”çš„åŒºé—´æ¥äº§ç”Ÿä¸ç›¸å…³çš„æ•°æ®ã€‚ç„¶åå¯ä»¥ä»ä¸ç›¸å…³çš„æ•°æ®ä¸­ä¼°è®¡ç»Ÿè®¡æ•°æ®ã€‚ ä¸ºäº†éªŒè¯ç”Ÿæˆæ‚æ³¢æ•°æ®åº“çš„æ¦‚ç‡æ¨¡å‹ï¼Œå°†Kolmogorov-Smirov (K-S)éå‚æ•°æ‹Ÿåˆä¼˜åº¦æµ‹è¯•ç¨‹åºåº”ç”¨äºæ•°æ®[9]ã€‚K-S æµ‹è¯•ç¨‹åºå’Œè®¡ç®—æœºå®ç°çš„ç®€è¦è®¨è®ºå¦‚ä¸‹ã€‚ Kolmogorov-Smirov (K-S) Test K-Sæ£€éªŒç»Ÿè®¡åœ°æµ‹é‡è§‚å¯Ÿåˆ°çš„æ ·æœ¬å€¼çš„CDFå’ŒæŒ‡å®šçš„è¿ç»­åˆ†å¸ƒå‡½æ•°ä¹‹é—´çš„ç»å¯¹è¯¯å·®ã€‚å…·ä½“è€Œè¨€ï¼ŒK-Sæ£€éªŒåŸºäºå¤§å°ä¸ºNçš„éšæœºæ ·æœ¬çš„CDFå€¼ä¸æŒ‡å®šç†è®ºåˆ†å¸ƒä¹‹é—´çš„æœ€å¤§ç»å¯¹å·®Dã€‚ åœ¨æ•°å­¦ä¸Šï¼Œè¿™ä¸ªæ£€éªŒç”±ä¸‹å¼ç»™å‡ºã€‚å…¶ä¸­ Sn(x)S_n(x)Snâ€‹(x) æ˜¯é‡‡æ ·çš„ CDFï¼ŒP(x)P(x)P(x) æ˜¯å‡è®¾çš„ CDFã€‚ D=maxâ¡âˆ£Sn(x)âˆ’P(x)âˆ£forÂ allÂ xD = \\max \\left| S_{n}(x) - P(x) \\right| \\quad \\text{for all } x D=maxâˆ£Snâ€‹(x)âˆ’P(x)âˆ£forÂ allÂ x ä¸ºäº†ç¡®å®šå¯¹äºç»™å®šçš„æ˜¾ç€æ€§æ°´å¹³ (a) æ˜¯å¦å¯ä»¥åˆç†æœŸæœ›è¿™ç§åˆ†å¸ƒï¼Œå°†å‚è€ƒæä¾›ç»™ç»Ÿè®¡è¡¨ä¸­ D çš„ä¸´ç•Œå€¼ã€‚ åŸå‡è®¾(Null hypothesis)æˆç«‹çš„æƒ…å†µæ˜¯ï¼Œæ–¹ç¨‹10ä¸­å¾—åˆ°çš„å·®å€¼Då°äºç»™å®šæ ·æœ¬æ•°Nå’Œæ˜¾è‘—æ€§æ°´å¹³Î±çš„æƒ…å†µä¸‹ï¼Œä»ç»Ÿè®¡è¡¨ä¸­æŸ¥å¾—çš„Dçš„ä¸´ç•Œå€¼ã€‚ Experimental results ä½œä¸ºè¿™é¡¹æŠ€æœ¯åº”ç”¨çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œè€ƒè™‘å›¾5ï¼Œå®ƒä»£è¡¨äº†å¯¹1000ä¸ªç‹¬ç«‹æ¨¡æ‹Ÿé›·è¾¾æ‚æ³¢æ•°æ®æ ·æœ¬è¿›è¡Œçš„K-Sæ£€éªŒï¼Œå…¶ä¸­c=1ä¸”v=1ã€‚ä»å›¾5å¯ä»¥çœ‹å‡ºï¼Œåœ¨100æ¬¡è’™ç‰¹å¡ç½—è¿ç®—ä¸­ï¼Œæœ€å¤§çš„ç»å¯¹å·®å€¼Dæ€»æ˜¯å°äºN=1000å’ŒÎ±=0.05æ—¶ç»Ÿè®¡è¡¨ä¸­çš„Dçš„ä¸´ç•Œå€¼ï¼ˆé™¤äº†å°‘æ•°æƒ…å†µï¼‰ã€‚è¿™ç¡®ä¿äº†æ¨¡æ‹Ÿçš„æµ·æ‚æ³¢å¹…åº¦ç»Ÿè®¡æ•°æ®éµå¾ªKåˆ†å¸ƒï¼Œè¯¥åˆ†å¸ƒæ¨¡æ‹Ÿäº†å°–å³°æµ·æ´‹ç¯å¢ƒã€‚ Conclusion è¿™ç¯‡æ–‡ç« æè¿°äº†Kåˆ†å¸ƒæ¨¡å‹åœ¨æµ·æ‚æ³¢ä¸­çš„åº”ç”¨ï¼Œå¹¶å±•ç¤ºäº†æ¨¡æ‹Ÿæ‚æ³¢çš„æ–¹æ³•ï¼Œå¹¶ç¡®ä¿äº†åˆç†åŒ–åº•å±‚å¯†åº¦å‡½æ•°çš„æ–¹å¼ã€‚Kåˆ†å¸ƒå‡½æ•°èƒ½è§£é‡Šè§‚å¯Ÿåˆ°çš„å®éªŒè¡Œä¸ºï¼Œå¹¶ä¸”å¯ä»¥æ–¹ä¾¿åœ°ç”¨äºæµ·æ´‹åº”ç”¨ã€‚è¿™ç§å»ºæ¨¡è¿˜å¯ä»¥å¸®åŠ©è®¾å®šé˜ˆå€¼æé™ï¼Œä»¥æ›´å¥½åœ°æé«˜ç›®æ ‡çš„æ£€æµ‹å’Œé¢„æµ‹æ¦‚ç‡ã€‚å»ºæ¨¡å¤æ‚æ‚æ³¢çš„æŒ¯å¹…åˆ†å¸ƒéœ€è¦ä¼°è®¡å¹³ç¨³å‡å€¼ã€ç›¸å…³å‡½æ•°å’Œæ¦‚ç‡åˆ†å¸ƒå‡½æ•°ã€‚K-Séå‚æ•°æ£€éªŒæä¾›äº†ä¸€ç§è¯„ä¼°æ•°æ®éµå¾ªç‰¹å®šç†è®ºåˆ†å¸ƒçš„åŸå‡è®¾çš„æ–¹æ³•ï¼Œè¯¥ç†è®ºåˆ†å¸ƒæ˜¯æ ¹æ®æ ·æœ¬æ•°æ®ä¼°è®¡çš„å‚æ•°æ„å»ºçš„ã€‚æ•°æ®çš„PDFå’Œç›´æ–¹å›¾ä¸å‡å®šæ¨¡å‹çš„å¯¹æ¯”å›¾å¯ä»¥æä¾›ä¸€ä¸ªâ€œå¥½â€æˆ–â€œæœ€ä½³â€æ‹Ÿåˆçš„è§†è§‰è¯æ®ã€‚ æ‰€é‡‡ç”¨çš„ç®—æ³•ç®€å•ã€å¿«é€Ÿï¼Œåœ¨ MATLAB ä¸­è¿›è¡Œäº†ä»¿çœŸã€‚ä¸Šè¿°å·¥ä½œå¯èƒ½åœ¨æœªæ¥å¯å‘ä¸€ä¸ªç®€å•çš„æ–¹æ³•è·Ÿè¸ªå’Œåˆ†ææ›´å¤æ‚çš„ç°ä»£é›·è¾¾çš„ç»Ÿè®¡æ–¹æ³•ã€‚","tags":["SeaClutter","K distribution"],"categories":["SeaClutter"]},{"title":"Hello World","path":"/2024/04/08/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment a=aba = \\frac{a}{b} a=baâ€‹ w(n)=0.54âˆ’0.46cosâ¡(2Ï€nN),0â‰¤nâ‰¤Nw(n)=0.54-0.46\\cos(2\\pi\\frac{n}{N}),\\quad 0\\le n\\le N w(n)=0.54âˆ’0.46cos(2Ï€Nnâ€‹),0â‰¤nâ‰¤N è¯•è¯•è¡Œå†…a=abca=\\frac{a}{\\frac{b}{c}}a=cbâ€‹aâ€‹ è¿™æ ·è¡Œå—a=asa=\\frac{a}{s}a=saâ€‹"},{"title":"åŠ¨æ€è§„åˆ’","path":"/wiki/Luogu/åŠ¨æ€è§„åˆ’.html","content":"ã€åŠ¨æ€è§„åˆ’1ã€‘åŠ¨æ€è§„åˆ’çš„å¼•å…¥ P1216 [USACO1.5] [IOI1994]æ•°å­—ä¸‰è§’å½¢ Number Triangles é¢˜ç›®ä¼ é€é—¨ï¼šP1216 [USACO1.5] [IOI1994]æ•°å­—ä¸‰è§’å½¢ Number Triangles - æ´›è°· | è®¡ç®—æœºç§‘å­¦æ•™è‚²æ–°ç”Ÿæ€ (luogu.com.cn) éå¸¸åŸºç¡€çš„ä¸€é“é¢˜ç›®ï¼Œç›´æ¥é€’æ¨åˆ·è¡¨å³å¯ã€‚ 123456789101112131415161718192021222324252627282930/* * Problem: P1216 [USACO1.5] [IOI1994]æ•°å­—ä¸‰è§’å½¢ Number Triangles * URL: https://www.luogu.com.cn/problem/P1216 * Description: basic dp * Created by Vegetabot on 2023/12/17. */#include&lt;bits/stdc++.h&gt;#define N 1002using namespace std;vector&lt;vector&lt;int&gt;&gt; dp(N,vector&lt;int&gt;(N,0));vector&lt;vector&lt;int&gt;&gt; nums(N,vector&lt;int&gt;(N,0));int n;int main()&#123; scanf(&quot;%d&quot;,&amp;n); for(int i=0;i&lt;n;++i)&#123; for(int j=0;j&lt;=i;++j)&#123; scanf(&quot;%d&quot;,&amp;nums[i][j]); &#125; &#125; for(int i=1;i&lt;=n;++i)&#123; for(int j=1;j&lt;=i;++j)&#123; dp[i][j] = max(dp[i-1][j-1],dp[i-1][j]) + nums[i-1][j-1]; &#125; &#125; int ans = dp[n][0]; for(int i=1;i&lt;=n;++i) ans = ans&gt;dp[n][i]?ans:dp[n][i]; printf(&quot;%d&quot;,ans); return 0;&#125; P1048 [NOIP2005 æ™®åŠç»„] é‡‡è¯ é¢˜ç›®ä¼ é€é—¨ï¼šP1048 [NOIP2005 æ™®åŠç»„] é‡‡è¯ - æ´›è°· | è®¡ç®—æœºç§‘å­¦æ•™è‚²æ–°ç”Ÿæ€ (luogu.com.cn) 01èƒŒåŒ…æ¿å­é¢˜ï¼ŒèƒŒåŒ…ç›¸å…³çš„çŸ¥è¯†ç‚¹å»ºè®®å¯ä»¥å­¦ä¹ ç½‘ä¸Šéå¸¸çš„æµè¡Œçš„èƒŒåŒ…ä¹è®²æ•™ç¨‹ 12345678910111213141516171819202122232425262728293031/* * Problem: P1048 [NOIP2005 æ™®åŠç»„] é‡‡è¯ * URL: https://www.luogu.com.cn/problem/P1048 * Description: 01èƒŒåŒ… * Created by Vegetabot on 2023/12/17. */#include&lt;bits/stdc++.h&gt;using namespace std;vector&lt;vector&lt;int&gt;&gt; dp(101,vector&lt;int&gt;(1001,0));vector&lt;int&gt; times,vals;int M,T;int main()&#123; scanf(&quot;%d%d&quot;,&amp;T,&amp;M); for(int i=0;i&lt;M;++i)&#123; int a,b; scanf(&quot;%d%d&quot;,&amp;a,&amp;b); times.emplace_back(a); vals.emplace_back(b); &#125; for(int i=1;i&lt;=M;++i)&#123; for(int j=0;j&lt;=T;++j)&#123; if (j &lt; times[i-1]) dp[i][j] = dp[i-1][j]; else dp[i][j] = max(dp[i-1][j],dp[i-1][j-times[i-1]]+vals[i-1]); &#125; &#125; int ans = dp[M][0]; for(int i=0;i&lt;=T;++i) ans = ans&gt;dp[M][i]?ans:dp[M][i]; printf(&quot;%d&quot;,ans); return 0;&#125; æ„Ÿè§‰emplace_backæ€§èƒ½ä¼šæ¯”push_backè¦å¥½ä¸€äº›ï¼Œ ä»¥åéƒ½ç”¨emplace_backå¥½äº† åŒæ ·å› ä¸ºæ˜¯åŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œæ‰€ä»¥æ¯‹åº¸ç½®ç–‘çš„æ˜¯ï¼Œè¿™é“é¢˜ç›®ä¹Ÿå¯ä»¥ä½¿ç”¨è®°å¿†åŒ–æœç´¢çš„æ–¹å¼æ¥è§£å†³ã€‚ ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940/* * Problem: P1048 [NOIP2005 æ™®åŠç»„] é‡‡è¯ * URL: https://www.luogu.com.cn/problem/P1048 * Description: 01èƒŒåŒ… * Created by Vegetabot on 2023/12/17. */#include&lt;bits/stdc++.h&gt;using namespace std;vector&lt;vector&lt;int&gt;&gt; dp;vector&lt;int&gt; times, vals;int M, T;int solve(int i, int j) &#123; if (i == 0) return 0; // è¾¹ç•Œæ¡ä»¶ if (dp[i][j] != -1) return dp[i][j]; // å·²ç»è®¡ç®—è¿‡ int notTake = solve(i - 1, j); // ä¸é€‰æ‹©å½“å‰ç‰©å“ int take = 0; if (j &gt;= times[i-1]) &#123; take = vals[i-1] + solve(i - 1, j - times[i-1]); // é€‰æ‹©å½“å‰ç‰©å“ &#125; return dp[i][j] = max(notTake, take); // è®°å¿†åŒ–å­˜å‚¨å¹¶è¿”å›ç»“æœ&#125;int main() &#123; scanf(&quot;%d%d&quot;, &amp;T, &amp;M); dp.assign(M+1, vector&lt;int&gt;(T + 1, -1)); // åˆå§‹åŒ–è®°å¿†åŒ–æ•°ç»„ times.resize(M); vals.resize(M); for (int i = 0; i &lt; M; ++i) &#123; scanf(&quot;%d%d&quot;, &amp;times[i], &amp;vals[i]); &#125; printf(&quot;%d&quot;, solve(M, T)); // ä»ç¬¬0ä¸ªç‰©å“å¼€å§‹ï¼Œæ€»é™åˆ¶ä¸ºT return 0;&#125; å½“ç„¶01èƒŒåŒ…é—®é¢˜è¿˜å¯ä»¥ä½¿ç”¨æ»šåŠ¨æ•°ç»„å¯¹ç©ºé—´è¿›è¡Œä¼˜åŒ–ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°äº†ï¼ˆå› ä¸ºå†™çš„æ¯”è¾ƒå¤šï¼‰"},{"title":"PyTorch RNN&LSTM","path":"/wiki/PyTorch/PyTorch RNN&LSTM.html","content":"åºåˆ—è¡¨ç¤ºï¼ˆSequence representationï¼‰ æ–¹æ³•ä¸€ å¯¹äºä¸€ä¸ªå¥å­ï¼Œæˆ‘ä»¬é‡‡ç”¨å¦‚ä¸‹çš„è¡¨ç¤ºæ–¹å¼ï¼š [seq_len,feature_len][seq\\_len,feature\\_len] [seq_len,feature_len] seq_lenseq \\_ lenseq_lenè¡¨ç¤ºçš„æ˜¯è¿™ä¸ªå¥å­æ‰€å«çš„å•è¯æ•°é‡ï¼Œfeature_lenfeature \\_ lenfeature_lenè¡¨ç¤ºçš„æ˜¯è¡¨ç¤ºä¸€ä¸ªå•è¯æ‰€éœ€å‘é‡çš„é•¿åº¦ï¼ˆä¸€èˆ¬é‡‡ç”¨ç‹¬çƒ­ç¼–ç ï¼‰ã€‚ ç¼ºç‚¹ï¼šç‹¬çƒ­ç ä½¿å¾—çŸ©é˜µå˜å¾—ç¨€ç–ï¼Œå ç”¨äº†å¤§é‡å­˜å‚¨ç©ºé—´çš„åŒæ—¶ï¼Œè¡¨è¾¾çš„ä¿¡æ¯æµ·éå¸¸å°‘ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬æƒ³çœ‹åˆ°çš„ç»“æœã€‚ æ–¹æ³•äºŒ ä¸ºäº†è®©ç‰¹å¾å‘é‡å˜å¾—ä¸é‚£ä¹ˆç¨€ç–ï¼Œæˆ‘ä»¬ä¸é‡‡ç”¨ç‹¬çƒ­ç¼–ç æ–¹å¼ã€‚æˆ‘ä»¬è¿˜æ˜¯å¯ä»¥å°†è¦ä½¿ç”¨çš„å•è¯ä½¿ç”¨å‘é‡ç¼–ç ï¼Œåªä¸è¿‡è¿™æ¬¡å‘é‡ç¼–ç æœ‰æ•ˆçš„åˆ©ç”¨äº†è¯­ä¹‰ç›¸å…³æ€§ï¼Œè¯­ä¹‰ç›¸å…³æ€§é«˜çš„ä¸¤ä¸ªå‘é‡ï¼Œä»–ä»¬çš„å¤¹è§’æ›´å°ï¼Œåä¹‹ï¼Œå¤¹è§’ä¼šéå¸¸å¤§ã€‚ç°ç›®å‰å·²ç»æœ‰ä¸¤ç§æŠ€æœ¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¥è¿›è¡Œè¿™ç§æ–¹å¼çš„ç¼–ç ã€‚ Word2vec GloVe å› ä¸ºä¸ä¼šæ·±å…¥nlpéƒ¨åˆ†ï¼Œæ‰€ä»¥æˆ‘ä»¬æš‚æ—¶ä¸è¯¦ç»†ä»‹ç»è¿™ä¸¤ç§æ–¹å¼ï¼Œå¤§å®¶æœ‰å…´è¶£å¯ä»¥è‡ªè¡Œç™¾åº¦ã€‚ æ–¹æ³•äºŒä¹Ÿæ˜¯ç°ç›®å‰ä½¿ç”¨æœ€å¹¿æ³›çš„ä¸€ç§æ–¹æ³•ã€‚ PyTorchå®ç° ä½¿ç”¨PyTorch å»ºç«‹ç´¢å¼•ç‰¹å¾å‘é‡è¡¨å¹¶æ ¹æ®ç´¢å¼•æŸ¥è¯¢å¯¹åº”å•è¯çš„ç‰¹å¾å‘é‡ 12345678910import torchfrom torch import nnword_to_ix=&#123;&quot;hello&quot;: 0,&quot;world&quot; :1&#125;lookup_tensor = torch.tensor([word_to_ix[&quot;hello&quot;]],dtype=torch.long)embeds=nn.Embedding(2,5)hello_embed=embeds(lookup_tensor)print(hello_embed) è¿è¡Œç»“æœ 12tensor([[-0.4940, -0.9166, 1.2154, 0.4011, -0.6101]], grad_fn=&lt;EmbeddingBackward0&gt;) PyTorch å¯¼å…¥GloVe GloVeæ˜¯ä¸€ç§nlpä¸­å¸¸ç”¨çš„å•è¯çš„å‘é‡ç¼–ç ã€‚ åœ¨PyTorchä¸­ä½¿ç”¨GloVeç¼–ç çš„ä»£ç å¦‚ä¸‹ï¼š 1234from torchnlp.word_to_vector import GloVevectors=GloVe()print(vectors[&#x27;hello&#x27;]) # ç„¶åå°±å¯ä»¥å¾—åˆ°å‘é‡è¡¨ç¤ºçš„ç»“æœ RNNåŸç† æ‰€å…·å¤‡çš„èƒ½åŠ› èƒ½å¤„ç†é•¿å¥å­ï¼Œæ™®é€šçš„å…¨è¿æ¥ç¥ç»ç½‘ç»œä¸è¡Œï¼Œå› ä¸ºè¿™æ ·w,bå‚æ•°å¤ªå¤šäº†ã€‚è§£å†³æ–¹å¼æ˜¯é‡‡ç”¨äº†æƒå€¼å…±äº« èƒ½å¤Ÿè¿æ¥ä¸Šä¸‹æ–‡ï¼Œå…·æœ‰ä¸Šä¸‹æ–‡è¯­å¢ƒä¿¡æ¯ï¼ˆè¯­å¢ƒè´¯ç©¿ï¼‰ å…·ä½“ä¸€èˆ¬æƒ…å†µä¸‹çš„è¡¨è¾¾å¼å¦‚ä¸‹ï¼š ht=fw(htâˆ’1,xt)h_t=f_w(h_{t-1},x_t) htâ€‹=fwâ€‹(htâˆ’1â€‹,xtâ€‹) ht=tanh(Whhhtâˆ’1+Wxhxt)(thereÂ areÂ twoÂ bias!)h_t=tanh(W_{hh}h_{t-1}+W_{xh}x_t)\\qquad(there\\ are \\ two \\ bias!) htâ€‹=tanh(Whhâ€‹htâˆ’1â€‹+Wxhâ€‹xtâ€‹)(thereÂ areÂ twoÂ bias!) yt=Whyhty_t=W_{hy}h_t ytâ€‹=Whyâ€‹htâ€‹ åå‘ä¼ æ’­æ›´æ–°æ¢¯åº¦çš„å…¬å¼ âˆ‚Etâˆ‚Whh=âˆ‘i=0tâˆ‚Etâˆ‚ytâˆ‚ytâˆ‚htâˆ‚htâˆ‚hiâˆ‚hiâˆ‚Whh\\frac{\\partial E_t}{\\partial W_{hh}}=\\sum_{i=0}^t \\frac{\\partial E_t}{\\partial y_t}\\frac{\\partial y_t}{\\partial h_t}\\frac{\\partial h_t}{\\partial h_i}\\frac{\\partial h_i}{\\partial W_{hh}} âˆ‚Whhâ€‹âˆ‚Etâ€‹â€‹=i=0âˆ‘tâ€‹âˆ‚ytâ€‹âˆ‚Etâ€‹â€‹âˆ‚htâ€‹âˆ‚ytâ€‹â€‹âˆ‚hiâ€‹âˆ‚htâ€‹â€‹âˆ‚Whhâ€‹âˆ‚hiâ€‹â€‹ å¦‚æœæˆ‘ä»¬é‡‡ç”¨[seq_len,batch_sz,feature_len][seq\\_len,batch\\_sz,feature\\_len][seq_len,batch_sz,feature_len]æ¥è¡¨ç¤ºæ•°æ®ï¼Œåˆ™å¯¹äºæ•°æ®å¤§å°ä¸º[5,3,100]çš„è¯­ä¹‰æ•°æ®æ¥è¯´ï¼Œæˆ‘ä»¬è¾“å…¥RNNä¸­xix_ixiâ€‹çš„ç»´åº¦åº”è¯¥æ˜¯[3,100]ä¹Ÿå°±æ˜¯[batch_sz,feature_len][batch\\_sz,feature\\_len][batch_sz,feature_len] RNN Layerä½¿ç”¨ è¯·ç‰¢è®° xt@wxh+ht@whhx_t@w_{xh}+h_t@w_{hh} xtâ€‹@wxhâ€‹+htâ€‹@whhâ€‹ nn.RNN é¦–å…ˆä¸¾ä¸€ä¸ªç®€å•çš„ä¾‹å­è®©æˆ‘ä»¬æ¥çœ‹ä¸€çœ‹è¯¥APIä¸­çš„å‚æ•°ä¿¡æ¯ 123456789In [3]: from torch import nnIn [4]: rnn=nn.RNN(100,20)In [5]: rnn._parameters.keys()Out[5]: odict_keys([&#x27;weight_ih_l0&#x27;, &#x27;weight_hh_l0&#x27;, &#x27;bias_ih_l0&#x27;, &#x27;bias_hh_l0&#x27;])In [6]: rnn.weight_hh_l0.shape,rnn.weight_ih_l0.shapeOut[6]: (torch.Size([20, 20]), torch.Size([20, 100]))In [7]: rnn.bias_hh_l0.shape,rnn.bias_ih_l0.shapeOut[7]: (torch.Size([20]), torch.Size([20])) ä¸€èˆ¬æ¥è¯´è¯¥APIå¡«å…¥å‚æ•°æ˜¯`nn.RNN(input_size,hidden_size,byn_layers)`input_size:ä»£è¡¨çš„æ˜¯è¡¨ç¤ºä¸€ä¸ªå•è¯æ‰€éœ€çš„å‘é‡çš„é•¿åº¦ã€‚ hidden_size:ä»£è¡¨çš„æ˜¯è¾“å‡ºçš„æ—¶å€™å‘é‡çš„é•¿åº¦ã€‚ byn_layers:ä»£è¡¨çš„æ˜¯è¾“å…¥åˆ°è¾“å‡ºä¸­é—´å±‚çš„ä¸ªæ•°ï¼Œé»˜è®¤å±‚æ•°ä¸ºä¸€å±‚ å› ä¸ºä¸Šé¢ä»£ç æ²¡å†™`byn_layers`å‚æ•°ï¼Œæ‰€ä»¥é»˜è®¤ä¸€å±‚ï¼Œå› æ­¤ä¸Šé¢çš„ç½‘ç»œå‚æ•°ç»“å°¾æ•°å­—éƒ½æ˜¯0ã€‚ forward 1out,ht=forward(x,h0) xï¼šç½‘ç»œè¾“å…¥ï¼Œtensorå¤§å°ä¸º[seq_len,batchsz,word_vec][seq\\_len,batchsz,word\\_vec][seq_len,batchsz,word_vec] h0ï¼šRNNçš„åˆå§‹è¾“å…¥ï¼Œtensorå¤§å°ä¸º[num_layers,batchsz,h_dim][num\\_layers,batchsz,h\\_dim][num_layers,batchsz,h_dim]å…¶å®å¯ä»¥ä¸å†™ï¼Œforwordå¯¹äºä¸€ä¸ªé•¿åº¦ä¸ºseq_lençš„å¥å­ï¼Œä¼šå°†å¾ªç¯ç¥ç»ç½‘ç»œå…¨éƒ¨æ‰§è¡Œä¸€éï¼ˆæ¯ä¸ªå•è¯æŒ‰é¡ºåºä¸€æ¬¡æ‰”è¿›å»æ›´æ–°æ¨¡å‹å‚æ•°ï¼‰ã€‚ htï¼štensorå¤§å°ä¸º[num_layers,batchsz,h_dim][num\\_layers,batchsz,h\\_dim][num_layers,batchsz,h_dim],è¡¨ç¤ºçš„æ˜¯æœ€åä¸€ä¸ªå•è¯é€å…¥åï¼Œæœ€åä¸€ä¸ªMLPçš„æ¯ä¸€å±‚çš„è¾“å‡º outï¼štensorå¤§å°ä¸º[seq_len,batchsz,h_dim][seq\\_len,batchsz,h\\_dim][seq_len,batchsz,h_dim],è¡¨ç¤ºçš„æ˜¯æ¯é€å…¥ä¸€ä¸ªå•è¯åï¼Œæ¯ä¸€ä¸ªMLPçš„æœ€åä¸€å±‚çš„è¾“å‡º h_dimå°±æ˜¯ä¸Šé¢çš„hidden_size ä¸‹é¢ä¸¾ä¸€ä¸ªä¾‹å­æ›´åŠ å…·ä½“çš„æ¥è¯´æ˜è¿™ä¸ªAPIçš„ä½¿ç”¨æ–¹æ³•ã€‚ è¿™æ˜¯ä¸€ä¸ªå•å±‚çš„RNN 123456789In [3]: from torch import nnIn [4]: rnn=nn.RNN(input_size=100, hidden_size=20,num_layers=1)In [5]: print(rnn)RNN(100, 20)In [6]: x=torch.randn(10,3,100)In [7]: out,ht=rnn(x,torch.zeros(1,3,20))In [8]: print(out.shape)torch.Size([10, 3, 20]) ä»”ç»†é˜…è¯»ä»£ç ä¼šå‘ç°å’Œå‰é¢è¯´çš„ä¸€æ ·ï¼Œå¾ˆå¥½çš„éªŒè¯äº†å‰é¢æˆ‘ä»¬è¯´çš„æ­£ç¡®æ€§ã€‚ å¤šå±‚RNN åŸç†ä¸€æ ·ï¼Œè¿™é‡Œæ”¾ä¸ªä»£ç æ¥è§‚å¯Ÿä¸€ä¸‹PyTorchä¸­RNNæ¨¡å—çš„å‚æ•°å®šä¹‰å’Œå¤šå±‚RNNè®¾è®¡è§„åˆ™ã€‚ 123456789In [3]: from torch import nnIn [4]: rnn=nn.RNN(100,10,num_layers=2)In [5]: rnn._parameters.keys()Out[5]: odict_keys([&#x27;weight_ih_l0&#x27;, &#x27;weight_hh_l0&#x27;, &#x27;bias_ih_l0&#x27;, &#x27;bias_hh_l0&#x27;, &#x27;weight_ih_l1&#x27;, &#x27;weight_hh_l1&#x27;, &#x27;bias_ih_l1&#x27;, &#x27;bias_hh_l1&#x27;])In [6]: rnn.weight_hh_l0.shape, rnn.weight_ih_l0.shapeOut[6]: (torch.Size([10, 10]), torch.Size([10, 100]))In [7]: rnn.weight_hh_l1.shape, rnn.weight_ih_l1.shapeOut[7]: (torch.Size([10, 10]), torch.Size([10, 10])) æ³¨æ„è§‚å¯Ÿrnn.weight_ih_l0.shapeå’Œrnn.weight_ih_l1.shapeçš„ç»´åº¦åŒºåˆ« åŒç†æˆ‘ä»¬ä¹Ÿç»™å‡ºå’Œä¸Šé¢å•å±‚æ¯”è¾ƒåƒçš„4å±‚RNNä»£ç ï¼Œå¸®åŠ©å¤§å®¶ç†è§£ã€‚ 123456789In [3]: from torch import nnIn [4]: rnn=nn.RNN(input_size=100,hidden_size=20,num_layers=4)In [5]: print(rnn)RNN(100, 20, num_layers=4)In [6]: x=torch.randn(10,3,100)In [7]: out,h=rnn(x)In [8]: print(out.shape,h.shape)torch.Size([10, 3, 20]) torch.Size([4, 3, 20]) nn.RNNCell ä¸åŒäºnn.RNN,è¯¥å‡½æ•°éœ€è¦æˆ‘ä»¬å¤šæ¬¡inputæ‰èƒ½è¿­ä»£å‡ºæœ€åçš„ç»“æœã€‚æ‰“æ¯”æ–¹å°±æ˜¯æ¯”å¦‚è¯´æˆ‘æœ‰ä¸€å¥è¯ï¼Œå…¶ä¸­æœ‰10ä¸ªå•è¯ã€‚å¯¹äºnn.RNNæˆ‘ä»¬åªéœ€è¦ä¸€èµ·inputè¿›å»ï¼Œnn.RNNè¿­ä»£ä¸€æ¬¡å°±è‡ªåŠ¨æ›´æ–°äº†æ‰€æœ‰ï¼Œè€Œnn.RNNCellæˆ‘ä»¬è¦æŒ‰é¡ºåºä¸€ä¸ªå•è¯ä¸€ä¸ªå•è¯æ‰”è¿›å»è®­ç»ƒã€‚ç›¸æ¯”ä¹‹ä¸‹nn.RNNCellè™½ç„¶æ›´åŠ éº»çƒ¦ï¼Œä½†æ˜¯æ¯”nn.RNNæ›´åŠ çµæ´»ã€‚ åˆå§‹åŒ– 1rnncell=nn.RNNCell(100,20) ä¸¤ä¸ªå‚æ•°è¡¨ç¤ºè¾“å…¥å’Œè¾“å‡ºçš„ç»´åº¦ï¼Œæ„Ÿè§‰å’Œnn.Linearæœ‰ç‚¹åƒ ä½¿ç”¨æ–¹æ³• 1ht=rnncell(xt,ht_1) xtï¼šå½“å‰ç½‘ç»œè¾“å…¥ï¼Œtensorå¤§å°ä¸º[batchsz,word_vec][batchsz,word\\_vec][batchsz,word_vec] ht_1ï¼šä¸Šä¸€æ¬¡RNNè¾“å‡ºï¼Œtensorå¤§å°ä¸º[num_layers,batchsz,h_dim][num\\_layers,batchsz,h\\_dim][num_layers,batchsz,h_dim]ï¼Œå’Œä¹‹å‰é‚£ä¸€æ · htï¼šæœ¬æ¬¡RNNè¾“å‡ºï¼Œtensorå¤§å°ä¸º[num_layers,batchsz,h_dim][num\\_layers,batchsz,h\\_dim][num_layers,batchsz,h_dim] è¿­ä»£æ“ä½œ å•å±‚RNN 1234567In [3]: from torch import nnIn [4]: cell1=nn.RNNCell(100,20)In [5]: h1=torch.zeros(3,20)In [6]: for xt in x: ...: h1=cell1(xt,h1)In [7]: print(h1.shape)torch.Size([3,20]) åŒå±‚RNN 12345678910In [3]: from torch import nnIn [4]: cell1=nn.RNNCell(100,30)In [5]: h1=torch.zeros(3,30)In [6]: cell2=nn.RNNCell(30,20)In [7]: h2=torch.zeros(3,20)In [8]: for xt in x: ...: h1=cell1(xt,h1) ...: h2=cell2(h1,h2)In [9]: print(h2.shape)torch.Size([3,20]) å®æˆ˜RNNæ³¢å½¢é¢„æµ‹ è¿™é‡Œæƒ³å®ç°çš„ä¸€ä¸ªç›®çš„å°±æ˜¯æ ¹æ®æ­£å¼¦æ³¢å½¢çš„å‰æ®µéƒ¨åˆ†ï¼Œé¢„æµ‹åé¢çš„æ­£å¼¦æ›²çº¿èµ°åŠ¿ã€‚ æˆ‘ä»¬è¿™é‡Œå®ç°çš„åŠŸèƒ½æ˜¯æ ¹æ®å‰1ä¸ªå€¼é¢„æµ‹å1ä¸ªå€¼æ˜¯å¤šå°‘ã€‚ è®­ç»ƒæ˜¯æ¯æ¬¡æ‰”å…¥è¿ç»­çš„50ä¸ªå€¼ï¼Œç„¶åé¢„æµ‹å‘åé¢„æµ‹ä»…å¾€åç§»åŠ¨ä¸€ä¸ªå•ä½çš„50ä¸ªå€¼ï¼ˆæœ‰49ä¸ªå€¼æ˜¯é‡å¤çš„ï¼‰ ç½‘ç»œè®¾è®¡ 12345678910111213141516171819202122232425class Net(nn.Module): def __init__(self, ): super(Net, self).__init__() self.rnn = nn.RNN( input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True, #input:[b,seq_len,word_vec] ) # åˆå§‹åŒ–å‚æ•° for p in self.rnn.parameters(): nn.init.normal_(p, mean=0.0, std=0.001) self.linear = nn.Linear(hidden_size, output_size) def forward(self, x, hidden_prev): out, hidden_prev = self.rnn(x, hidden_prev) # [b, seq, h] out = out.view(-1, hidden_size) out = self.linear(out) out = out.unsqueeze(dim=0) return out, hidden_prev è®­ç»ƒéƒ¨åˆ† 123456789101112131415161718192021for iter in range(6000): start = np.random.randint(3, size=1)[0] time_steps = np.linspace(start, start + 10, num_time_steps) data = np.sin(time_steps) data = data.reshape(num_time_steps, 1) x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1) y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1) output, hidden_prev = model(x, hidden_prev) hidden_prev = hidden_prev.detach() loss = criterion(output, y) model.zero_grad() loss.backward() # for p in model.parameters(): # print(p.grad.norm()) # torch.nn.utils.clip_grad_norm_(p, 10) optimizer.step() if iter % 100 == 0: print(&quot;Iteration: &#123;&#125; loss &#123;&#125;&quot;.format(iter, loss.item())) ä»£ç ä¸­çš„detachæ˜¯æˆ‘ä»¬ä¹‹å‰ä»æœªè§è¿‡çš„å‡½æ•°ã€‚å®ƒè¿”å›ä¸€ä¸ªæ–°çš„tensorï¼Œä»å½“å‰è®¡ç®—å›¾ä¸­åˆ†ç¦»ä¸‹æ¥ã€‚ä½†æ˜¯ä»æŒ‡å‘åŸå˜é‡çš„å­˜æ”¾ä½ç½®ï¼Œ**ä¸åŒä¹‹å¤„åªæ˜¯requirse_gradä¸ºfalse.**å¾—åˆ°çš„è¿™ä¸ªtensiræ°¸è¿œä¸éœ€è¦è®¡ç®—å™¨æ¢¯åº¦ï¼Œä¸å…·æœ‰grad. æµ‹è¯•éƒ¨åˆ† 12345678910111213141516171819202122start = np.random.randint(3, size=1)[0]time_steps = np.linspace(start, start + 10, num_time_steps)data = np.sin(time_steps)data = data.reshape(num_time_steps, 1)x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)predictions = []input = x[:, 0, :]for _ in range(x.shape[1]): input = input.view(1, 1, 1) (pred, hidden_prev) = model(input, hidden_prev) input = pred predictions.append(pred.detach().numpy().ravel()[0])x = x.data.numpy().ravel()y = y.data.numpy()plt.scatter(time_steps[:-1], x.ravel(), s=90)plt.plot(time_steps[:-1], x.ravel())plt.scatter(time_steps[1:], predictions)plt.show() ä»£ç æ±‡æ€» 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import numpy as npimport torchimport torch.nn as nnimport torch.optim as optimfrom matplotlib import pyplot as pltnum_time_steps = 50input_size = 1hidden_size = 16output_size = 1lr=0.01class Net(nn.Module): def __init__(self, ): super(Net, self).__init__() self.rnn = nn.RNN( input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True, ) for p in self.rnn.parameters(): nn.init.normal_(p, mean=0.0, std=0.001) self.linear = nn.Linear(hidden_size, output_size) def forward(self, x, hidden_prev): out, hidden_prev = self.rnn(x, hidden_prev) # [b, seq, h] out = out.view(-1, hidden_size) out = self.linear(out) out = out.unsqueeze(dim=0) return out, hidden_prevmodel = Net()criterion = nn.MSELoss()optimizer = optim.Adam(model.parameters(), lr)hidden_prev = torch.zeros(1, 1, hidden_size)for iter in range(6000): start = np.random.randint(3, size=1)[0] time_steps = np.linspace(start, start + 10, num_time_steps) data = np.sin(time_steps) data = data.reshape(num_time_steps, 1) x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1) y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1) output, hidden_prev = model(x, hidden_prev) hidden_prev = hidden_prev.detach() loss = criterion(output, y) model.zero_grad() loss.backward() # for p in model.parameters(): # print(p.grad.norm()) # torch.nn.utils.clip_grad_norm_(p, 10) optimizer.step() if iter % 100 == 0: print(&quot;Iteration: &#123;&#125; loss &#123;&#125;&quot;.format(iter, loss.item()))start = np.random.randint(3, size=1)[0]time_steps = np.linspace(start, start + 10, num_time_steps)data = np.sin(time_steps)data = data.reshape(num_time_steps, 1)x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)predictions = []input = x[:, 0, :]for _ in range(x.shape[1]): input = input.view(1, 1, 1) (pred, hidden_prev) = model(input, hidden_prev) input = pred predictions.append(pred.detach().numpy().ravel()[0])x = x.data.numpy().ravel()y = y.data.numpy()plt.scatter(time_steps[:-1], x.ravel(), s=90)plt.plot(time_steps[:-1], x.ravel())plt.scatter(time_steps[1:], predictions)plt.show() ravel()åœ¨numpyä¸­æ˜¯å°†numpyæ•°ç»„æ‹å¹³ï¼Œå˜æˆä¸€ç»´çš„æ“ä½œï¼Œç±»ä¼¼å‰é¢è®²çš„Flatten ç»“æœ RNNè®­ç»ƒé—®é¢˜ æ¢¯åº¦çˆ†ç‚¸ æ¢¯åº¦å¼¥æ•£ æ¢¯åº¦çˆ†ç‚¸ è§£å†³æ–¹æ³• å…¶å®å¹¶ä¸æ˜¯å¾ˆéš¾ï¼Œæˆ‘ä»¬é‡‡ç”¨clippingçš„æ–¹æ³•ï¼Œå°±æ˜¯æˆ‘ä»¬æ¯æ¬¡ä½¿ç”¨backward()æ›´æ–°äº†æ¢¯åº¦ä¿¡æ¯åï¼Œå¯¹æ‰€å¾—åˆ°çš„æ¢¯åº¦å¤§å°è¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœæ¨¡é•¿å¤§äºäº†é˜ˆå€¼ï¼Œåˆ™æˆ‘ä»¬å¯¹è¯¥æ¢¯åº¦(gradâƒ—\\vec{grad}gradâ€‹)è¿›è¡Œå¦‚ä¸‹æ“ä½œ: gradâƒ—=thresholdÃ—gradâƒ—âˆ£âˆ£gradâˆ£âˆ£\\vec{grad}=threshold\\times \\frac{\\vec{grad}}{||grad||} gradâ€‹=thresholdÃ—âˆ£âˆ£gradâˆ£âˆ£gradâ€‹â€‹ è™½ç„¶æ²¡æœ‰ä»æ ¹æœ¬è§£å†³æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼Œä½†æ˜¯æˆ‘ä»¬æœ‰æ•ˆéåˆ¶äº†å®ƒå¸¦æ¥çš„ç³Ÿç³•çš„æƒ…å†µã€‚ æ³¨æ„æ˜¯å¯¹å‚æ•°çš„æ¢¯åº¦è¿›è¡Œclippingä¸æ˜¯å¯¹ç½‘ç»œä¸­çš„å‚æ•°æœ¬ä½“ï¼ï¼ï¼ PyTorchå®ç° æ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯torch.nn.utils.clip_grad_norm_ 1234567loss = criterion(output,y)model.zero_grad()loss.backward()for p in model.parameters():\tprint(p.grad.norm())\ttorch.nn.utils.clip_grad_norm_(p,10) # &lt;10optimizer.step() æ¢¯åº¦åœ¨10å·¦å³æ¯”è¾ƒåˆé€‚ æ¢¯åº¦å¼¥æ•£ RNNæ¢¯åº¦å¼¥æ•£çš„è§£å†³æ–¹æ³•ï¼Œè¯·è§ä¸‹èŠ‚è¯¾æ‰€è®²çš„LSTM LSTM å¤§ä½“ç»“æ„å’ŒRNNç›¸åŒåªæ˜¯å¤šäº†ä¸‰ä¸ªÏƒ\\sigmaÏƒ(sigmoid)å‡½æ•°æ¥ä½œä¸ºé—¨ï¼Œè¿™ä¸‰é“é—¨åˆ†åˆ«å«åšForget gate,Input gate,Output gate ä¸åŒäºRNNï¼ŒLSTMçš„CtC_tCtâ€‹çš„ä½œç”¨æ‰æ˜¯memoryï¼ˆRNNä¸­æ˜¯hth_thtâ€‹ï¼‰ ä¸‰ä¸ªSigmoid Forget gate ft=Ïƒ(Wfâ‹…[htâˆ’1,xt]+bf)f_t=\\sigma (W_f \\cdot [h_{t-1},x_t] + b_f) ftâ€‹=Ïƒ(Wfâ€‹â‹…[htâˆ’1â€‹,xtâ€‹]+bfâ€‹) Input gate it=Ïƒ(Wiâ‹…[htâˆ’1,xt]+bi)i_t=\\sigma(W_i\\cdot [h_{t-1},x_t]+b_i) itâ€‹=Ïƒ(Wiâ€‹â‹…[htâˆ’1â€‹,xtâ€‹]+biâ€‹) C~t=tanh(WCâ‹…[htâˆ’1,xt]+bC)\\tilde{C}_t=tanh(W_C\\cdot [h_{t-1},x_t]+b_C) C~tâ€‹=tanh(WCâ€‹â‹…[htâˆ’1â€‹,xtâ€‹]+bCâ€‹) æ›´æ–°C Ct=ftâˆ—Ctâˆ’1+itâˆ—C~tC_t=f_t*C_{t-1}+i_t*\\tilde{C}_t Ctâ€‹=ftâ€‹âˆ—Ctâˆ’1â€‹+itâ€‹âˆ—C~tâ€‹ Output gate ot=Ïƒ(Wo[htâˆ’1,xt]+bo)o_t=\\sigma (W_o[h_{t-1},x_t]+b_o) otâ€‹=Ïƒ(Woâ€‹[htâˆ’1â€‹,xtâ€‹]+boâ€‹) ht=otâˆ—tanh(Ct)h_t=o_t*tanh(C_t) htâ€‹=otâ€‹âˆ—tanh(Ctâ€‹) LSTMè¡Œä¸º input gate forget gate behavior 0 1 è®°ä½è¿‡å»çš„å€¼ 1 1 å°†ç°åœ¨çš„å€¼åŠ å…¥è®°å¿† 0 0 æŠ¹é™¤æ‰€æœ‰çš„è®°å¿† 1 0 å¿˜æ‰è¿‡å»çš„ï¼ŒåŠ å…¥ç°åœ¨çš„ Forgeté—¨å«Rememberæ›´åŠ åˆç†ä¸€äº› LSTMè§£å†³æ¢¯åº¦å¼¥æ•£ å› ä¸ºæ•°å­¦åŸç†ç¨å¾®å¤æ‚ï¼Œæ‰€ä»¥è¿™é‡Œåªæ”¾å‡ºä¸€å¼ å›¾ä¾›å¤§å®¶å‚è€ƒï¼Œæœ‰å…´è¶£å¯ä»¥ä¸‹æ¥è‡ªè¡Œç™¾åº¦ã€‚ç®€å•ç›´è§‚ç†è§£å°±æ˜¯ï¼ŒLSTMå› ä¸ºåŠ å…¥äº†input gate forget gateç­‰ç»“æ„ï¼ŒåŸç†ä¸Šç±»ä¼¼ResNetï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¸€ä¸ªRNNå•å…ƒå¯èƒ½é€€åŒ–æˆç›´è¿ï¼ˆç±»ä¼¼äºResNetä¸­é€€åŒ–æˆåªæœ‰shortcutï¼‰ã€‚å› æ­¤ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†æ¢¯åº¦å¼¥æ•£é—®é¢˜ã€‚ LSTM Layer nn.LSTM __init()__ å’Œnn.RNNåˆå§‹åŒ–æ“ä½œä¸€æ ·: nn.LSTM(input_size,hidden_size,num_layers) æ³¨æ„ï¼šnn.LSTMä¸­çš„CCCå’Œhhhçš„ç»´åº¦å¤§å°æ˜¯ä¸€æ ·çš„ï¼Œéƒ½ç”¨hidden_sizeè¿›è¡Œè¡¨ç¤º LSTM.forward() 1out,(ht,ct)=lstm(x,[ht_1,ct_1]) xï¼štensorå¤§å°ä¸º[seq,b,vec][seq,b,vec][seq,b,vec] h/cï¼štensorå¤§å°ä¸º[numlayer,b,h][num_layer,b,h][numlâ€‹ayer,b,h] outï¼štensorå¤§å°ä¸º[seq,b,h][seq,b,h][seq,b,h] æ³¨æ„ï¼šoutè¾“å‡ºçš„æ˜¯hä¸æ˜¯c ä¸‹é¢è¿˜æ˜¯ç®€å•ç»™å‡ºä¸€ä¸ªä¾‹å­ï¼Œå¸®åŠ©ç†è§£ï¼š 123456789In [3]: from torch import nnIn [4]: lstm=nn.LSTM(input_size=100, hidden_size=20, num_layers=4)In [5]: lstmOut[5]: LSTM(100, 20, num_layers=4)In [6]: x=torch.randn(10,3,100)In [7]: out,(h,c)=lstm(x)In [8]: out.shape,h.shape,c.shapeOut[8]: (torch.Size([10, 3, 20]), torch.Size([4, 3, 20]), torch.Size([4, 3, 20])) å…¶å®å’ŒåŸæ¥çš„RNNä½¿ç”¨å·®åˆ«ä¸æ˜¯éå¸¸å¤§ nn.LSTMCell __init()__ å’Œnn.LSTMåˆå§‹åŒ–æ“ä½œä¸€æ ·: nn.LSTM(input_size,hidden_size,num_layers) LSTMCell.forward() 1ht,ct=lstmcell(xt,[ht_1,ct_1]) å¯¹äºä¸€ä¸ªè¾“å…¥æ˜¯[10,3,100]çš„æ•°æ®ï¼Œä½¿ç”¨ä¸Šè¿°æ–¹æ³•éœ€è¦é€å…¥10æ¬¡ï¼Œæ¯æ¬¡é€å…¥å¤§å°æ˜¯[3,100] åŒç†ï¼Œç›¸æ¯”LSTMï¼ŒLSTMCellæ›´åŠ çš„çµæ´»ï¼Œæˆ‘ä»¬æ›´æ¨èè¿™æ ·çš„æ–¹å¼ åŒä¸Šï¼Œä¸‹é¢è¿˜æ˜¯ç®€å•ç»™å‡ºä¸€ä¸ªä¾‹å­ï¼Œå¸®åŠ©ç†è§£ï¼š 123456789101112131415In [3]: from torch import nnIn [4]: xt=torch.randn(10,3,100)In [5]: cell1=nn.LSTMCell(input_size=100,hidden_size=30)In [6]: cell2=nn.LSTMCell(input_size=30,hidden_size=20)In [7]: h1=torch.zeros(3,30)In [8]: c1=torch.zeros(3,30)In [9]: h2=torch.zeros(3,20)In [10]: c2=torch.zeros(3,20)In [11]: for x in xt: ...: h1,c1=cell1(x,[h1,c1]) ...: h2,c2=cell2(h1,[h2,c2]) In [12]: h2.shape,c2.shapeOut[12]: (torch.Size([3, 20]), torch.Size([3, 20])) LSTMæƒ…æ„Ÿåˆ†ç±»å®æˆ˜ å®‰åˆ©ï¼šGoogle CoLab å…è´¹12Hè®­ç»ƒ å…è´¹K80GPU ç•Œé¢ç±»ä¼¼Jupyterï¼Œæˆ‘ä»¬åªéœ€è¦æŠŠæˆ‘ä»¬çš„ä»£ç æ‰”ä¸Šå»å°±å¯ä»¥è·‘å•¦ã€‚ æ•°æ®å¯¼å…¥ 12345TEXT = data.Field(tokenize=&#x27;spacy&#x27;)LABEL = data.LabelField(dtype=torch.float)train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)print(&#x27;len of train data:&#x27;, len(train_data))print(&#x27;len of test data:&#x27;, len(test_data)) è¿è¡Œç»“æœ 12len of train data: 25000len of test data: 25000 æ‰“å‡ºæ•°æ®ä¸­çš„ä¸€ä¸ªexampleè¿›è¡Œè§‚å¯Ÿ 12print(train_data.examples[15].text)print(train_data.examples[15].label) 12[&#x27;Well&#x27;, &#x27;when&#x27;, &#x27;watching&#x27;, &#x27;this&#x27;, &#x27;film&#x27;, &#x27;late&#x27;, &#x27;one&#x27;, &#x27;night&#x27;, &#x27;I&#x27;, &#x27;was&#x27;, &#x27;simple&#x27;, &#x27;amazed&#x27;, &#x27;by&#x27;, &#x27;it&#x27;, &quot;&#x27;s&quot;, &#x27;greatness&#x27;, &#x27;.&#x27;, &#x27;Fantastic&#x27;, &#x27;script&#x27;, &#x27;,&#x27;, &#x27;great&#x27;, &#x27;acting&#x27;, &#x27;,&#x27;, &#x27;costumes&#x27;, &#x27;and&#x27;, &#x27;special&#x27;, &#x27;effects&#x27;, &#x27;,&#x27;, &#x27;and&#x27;, &#x27;the&#x27;, &#x27;plot&#x27;, &#x27;twists&#x27;, &#x27;,&#x27;, &#x27;wow&#x27;, &#x27;!&#x27;, &#x27;!&#x27;, &#x27;In&#x27;, &#x27;fact&#x27;, &#x27;if&#x27;, &#x27;you&#x27;, &#x27;can&#x27;, &#x27;see&#x27;, &#x27;the&#x27;, &#x27;ending&#x27;, &#x27;coming&#x27;, &#x27;you&#x27;, &#x27;should&#x27;, &#x27;become&#x27;, &#x27;a&#x27;, &#x27;writer&#x27;, &#x27;yourself.&lt;br&#x27;, &#x27;/&gt;&lt;br&#x27;, &#x27;/&gt;Great&#x27;, &#x27;,&#x27;, &#x27;I&#x27;, &#x27;would&#x27;, &#x27;recommend&#x27;, &#x27;this&#x27;, &#x27;film&#x27;, &#x27;to&#x27;, &#x27;anyone&#x27;, &#x27;,&#x27;, &#x27;especially&#x27;, &#x27;if&#x27;, &#x27;I&#x27;, &#x27;don;t&#x27;, &#x27;like&#x27;, &#x27;them&#x27;, &#x27;much.&lt;br&#x27;, &#x27;/&gt;&lt;br&#x27;, &#x27;/&gt;Terrific&#x27;]pos ä½¿ç”¨GloVeå¯¹æ•°æ®ç¼–ç  123456789101112# word2vec, gloveTEXT.build_vocab(train_data, max_size=10000, vectors=&#x27;glove.6B.100d&#x27;)LABEL.build_vocab(train_data)batchsz = 30device = torch.device(&#x27;cuda&#x27;)train_iterator, test_iterator = data.BucketIterator.splits( (train_data, test_data), batch_size = batchsz, device=device) ç½‘ç»œè®¾è®¡â€» 12345678910111213141516171819202122232425262728293031323334353637class RNN(nn.Module): def __init__(self, vocab_size, embedding_dim, hidden_dim): &quot;&quot;&quot; &quot;&quot;&quot; super(RNN, self).__init__() # [0-10001] =&gt; [100] self.embedding = nn.Embedding(vocab_size, embedding_dim) # [100] =&gt; [256] self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=0.5) # [256*2] =&gt; [1] self.fc = nn.Linear(hidden_dim*2, 1) self.dropout = nn.Dropout(0.5) def forward(self, x): &quot;&quot;&quot; x: [seq_len, b] vs [b, 3, 28, 28] &quot;&quot;&quot; # [seq, b, 1] =&gt; [seq, b, 100] embedding = self.dropout(self.embedding(x)) # output: [seq, b, hid_dim*2] # hidden/h: [num_layers*2, b, hid_dim] # cell/c: [num_layers*2, b, hid_di] output, (hidden, cell) = self.rnn(embedding) # [num_layers*2, b, hid_dim] =&gt; 2 of [b, hid_dim] =&gt; [b, hid_dim*2] hidden = torch.cat([hidden[-2], hidden[-1]], dim=1) # [b, hid_dim*2] =&gt; [b, 1] hidden = self.dropout(hidden) out = self.fc(hidden) return out å› ä¸ºnn.LSTMé‡‡ç”¨çš„æ˜¯åŒå‘bidirectional=True,å› æ­¤åé¢å…¨è¿æ¥å±‚çš„hidden_sizeè¦ä¹˜2ã€‚æœ€åLSTMç®—å‡ºæ¥çš„hiddenéƒ¨åˆ†ï¼Œæœ€åä¸¤å±‚å°±æ˜¯å®é™…ç½‘ç»œçš„æœ€åä¸€å±‚ï¼Œåªä¸è¿‡æ˜¯ä¸¤ä¸ªæ–¹å‘ï¼Œæ‰€ä»¥ç»´åº¦ä¸Šå äº†ä¸¤å±‚ã€‚ `vocab_size`è¡¨ç¤ºçš„æ˜¯æœ‰å¤šå°‘ä¸ªå•è¯ï¼Œ`embedding_dim`è¡¨ç¤ºçš„æ˜¯è¡¨ç¤ºä¸€ä¸ªå•è¯éœ€è¦å¤šé•¿ç»´åº¦çš„å‘é‡ã€‚æœ€åä¸€ä¸ªdropoutçš„å¼•å…¥æ˜¯ä¸ºäº†åŠ å¼ºç½‘ç»œçš„é²æ£’æ€§è€Œå¼•å…¥çš„ã€‚ è®­ç»ƒéƒ¨åˆ† 123456789101112131415161718192021222324252627282930313233343536optimizer = optim.Adam(rnn.parameters(), lr=1e-3)criteon = nn.BCEWithLogitsLoss().to(device)rnn.to(device)def binary_acc(preds, y): &quot;&quot;&quot; get accuracy &quot;&quot;&quot; preds = torch.round(torch.sigmoid(preds)) correct = torch.eq(preds, y).float() acc = correct.sum() / len(correct) return accdef train(rnn, iterator, optimizer, criteon): avg_acc = [] rnn.train() for i, batch in enumerate(iterator): # [seq, b] =&gt; [b, 1] =&gt; [b] pred = rnn(batch.text).squeeze(1) # å°†ç¬¬ä¸€ä¸ªç»´åº¦çš„ä¿¡æ¯å‹ç¼©æ‰ # loss = criteon(pred, batch.label) acc = binary_acc(pred, batch.label).item() avg_acc.append(acc) optimizer.zero_grad() loss.backward() optimizer.step() if i%10 == 0: print(i, acc) # ä¸€è½®è®­ç»ƒç»“æŸåæ‰“å‡ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„å¹³å‡å‡†ç¡®ç‡ avg_acc = np.array(avg_acc).mean() print(&#x27;avg acc:&#x27;, avg_acc) evaléƒ¨åˆ† 123456789101112131415161718192021def eval(rnn, iterator, criteon): avg_acc = [] rnn.eval() # åˆ‡æ¢çŠ¶æ€ with torch.no_grad(): for batch in iterator: # [b, 1] =&gt; [b] pred = rnn(batch.text).squeeze(1) # loss = criteon(pred, batch.label) acc = binary_acc(pred, batch.label).item() avg_acc.append(acc) avg_acc = np.array(avg_acc).mean() print(&#x27;&gt;&gt;test:&#x27;, avg_acc) mainéƒ¨åˆ† 1234for epoch in range(10): eval(rnn, test_iterator, criteon) train(rnn, train_iterator, optimizer, criteon) è¿è¡Œç»“æœï¼š 123456789101112131415161718192021222324252627282930&gt;&gt;test: 0.49976021360507690 0.4666666984558105510 0.4000000357627868720 0.530 0.540 0.433333367109298750 0.533333361148834260 0.600000023841857970 0.566666722297668580 0.4000000357627868790 0.36666667461395264100 0.5333333611488342110 0.6666666865348816120 0.7333333492279053130 0.4333333671092987140 0.6000000238418579150 0.5333333611488342160 0.5170 0.46666669845581055180 0.6333333849906921190 0.6666666865348816200 0.40000003576278687210 0.46666669845581055220 0.5666667222976685230 0.5...810 0.9666666984558105820 0.9666666984558105830 0.9666666984558105avg acc: 0.9673461499545786 æ±‡æ€» 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157# -*- coding: utf-8 -*-&quot;&quot;&quot;lstmAutomatically generated by Colaboratory.Original file is located at https://colab.research.google.com/drive/1GX0Rqur8T45MSYhLU9MYWAbycfLH4-Fu&quot;&quot;&quot;!pip install torch!pip install torchtext!python -m spacy download en# K80 gpu for 12 hoursimport torchfrom torch import nn, optimfrom torchtext import data, datasetsprint(&#x27;GPU:&#x27;, torch.cuda.is_available())torch.manual_seed(123)TEXT = data.Field(tokenize=&#x27;spacy&#x27;)LABEL = data.LabelField(dtype=torch.float)train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)print(&#x27;len of train data:&#x27;, len(train_data))print(&#x27;len of test data:&#x27;, len(test_data))print(train_data.examples[15].text)print(train_data.examples[15].label)# word2vec, gloveTEXT.build_vocab(train_data, max_size=10000, vectors=&#x27;glove.6B.100d&#x27;)LABEL.build_vocab(train_data)batchsz = 30device = torch.device(&#x27;cuda&#x27;)train_iterator, test_iterator = data.BucketIterator.splits( (train_data, test_data), batch_size = batchsz, device=device)class RNN(nn.Module): def __init__(self, vocab_size, embedding_dim, hidden_dim): &quot;&quot;&quot; &quot;&quot;&quot; super(RNN, self).__init__() # [0-10001] =&gt; [100] self.embedding = nn.Embedding(vocab_size, embedding_dim) # [100] =&gt; [256] self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=0.5) # [256*2] =&gt; [1] self.fc = nn.Linear(hidden_dim*2, 1) self.dropout = nn.Dropout(0.5) def forward(self, x): &quot;&quot;&quot; x: [seq_len, b] vs [b, 3, 28, 28] &quot;&quot;&quot; # [seq, b, 1] =&gt; [seq, b, 100] embedding = self.dropout(self.embedding(x)) # output: [seq, b, hid_dim*2] # hidden/h: [num_layers*2, b, hid_dim] # cell/c: [num_layers*2, b, hid_di] output, (hidden, cell) = self.rnn(embedding) # [num_layers*2, b, hid_dim] =&gt; 2 of [b, hid_dim] =&gt; [b, hid_dim*2] hidden = torch.cat([hidden[-2], hidden[-1]], dim=1) # [b, hid_dim*2] =&gt; [b, 1] hidden = self.dropout(hidden) out = self.fc(hidden) return outrnn = RNN(len(TEXT.vocab), 100, 256)pretrained_embedding = TEXT.vocab.vectorsprint(&#x27;pretrained_embedding:&#x27;, pretrained_embedding.shape)rnn.embedding.weight.data.copy_(pretrained_embedding)print(&#x27;embedding layer inited.&#x27;)optimizer = optim.Adam(rnn.parameters(), lr=1e-3)criteon = nn.BCEWithLogitsLoss().to(device)rnn.to(device)import numpy as npdef binary_acc(preds, y): &quot;&quot;&quot; get accuracy &quot;&quot;&quot; preds = torch.round(torch.sigmoid(preds)) correct = torch.eq(preds, y).float() acc = correct.sum() / len(correct) return accdef train(rnn, iterator, optimizer, criteon): avg_acc = [] rnn.train() for i, batch in enumerate(iterator): # [seq, b] =&gt; [b, 1] =&gt; [b] pred = rnn(batch.text).squeeze(1) # loss = criteon(pred, batch.label) acc = binary_acc(pred, batch.label).item() avg_acc.append(acc) optimizer.zero_grad() loss.backward() optimizer.step() if i%10 == 0: print(i, acc) avg_acc = np.array(avg_acc).mean() print(&#x27;avg acc:&#x27;, avg_acc) def eval(rnn, iterator, criteon): avg_acc = [] rnn.eval() with torch.no_grad(): for batch in iterator: # [b, 1] =&gt; [b] pred = rnn(batch.text).squeeze(1) # loss = criteon(pred, batch.label) acc = binary_acc(pred, batch.label).item() avg_acc.append(acc) avg_acc = np.array(avg_acc).mean() print(&#x27;&gt;&gt;test:&#x27;, avg_acc)for epoch in range(10): eval(rnn, test_iterator, criteon) train(rnn, train_iterator, optimizer, criteon)"},{"title":"PyTorch CNN","path":"/wiki/PyTorch/PyTorch CNN.html","content":"å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ä»‹ç» å¦‚æœç”¨å…¨è¿æ¥ç¥ç»ç½‘ç»œå¤„ç†å¤§å°ºå¯¸å›¾åƒå…·æœ‰ä¸‰ä¸ªæ˜æ˜¾çš„ç¼ºç‚¹ï¼š ï¼ˆ1ï¼‰é¦–å…ˆå°†å›¾åƒå±•å¼€ä¸ºå‘é‡ä¼šä¸¢å¤±ç©ºé—´ä¿¡æ¯ï¼› ï¼ˆ2ï¼‰å…¶æ¬¡å‚æ•°è¿‡å¤šæ•ˆç‡ä½ä¸‹ï¼Œè®­ç»ƒå›°éš¾ï¼› ï¼ˆ3ï¼‰åŒæ—¶å¤§é‡çš„å‚æ•°ä¹Ÿå¾ˆå¿«ä¼šå¯¼è‡´ç½‘ç»œè¿‡æ‹Ÿåˆã€‚ è€Œä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œå¯ä»¥å¾ˆå¥½åœ°è§£å†³ä¸Šé¢çš„ä¸‰ä¸ªé—®é¢˜ã€‚ å·ç§¯ç¥ç»ç½‘ç»œçš„æå‡ºå‚è€ƒäº†äººçœ¼çš„å±€éƒ¨ç›¸å…³æ€§ï¼Œäººçœ¼ç”¨äºè¯†åˆ«ç‰©ä½“ä¹Ÿæ˜¯å…ˆçœ‹ä¸€ä¸ªå±€éƒ¨ï¼Œæ ¹æ®ä¸€äº›ç‰¹ç§°æ‰èƒ½è¾¨åˆ«è¿™ä¸ªç‰©ä½“æ˜¯ä»€ä¹ˆï¼Œç‰¹å¾çš„è¯†åˆ«å’Œåƒç´ ç‚¹çš„æ’åˆ—ä½ç½®å’Œæƒ…å†µæœ‰å…³ã€‚ æ ¹æ®å±€éƒ¨ç›¸å…³æ€§æå‡ºçš„å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ å·ç§¯è¿ç®— é¦–å…ˆæˆ‘ä»¬ä½¿ç”¨å‡ å¼ å›¾æ¥ç›´è§‚æ„Ÿå—ä¸€ä¸‹å·ç§¯æ˜¯å¦‚ä½•è¿ç®—çš„ æœ€å·¦è¾¹çš„é‚£ä¸ªå«åšå·ç§¯æ ¸ æ›´å¤šæ›´è¯¦ç»†å…³äºå·ç§¯ç¥ç»ç½‘ç»œçš„åŸºç¡€çŸ¥è¯†å¯ä»¥è®¿é—®å¦‚ä¸‹è¿™ç¯‡åšå®¢ï¼šæ·±åº¦å­¦ä¹ ï¼šå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNN å¸¸ç”¨å·ç§¯æ ¸ æ¦‚å¿µè§£æ è¾“å…¥é€šé“ï¼ˆInput_channelsï¼‰:è¾“å…¥æœ‰å¤šå°‘ä¸ªé€šé“ï¼ˆå¤šå°‘å±‚è¾“å…¥ï¼‰ï¼Œæ¯”å¦‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯é»‘ç™½ç…§ç‰‡ï¼Œé‚£ä¹ˆå°±åªæœ‰ä¸€ä¸ªé€šé“ï¼›å¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯rgbå½©è‰²ç…§ç‰‡é‚£ä¹ˆå°±æœ‰ä¸‰ä¸ªé€šé“ã€‚ **æ ¸é€šé“ï¼ˆKernel_channelsï¼‰ğŸ˜—*å·ç§¯æ ¸æœ‰å¤šå°‘ä¸ªé€šé“æ•°é‡ã€‚ æ ¸å¤§å°ï¼ˆKernel_sizeï¼‰:å·ç§¯æ ¸çš„å¤§å°ï¼Œä¸€èˆ¬æ˜¯3Ã—3 æ­¥é•¿ï¼ˆStrideï¼‰:æ¯æ¬¡å·ç§¯æ ¸ç§»åŠ¨çš„æ­¥é•¿ï¼Œä¸€èˆ¬é»˜è®¤æ˜¯1 å¡«å……ï¼ˆPaddingï¼‰:ä¸ºäº†ä¿è¯å·ç§¯è¿ç®—æ¯æ¬¡å·ç§¯å®Œæˆä»¥åè¾“å…¥è¾“å‡ºå›¾ç‰‡å¤§å°ç›¸åŒï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦åœ¨å›¾ç‰‡å‘¨å›´å¡«å……ä¸€åœˆ0ã€‚ å¯¹äºæ¯ä¸€ä¸ªå·ç§¯æ ¸ï¼Œå…¶æ‰€åŒ…å«çš„é€šé“æ•°å¿…é¡»å’Œè¾“å…¥çš„å·ç§¯å±‚çš„é€šé“æ•°ä¸€æ ·ï¼æ‰€ä»¥ä¸Šé¢æ ¸é€šé“æœ‰ä¸¤ç§å«ä¹‰ï¼Œä¸€ç§æ˜¯æŒ‡æ¯ä¸€ä¸ªå·ç§¯æ ¸ä¸­æ‰€å«çš„é€šé“æ•°ï¼Œè¿˜æœ‰ä¸€ç§å«ä¹‰æ˜¯æŒ‡æœ‰å¤šå°‘ä¸ªå·ç§¯æ ¸ã€‚ä½†æ˜¯ä¸€èˆ¬æƒ…å†µä¸‹éƒ½æ˜¯æŒ‡åè€…ã€‚ å› æ­¤å¯¹äºbä¸ª28Ã—28ï¼Œ3é€šé“çš„è¾“å…¥x: [b,3,28,28]å¦‚æœæˆ‘ä»¬é‡‡ç”¨16ä¸ª3*3çš„å·ç§¯æ ¸ï¼Œåˆ™å¯¹äºä¸€ä¸ªå·ç§¯æ ¸ä»–çš„sizeæ˜¯one-k: [3,3,3],å¯¹äº16ä¸ªkçš„æ€»sizeæ˜¯multi-k: [16,3,3,3],å› ä¸ºæœ‰16ä¸ªå·ç§¯æ ¸æ‰€ä»¥åç½®ä¹Ÿæœ‰16ä¸ªbias: [16](è¿™é‡Œè¿ç”¨äº†å¹¿æ’­)ã€‚æœ€ç»ˆçš„è¾“å‡ºæ˜¯out: [b,16,28,28]ï¼ˆè€ƒè™‘äº†paddingï¼‰ PyTorchå®ç° äº†è§£äº†åŸºæœ¬çš„å·ç§¯ç¥ç»ç½‘ç»œåï¼Œä¸‹é¢æˆ‘ä»¬å°è¯•ä½¿ç”¨PyTorchç®€å•çš„å®ç°ä¸€ä¸ªç®€å•çš„äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œï¼Œæ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯nn.Conv2då…¶ä¸­ç¬¬ä¸€ä¸ªå‚æ•°è¡¨ç¤ºçš„æ˜¯è¾“å…¥çš„é€šé“æ•°ï¼Œåé¢çš„å‚æ•°è¡¨ç¤ºçš„æ˜¯è¾“å‡ºçš„é€šé“æ•°ã€‚ 123456789101112131415161718In [3]: import torch.nn as nnIn [4]: layer=nn.Conv2d(1,3,kernel_size=3,stride=1,padding=0)In [5]: x=torch.rand(123,1,28,28)In [6]: out=layer.forward(x)In [7]: out.shapeOut[7]: torch.Size([123, 3, 26, 26])In [8]: layer=nn.Conv2d(1,12,kernel_size=3,stride=1,padding=1)In [9]: out=layer.forward(x)In [10]: out.shapeOut[10]: torch.Size([123, 12, 28, 28])In [11]: layer=nn.Conv2d(1,12,kernel_size=3,stride=2,padding=1)In [12]: out=layer.forward(x)In [13]: out.shapeOut[13]: torch.Size([123, 12, 14, 14])In [14]: out=layer(x) # å¼ºçƒˆæ¨èè¿™ä¸€ç§ä¸ä½¿ç”¨forwardçš„æ–¹æ³•In [15]: out.shapeOut[15]: torch.Size([123, 12, 14, 14]) æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç æ¥çœ‹çœ‹æœ€åä¸€æ¬¡è¿™ä¸ªlayerä¸­å­˜æ”¾äº†ä»€ä¹ˆæ ·çš„weightå’Œbias(æ¥ä¸Šé¢çš„ä»£ç ) 1234567891011121314151617181920212223242526272829303132333435363738394041424344In [16]: layer.weightOut[16]: Parameter containing:tensor([[[[-0.2432, -0.2371, 0.2480], [-0.2706, -0.2552, -0.0627], [ 0.1960, -0.3049, -0.0273]]], [[[-0.3008, 0.1268, 0.0518], [ 0.0673, 0.2716, -0.1481], [ 0.1075, -0.2905, 0.1106]]], [[[ 0.1498, -0.0681, -0.1162], [ 0.3015, 0.1400, 0.0372], [-0.1401, 0.1158, -0.0872]]], [[[ 0.1543, -0.0323, -0.2023], [ 0.2972, -0.0344, 0.3114], [ 0.2141, -0.0388, -0.0352]]], [[[ 0.1029, 0.0184, -0.2372], [ 0.2758, -0.1239, 0.2429], [-0.0263, -0.2977, -0.2075]]], [[[ 0.2166, -0.1031, -0.2122], [ 0.2123, -0.1492, -0.0831], [-0.0155, -0.0572, -0.2485]]], [[[-0.0441, -0.3298, 0.2896], [ 0.1438, 0.1364, -0.2721], [ 0.0076, 0.0919, -0.1219]]], [[[ 0.3241, 0.1343, 0.0140], [ 0.2732, -0.1690, -0.3122], [ 0.2933, 0.0007, 0.1548]]], [[[ 0.2695, 0.3256, 0.0424], [-0.2905, -0.1272, -0.1482], [-0.1993, 0.1244, 0.1924]]], [[[ 0.1136, -0.0931, -0.2240], [-0.0278, -0.1714, -0.0614], [-0.0067, -0.1385, -0.2265]]], [[[ 0.3065, 0.1684, -0.0113], [-0.0534, 0.0034, 0.0194], [-0.1013, 0.0573, -0.2356]]], [[[-0.1154, -0.0406, 0.0382], [-0.3318, -0.2613, 0.0636], [-0.2066, 0.3052, -0.2338]]]], requires_grad=True)In [17]: layer.weight.shapeOut[17]: torch.Size([12, 1, 3, 3])In [18]: layer.bias.shapeOut[18]: torch.Size([12]) ä»¥ä¸Šæ˜¯ç±»APIçš„å†™æ³•ï¼ŒPyTorchä¹Ÿæä¾›å‡½æ•°APIï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ï¼š 1234567891011In [3]: import torch.nn.functional as FIn [4]: w=torch.rand(16,3,5,5,requires_grad=True)In [5]: b=torch.rand(16,requires_grad=True)In [6]: x=torch.rand(321,3,28,28)In [7]: out=F.conv2d(x,w,b,stride=1,padding=1)In [8]: out.shapeOut[8]: torch.Size([321, 16, 26, 26])In [9]: out=F.conv2d(x,w,b,stride=2,padding=2)In [10]: out.shapeOut[10]: torch.Size([321, 16, 14, 14]) æ± åŒ–å±‚ä¸é‡‡æ · ä¸‹é‡‡æ ·ï¼ˆDownsampleï¼‰ å°±æ˜¯å°†ä¸‹é¢çš„è¿™ä¸ªå¤§çŸ©é˜µå˜æˆä¸Šé¢çš„é‚£ä¸ªå°çŸ©é˜µï¼Œå…¶å®ä¸‹é‡‡æ ·å’Œæ˜¯ç¼©å°å›¾ç‰‡æœ‰ç‚¹åƒ Max Pooling Max Poolingå’Œä¸‹é‡‡æ ·ç±»ä¼¼ï¼Œä½†æ˜¯æ˜¯æ¯æ¬¡è§‚å¯Ÿä¸€ä¸ªåŒºåŸŸåå–è¯¥åŒºåŸŸå€¼æœ€å¤§çš„å€¼ä¸ºè¯¥åŒºåŸŸçš„é‡‡æ ·å€¼ ç±»ä¼¼çš„è¿˜æœ‰AvgPooling PyTorch å®ç° PyTorchåŒæ ·æä¾›ä¸¤ç§ç±»å‹çš„APIï¼Œè¿™é‡Œæ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯nn.MaxPool2då’Œnn.AvgPool2då’Œavg_pool2då’Œmax_pool2d 123456789101112131415161718In [3]: import torch.nn as nnIn [4]: x=torch.rand(123,16,14,14)In [5]: layer=nn.MaxPool2d(2,stride=2)In [6]: out=layer(x)In [7]: out.shapeOut[7]: torch.Size([123, 16, 7, 7])In [8]: layer=nn.AvgPool2d(2,stride=2)In [9]: out=layer(x)In [10]: out.shapeOut[10]: torch.Size([123, 16, 7, 7])In [11]: import torch.nn.functional as FIn [12]: out=F.max_pool2d(x,2,stride=2)In [13]: out.shapeOut[13]: torch.Size([123, 16, 7, 7])In [14]: out=F.avg_pool2d(x,2,stride=2)In [15]: out.shapeOut[15]: torch.Size([123, 16, 7, 7]) ä¸Šé‡‡æ ·ï¼ˆUpsampleï¼‰ å°±æ˜¯å°†ä¸Šé¢çš„è¿™ä¸ªå°çŸ©é˜µå˜æˆä¸‹é¢çš„é‚£ä¸ªå¤§çŸ©é˜µï¼Œç›¸å½“äºå›¾ç‰‡çš„æ”¾å¤§ï¼Œå’Œä¸‹é‡‡æ ·æ­£å¥½ç›¸å PyTorch å®ç° ä¸Šé‡‡æ ·æ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯interpolateå‡½æ•° 123456789101112131415161718192021222324252627282930313233In [3]: import torch.nn.functional as FIn [4]: x=torch.rand(1,1,3,3)In [5]: xOut[5]: tensor([[[[0.0565, 0.2834, 0.3705], [0.4337, 0.8775, 0.8109], [0.8081, 0.8048, 0.3552]]]])In [6]: out=F.interpolate(x,scale_factor=2,mode=&#x27;nearest&#x27;)In [7]: outOut[7]: tensor([[[[0.0565, 0.0565, 0.2834, 0.2834, 0.3705, 0.3705], [0.0565, 0.0565, 0.2834, 0.2834, 0.3705, 0.3705], [0.4337, 0.4337, 0.8775, 0.8775, 0.8109, 0.8109], [0.4337, 0.4337, 0.8775, 0.8775, 0.8109, 0.8109], [0.8081, 0.8081, 0.8048, 0.8048, 0.3552, 0.3552], [0.8081, 0.8081, 0.8048, 0.8048, 0.3552, 0.3552]]]])In [8]: out.shapeOut[8]: torch.Size([1, 1, 6, 6])In [9]: out=F.interpolate(x,scale_factor=3,mode=&#x27;nearest&#x27;)In [10]: outOut[10]: tensor([[[[0.0565, 0.0565, 0.0565, 0.2834, 0.2834, 0.2834, 0.3705, 0.3705, 0.3705], [0.0565, 0.0565, 0.0565, 0.2834, 0.2834, 0.2834, 0.3705, 0.3705, 0.3705], [0.0565, 0.0565, 0.0565, 0.2834, 0.2834, 0.2834, 0.3705, 0.3705, 0.3705], [0.4337, 0.4337, 0.4337, 0.8775, 0.8775, 0.8775, 0.8109, 0.8109, 0.8109], [0.4337, 0.4337, 0.4337, 0.8775, 0.8775, 0.8775, 0.8109, 0.8109, 0.8109], [0.4337, 0.4337, 0.4337, 0.8775, 0.8775, 0.8775, 0.8109, 0.8109, 0.8109], [0.8081, 0.8081, 0.8081, 0.8048, 0.8048, 0.8048, 0.3552, 0.3552, 0.3552], [0.8081, 0.8081, 0.8081, 0.8048, 0.8048, 0.8048, 0.3552, 0.3552, 0.3552], [0.8081, 0.8081, 0.8081, 0.8048, 0.8048, 0.8048, 0.3552, 0.3552, 0.3552]]]])In [11]: out.shapeOut[11]: torch.Size([1, 1, 9, 9]) ReLU å·ç§¯ç¥ç»ç½‘ç»œçš„ReLUå‡½æ•°å’Œä¹‹å‰å…¨è¿æ¥ç¥ç»ç½‘ç»œæ‰€è¯´çš„ReLUå‡½æ•°ä¸€æ ·ï¼Œåœ¨è¿™é‡Œæ˜¯è¢«ç”¨äºå»é™¤å“åº”è¿‡å°çš„ç‚¹ã€‚ PyTorchå®ç° å’ŒåŸæ¥å…¨è¿æ¥ç¥ç»ç½‘ç»œä½¿ç”¨çš„å‡½æ•°ä¸€æ¨¡ä¸€æ · 1234567891011In [3]: import torch.nn as nnIn [4]: import torch.nn.functional as FIn [5]: x=torch.rand(1,16,7,7)In [6]: layer=nn.ReLU(inplace=True)In [7]: out=layer(x)In [8]: out.shapeOut[8]: torch.Size([1, 16, 7, 7])In [9]: out=F.relu(x)In [10]: out.shapeOut[10]: torch.Size([1, 16, 7, 7]) Batch-Normï¼ˆå½’ä¸€åŒ–ï¼‰ normå…¶å®å½’ä¸€åŒ–å°±æ˜¯ç‰¹å¾ç¼©æ”¾ï¼ˆfeature scalingï¼‰ï¼Œä¸€èˆ¬æƒ…å†µæˆ‘ä»¬å°†ç‰¹å¾ç¼©æ”¾æˆä»¥0ä¸ºå‡å€¼1ä¸ºæ–¹å·®çš„æƒ…å†µã€‚ Batch normåœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­æ˜¯æŒ‡ï¼Œå¯¹æ‰€æœ‰æ ·æœ¬çš„ç›¸åŒå±‚è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ã€‚ Î³,Î²\\gamma,\\betaÎ³,Î²æ˜¯è¦å‚ä¸åå‘ä¼ æ’­çš„ï¼ŒÎ¼,Î±\\mu,\\alphaÎ¼,Î±æ˜¯ä¸å‚ä¸åå‘ä¼ æ’­çš„ï¼Œæ˜¯è¿è¡Œä¸­ç»Ÿè®¡å‡ºæ¥çš„æ•°æ®ã€‚å½“å‰Î¼,Î±\\mu,\\alphaÎ¼,Î±çš„è®¡ç®—ä¹Ÿå’Œä¸Šä¸€æ¬¡Î¼,Î±\\mu,\\alphaÎ¼,Î±çš„å€¼æœ‰å…³ï¼ˆæŒ‡æ•°åŠ æƒå¹³å‡ï¼‰ PyTorch å®ç° ä¸‹é¢å®ç°ä¸€ä¸ªå…¨è¿æ¥å±‚çš„Batchnormï¼Œæ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯torch.nn.BatchNorm1d,è¾“å…¥å‚æ•°è¡¨ç¤ºæœ‰å¤šå°‘ä¸ªç‰¹å¾ï¼Œåœ¨ä¸‹é¢çš„ä¾‹å­ä¸­æ˜¯æœ‰16ä¸ªç‰¹å¾ 1234567891011121314In [3]: x=torch.rand(100,16)+0.5In [4]: layer=torch.nn.BatchNorm1d(16)In [5]: layer.running_mean,layer.running_varOut[5]: (tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))In [6]: out=layer(x)In [7]: layer.running_mean,layer.running_varOut[7]: (tensor([0.0961, 0.0963, 0.1018, 0.1019, 0.1005, 0.1021, 0.1000, 0.1006, 0.0965, 0.1005, 0.1054, 0.0996, 0.0940, 0.1024, 0.0938, 0.1022]), tensor([0.9089, 0.9086, 0.9073, 0.9105, 0.9075, 0.9087, 0.9068, 0.9079, 0.9096, 0.9084, 0.9087, 0.9086, 0.9073, 0.9090, 0.9072, 0.9097])) running_mean,running_varç»Ÿè®¡çš„æ˜¯å½“å‰è¾“å…¥çš„æ•°æ®çš„å‡å€¼å’Œæ–¹å·®çš„ å¯ä»¥å‘ç°running_meanä¸€å¼€å§‹å¹¶æ²¡æœ‰ç›´æ¥åˆ°çœŸå®æ•°æ®çš„å‡å€¼ï¼Œè¿™å°±æ˜¯å› ä¸ºæ¯ä¸€æ¬¡è®¡ç®—çš„å‡å€¼å’Œå‰ä¸€æ¬¡çš„å‡å€¼æ˜¯æœ‰å…³ç³»çš„ç¼˜æ•…ã€‚æ‰€ä»¥å½“æˆ‘ä»¬è¿™æ ·è®¡ç®—å¤šæ¬¡årunning_meanæ‰ä¼šé€æ¸æ¥è¿‘çœŸå®çš„å‡å€¼ï¼ˆè§ä¸‹é¢çš„ä»£ç ï¼‰ 123456789101112In [3]: x=torch.randn(100,16)+0.5In [4]: layer=torch.nn.BatchNorm1d(16) In [5]: for i in range(100): out=layer(x)In [6]: layer.running_meanOut[6]: tensor([0.5601, 0.4520, 0.2556, 0.4875, 0.4371, 0.3810, 0.4296, 0.4426, 0.5163, 0.5468, 0.4442, 0.3907, 0.4959, 0.5350, 0.5775, 0.3721])In [7]: layer.running_varOut[7]: tensor([0.8751, 0.9497, 0.8256, 0.9304, 0.9371, 0.8656, 0.8312, 0.9728, 0.9176, 0.9641, 1.2020, 0.8723, 1.3406, 0.8414, 0.9326, 0.9007]) ä¸‹é¢æˆ‘ä»¬è¿›ä¸€æ­¥æ¥çœ‹çœ‹BatchNormå¯¹äº2dçš„æ•°æ®æ˜¯å¦‚ä½•è¿›è¡Œæ“ä½œçš„ï¼Œè¿™é‡Œæ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯BatchNorm2dï¼Œå‚æ•°ä»£è¡¨çš„å«ä¹‰æ˜¯æœ‰å¤šå°‘ä¸ªé€šé“ã€‚ 123456789101112131415161718192021222324252627In [3]: import torch.nn as nnIn [4]: x=torch.randn(3,16,7,7)In [5]: layer=nn.BatchNorm2d(16)In [6]: out=layer(x)In [7]: out.shapeOut[7]: torch.Size([3, 16, 7, 7])In [8]: layer.weightOut[8]: Parameter containing:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)In [9]: layer.biasOut[9]: Parameter containing:tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)In [10]: layer.running_meanOut[10]: tensor([-3.1731e-03, -1.3501e-03, -2.2491e-03, 9.6934e-05, -2.5191e-03, -4.5400e-03, -1.0107e-02, 1.9353e-03, -1.2692e-02, 8.8569e-03, 9.0268e-04, -1.6005e-03, -8.5016e-03, -9.6128e-03, 1.5821e-03, 1.9608e-02])In [11]: layer.running_varOut[11]: tensor([1.0157, 0.9935, 0.9906, 1.0245, 1.0056, 1.0123, 1.0102, 1.0013, 0.9842, 0.9849, 0.9979, 0.9973, 1.0035, 0.9945, 0.9796, 1.0021]) `layer.weight`ä»£è¡¨çš„æ˜¯ä¸Šé¢åŸç†å›¾ä¸­çš„$\\gamma$,`layer.bias`ä»£è¡¨çš„æ˜¯ä¸Šé¢åŸç†å›¾ä¸­çš„$\\beta$ï¼Œ`layer.running_mean`ä»£è¡¨çš„æ˜¯$\\mu$ï¼Œ`layer.running_var`ä»£è¡¨çš„æ˜¯Ïƒ\\sigmaÏƒ ä½¿ç”¨varså¯ä»¥æ‰“å‡ºå±‚çš„æ‰€æœ‰ä¿¡æ¯ã€‚ 1234567891011121314151617181920212223242526272829303132In [12]: vars(layer)Out[12]: &#123;&#x27;training&#x27;: True, &#x27;_parameters&#x27;: OrderedDict([(&#x27;weight&#x27;, Parameter containing: tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)), (&#x27;bias&#x27;, Parameter containing: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))]), &#x27;_buffers&#x27;: OrderedDict([(&#x27;running_mean&#x27;, tensor([-3.1731e-03, -1.3501e-03, -2.2491e-03, 9.6934e-05, -2.5191e-03, -4.5400e-03, -1.0107e-02, 1.9353e-03, -1.2692e-02, 8.8569e-03, 9.0268e-04, -1.6005e-03, -8.5016e-03, -9.6128e-03, 1.5821e-03, 1.9608e-02])), (&#x27;running_var&#x27;, tensor([1.0157, 0.9935, 0.9906, 1.0245, 1.0056, 1.0123, 1.0102, 1.0013, 0.9842, 0.9849, 0.9979, 0.9973, 1.0035, 0.9945, 0.9796, 1.0021])), (&#x27;num_batches_tracked&#x27;, tensor(1))]), &#x27;_non_persistent_buffers_set&#x27;: set(), &#x27;_backward_hooks&#x27;: OrderedDict(), &#x27;_is_full_backward_hook&#x27;: None, &#x27;_forward_hooks&#x27;: OrderedDict(), &#x27;_forward_pre_hooks&#x27;: OrderedDict(), &#x27;_state_dict_hooks&#x27;: OrderedDict(), &#x27;_load_state_dict_pre_hooks&#x27;: OrderedDict(), &#x27;_modules&#x27;: OrderedDict(), &#x27;num_features&#x27;: 16, &#x27;eps&#x27;: 1e-05, &#x27;momentum&#x27;: 0.1, &#x27;affine&#x27;: True, &#x27;track_running_stats&#x27;: True&#125; å› ä¸ºBatchnormå±‚åœ¨è®­ç»ƒæ¨¡å¼å’Œæµ‹è¯•æ¨¡å¼ä¸‹çš„è¡Œä¸ºæœ‰æ‰€å·®åˆ«ï¼Œæ‰€ä»¥åœ¨è¿›è¡Œæµ‹è¯•æ—¶ï¼Œè¦ä½¿ç”¨evalæŠŠBatchnormå±‚çš„çŠ¶æ€è½¬æ¢è¿‡æ¥ï¼ˆä»è®­ç»ƒæ¨¡å¼è½¬æ¢ä¸ºæµ‹è¯•æ¨¡å¼ï¼‰ã€‚å› ä¸ºtestçš„æ—¶å€™åªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œæ‰€ä»¥Î¼,Ïƒ2\\mu,\\sigma^2Î¼,Ïƒ2æ˜¯æ— æ³•è¢«ç»Ÿè®¡çš„ã€‚ä¸€èˆ¬è¿™ä¸ªæ—¶å€™è¿™ä¸¤ä¸ªå€¼ä¼šè¢«èµ‹å€¼ä¸ºå…¨å±€çš„å€¼ã€‚ åˆç†ä½¿ç”¨BatchNormå¯ä»¥åŠ å¿«æ”¶æ•›é€Ÿåº¦å¹¶ä¸”æé«˜å‡†ç¡®åº¦ï¼Œè€Œä¸”ä½¿ç”¨äº†ä»¥åæ¨¡å‹çš„é²æ£’æ€§ä¼šæå‡ï¼ˆæ¨¡å‹æ›´åŠ ç¨³å®šï¼‰ ç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œ å…¶ä¸­å‡ ä¸ªè½¬æŠ˜ç‚¹ AlexNet(2012) ZFNet(2013) VGG(2014) GoogLeNet(2014) ResNetâ€» LeNet-5 LeNetç”±Yann Lecun æå‡ºï¼Œæ˜¯ä¸€ç§ç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œæ˜¯ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œçš„èµ·æºä¹‹ä¸€ã€‚Yannå°†è¯¥ç½‘ç»œç”¨äºé‚®å±€çš„é‚®æ”¿çš„é‚®æ”¿ç¼–ç è¯†åˆ«ï¼Œæœ‰ç€è‰¯å¥½çš„å­¦ä¹ å’Œè¯†åˆ«èƒ½åŠ›ã€‚LeNetåˆç§°LeNet-5,å…·æœ‰ä¸€ä¸ªè¾“å…¥å±‚ï¼Œä¸¤ä¸ªå·ç§¯å±‚ï¼Œä¸¤ä¸ªæ± åŒ–å±‚ï¼Œ3ä¸ªå…¨è¿æ¥å±‚ï¼ˆå…¶ä¸­æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ä¸ºè¾“å‡ºå±‚ï¼‰ã€‚ LeNet-5æ˜¯ä¸€ç§ç»å…¸çš„å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼Œäº1998å¹´æŠ•å…¥å®é™…ä½¿ç”¨ä¸­ã€‚è¯¥ç½‘ç»œæœ€æ—©åº”ç”¨äºæ‰‹å†™ä½“å­—ç¬¦è¯†åˆ«åº”ç”¨ä¸­ã€‚æ™®éè®¤ä¸ºï¼Œå·ç§¯ç¥ç»ç½‘ç»œçš„å‡ºç°å¼€å§‹äºLeCun ç­‰æå‡ºçš„LeNet ç½‘ç»œï¼ˆLeCun et al., 1998ï¼‰ï¼Œå¯ä»¥è¯´LeCun ç­‰æ˜¯CNN çš„ç¼”é€ è€…ï¼Œè€ŒLeNet-5 åˆ™æ˜¯LeCun ç­‰åˆ›é€ çš„CNN ç»å…¸ä¹‹ä½œ ã€‚ ç½‘ç»œç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…ˆæ˜¯ä¸€ä¸ªå·ç§¯å±‚ï¼Œç„¶åæ˜¯ä¸€ä¸ªä¸‹é‡‡æ ·ï¼Œç„¶ååˆæ˜¯ä¸€ä¸ªå·ç§¯å±‚ï¼Œç„¶ååˆæ˜¯ä¸€ä¸ªä¸‹é‡‡æ ·ï¼Œæœ€åä¸‰ä¸ªå°±æ˜¯ä¸‰ä¸ªå…¨è¿æ¥å±‚ã€‚ AlexNet AlexNetæ˜¯2012å¹´ImageNetç«èµ›å† å†›è·å¾—è€…Hintonå’Œä»–çš„å­¦ç”ŸAlex Krizhevskyè®¾è®¡çš„ã€‚ä¹Ÿæ˜¯åœ¨é‚£å¹´ä¹‹åï¼Œæ›´å¤šçš„æ›´æ·±çš„ç¥ç»ç½‘ç»œè¢«æå‡ºï¼Œæ¯”å¦‚ä¼˜ç§€çš„VGGï¼ŒGoogLeNetã€‚ è¿™å¯¹äºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ åˆ†ç±»ç®—æ³•è€Œè¨€ï¼Œå·²ç»ç›¸å½“çš„å‡ºè‰²ã€‚ AlexNetä¸­åŒ…å«äº†å‡ ä¸ªæ¯”è¾ƒæ–°çš„æŠ€æœ¯ç‚¹ï¼Œä¹Ÿé¦–æ¬¡åœ¨CNNä¸­æˆåŠŸåº”ç”¨äº†ReLUã€Dropoutå’ŒLRNç­‰Trickã€‚åŒæ—¶AlexNetä¹Ÿä½¿ç”¨äº†GPUè¿›è¡Œè¿ç®—åŠ é€Ÿã€‚ AlexNetå°†LeNetçš„æ€æƒ³å‘æ‰¬å…‰å¤§ï¼ŒæŠŠCNNçš„åŸºæœ¬åŸç†åº”ç”¨åˆ°äº†å¾ˆæ·±å¾ˆå®½çš„ç½‘ç»œä¸­ã€‚AlexNetä¸»è¦ä½¿ç”¨åˆ°çš„æ–°æŠ€æœ¯ç‚¹å¦‚ä¸‹ï¼š ï¼ˆ1ï¼‰æˆåŠŸä½¿ç”¨ReLUä½œä¸ºCNNçš„æ¿€æ´»å‡½æ•°ï¼Œå¹¶éªŒè¯å…¶æ•ˆæœåœ¨è¾ƒæ·±çš„ç½‘ç»œè¶…è¿‡äº†Sigmoidï¼ŒæˆåŠŸè§£å†³äº†Sigmoidåœ¨ç½‘ç»œè¾ƒæ·±æ—¶çš„æ¢¯åº¦å¼¥æ•£é—®é¢˜ã€‚è™½ç„¶ReLUæ¿€æ´»å‡½æ•°åœ¨å¾ˆä¹…ä¹‹å‰å°±è¢«æå‡ºäº†ï¼Œä½†æ˜¯ç›´åˆ°AlexNetçš„å‡ºç°æ‰å°†å…¶å‘æ‰¬å…‰å¤§ã€‚ ï¼ˆ2ï¼‰è®­ç»ƒæ—¶ä½¿ç”¨Dropoutéšæœºå¿½ç•¥ä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œä»¥é¿å…æ¨¡å‹è¿‡æ‹Ÿåˆã€‚Dropoutè™½æœ‰å•ç‹¬çš„è®ºæ–‡è®ºè¿°ï¼Œä½†æ˜¯AlexNetå°†å…¶å®ç”¨åŒ–ï¼Œé€šè¿‡å®è·µè¯å®äº†å®ƒçš„æ•ˆæœã€‚åœ¨AlexNetä¸­ä¸»è¦æ˜¯æœ€åå‡ ä¸ªå…¨è¿æ¥å±‚ä½¿ç”¨äº†Dropoutã€‚ ï¼ˆ3ï¼‰åœ¨CNNä¸­ä½¿ç”¨é‡å çš„æœ€å¤§æ± åŒ–ã€‚æ­¤å‰CNNä¸­æ™®éä½¿ç”¨å¹³å‡æ± åŒ–ï¼ŒAlexNetå…¨éƒ¨ä½¿ç”¨æœ€å¤§æ± åŒ–ï¼Œé¿å…å¹³å‡æ± åŒ–çš„æ¨¡ç³ŠåŒ–æ•ˆæœã€‚å¹¶ä¸”AlexNetä¸­æå‡ºè®©æ­¥é•¿æ¯”æ± åŒ–æ ¸çš„å°ºå¯¸å°ï¼Œè¿™æ ·æ± åŒ–å±‚çš„è¾“å‡ºä¹‹é—´ä¼šæœ‰é‡å å’Œè¦†ç›–ï¼Œæå‡äº†ç‰¹å¾çš„ä¸°å¯Œæ€§ã€‚ ï¼ˆ4ï¼‰æå‡ºäº†LRNå±‚ï¼Œå¯¹å±€éƒ¨ç¥ç»å…ƒçš„æ´»åŠ¨åˆ›å»ºç«äº‰æœºåˆ¶ï¼Œä½¿å¾—å…¶ä¸­å“åº”æ¯”è¾ƒå¤§çš„å€¼å˜å¾—ç›¸å¯¹æ›´å¤§ï¼Œå¹¶æŠ‘åˆ¶å…¶ä»–åé¦ˆè¾ƒå°çš„ç¥ç»å…ƒï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ ï¼ˆ5ï¼‰ä½¿ç”¨CUDAåŠ é€Ÿæ·±åº¦å·ç§¯ç½‘ç»œçš„è®­ç»ƒï¼Œåˆ©ç”¨GPUå¼ºå¤§çš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ï¼Œå¤„ç†ç¥ç»ç½‘ç»œè®­ç»ƒæ—¶å¤§é‡çš„çŸ©é˜µè¿ç®—ã€‚AlexNetä½¿ç”¨äº†ä¸¤å—GTXâ€‚580â€‚GPUè¿›è¡Œè®­ç»ƒï¼Œå•ä¸ªGTXâ€‚580åªæœ‰3GBæ˜¾å­˜ï¼Œè¿™é™åˆ¶äº†å¯è®­ç»ƒçš„ç½‘ç»œçš„æœ€å¤§è§„æ¨¡ã€‚å› æ­¤ä½œè€…å°†AlexNetåˆ†å¸ƒåœ¨ä¸¤ä¸ªGPUä¸Šï¼Œåœ¨æ¯ä¸ªGPUçš„æ˜¾å­˜ä¸­å‚¨å­˜ä¸€åŠçš„ç¥ç»å…ƒçš„å‚æ•°ã€‚å› ä¸ºGPUä¹‹é—´é€šä¿¡æ–¹ä¾¿ï¼Œå¯ä»¥äº’ç›¸è®¿é—®æ˜¾å­˜ï¼Œè€Œä¸éœ€è¦é€šè¿‡ä¸»æœºå†…å­˜ï¼Œæ‰€ä»¥åŒæ—¶ä½¿ç”¨å¤šå—GPUä¹Ÿæ˜¯éå¸¸é«˜æ•ˆçš„ã€‚åŒæ—¶ï¼ŒAlexNetçš„è®¾è®¡è®©GPUä¹‹é—´çš„é€šä¿¡åªåœ¨ç½‘ç»œçš„æŸäº›å±‚è¿›è¡Œï¼Œæ§åˆ¶äº†é€šä¿¡çš„æ€§èƒ½æŸè€—ã€‚ ï¼ˆ6ï¼‰æ•°æ®å¢å¼ºï¼Œéšæœºåœ°ä»256256çš„åŸå§‹å›¾åƒä¸­æˆªå–224224å¤§å°çš„åŒºåŸŸï¼ˆä»¥åŠæ°´å¹³ç¿»è½¬çš„é•œåƒï¼‰ï¼Œç›¸å½“äºå¢åŠ äº†2*(256-224)^2=2048å€çš„æ•°æ®é‡ã€‚å¦‚æœæ²¡æœ‰æ•°æ®å¢å¼ºï¼Œä»…é åŸå§‹çš„æ•°æ®é‡ï¼Œå‚æ•°ä¼—å¤šçš„CNNä¼šé™·å…¥è¿‡æ‹Ÿåˆä¸­ï¼Œä½¿ç”¨äº†æ•°æ®å¢å¼ºåå¯ä»¥å¤§å¤§å‡è½»è¿‡æ‹Ÿåˆï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚è¿›è¡Œé¢„æµ‹æ—¶ï¼Œåˆ™æ˜¯å–å›¾ç‰‡çš„å››ä¸ªè§’åŠ ä¸­é—´å…±5ä¸ªä½ç½®ï¼Œå¹¶è¿›è¡Œå·¦å³ç¿»è½¬ï¼Œä¸€å…±è·å¾—10å¼ å›¾ç‰‡ï¼Œå¯¹ä»–ä»¬è¿›è¡Œé¢„æµ‹å¹¶å¯¹10æ¬¡ç»“æœæ±‚å‡å€¼ã€‚åŒæ—¶ï¼ŒAlexNetè®ºæ–‡ä¸­æåˆ°äº†ä¼šå¯¹å›¾åƒçš„RGBæ•°æ®è¿›è¡ŒPCAå¤„ç†ï¼Œå¹¶å¯¹ä¸»æˆåˆ†åšä¸€ä¸ªæ ‡å‡†å·®ä¸º0.1çš„é«˜æ–¯æ‰°åŠ¨ï¼Œå¢åŠ ä¸€äº›å™ªå£°ï¼Œè¿™ä¸ªTrickå¯ä»¥è®©é”™è¯¯ç‡å†ä¸‹é™1%ã€‚ æ¨¡å‹ç‰¹ç‚¹ ä½¿ç”¨äº†ReLUæ¿€æ´»å‡½æ•° ä½¿ç”¨äº†æœ€å¤§æ± åŒ–å±‚ æ ‡å‡†åŒ– Dropout VGG VGGæ¨¡å‹æ˜¯2014å¹´ILSVRCç«èµ›çš„ç¬¬äºŒåï¼Œç¬¬ä¸€åæ˜¯GoogLeNetã€‚ä½†æ˜¯VGGæ¨¡å‹åœ¨å¤šä¸ªè¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­çš„è¡¨ç°è¦ä¼˜äºGoogLeNetã€‚è€Œä¸”ï¼Œä»å›¾åƒä¸­æå–CNNç‰¹å¾ï¼ŒVGGæ¨¡å‹æ˜¯é¦–é€‰ç®—æ³•ã€‚å®ƒçš„ç¼ºç‚¹åœ¨äºï¼Œå‚æ•°é‡æœ‰140Mä¹‹å¤šï¼Œéœ€è¦æ›´å¤§çš„å­˜å‚¨ç©ºé—´ã€‚ä½†æ˜¯è¿™ä¸ªæ¨¡å‹å¾ˆæœ‰ç ”ç©¶ä»·å€¼ã€‚ æ¨¡å‹çš„åç§°â€”â€”â€œVGGâ€ä»£è¡¨äº†ç‰›æ´¥å¤§å­¦çš„Oxford Visual Geometry Groupï¼Œè¯¥å°ç»„éš¶å±äº1985å¹´æˆç«‹çš„Robotics Research Groupï¼Œè¯¥Groupç ”ç©¶èŒƒå›´åŒ…æ‹¬äº†æœºå™¨å­¦ä¹ åˆ°ç§»åŠ¨æœºå™¨äººã€‚ä¸‹é¢æ˜¯ä¸€æ®µæ¥è‡ªç½‘ç»œå¯¹åŒå¹´GoogLeNetå’ŒVGGçš„æè¿°ï¼š â€œGoogLeNetå’ŒVGGçš„Classificationæ¨¡å‹ä»åŸç†ä¸Šå¹¶æ²¡æœ‰ä¸ä¼ ç»Ÿçš„CNNæ¨¡å‹æœ‰å¤ªå¤§ä¸åŒã€‚å¤§å®¶æ‰€ç”¨çš„Pipelineä¹Ÿéƒ½æ˜¯ï¼šè®­ç»ƒæ—¶å€™ï¼šå„ç§æ•°æ®Augmentationï¼ˆå‰ªè£ï¼Œä¸åŒå¤§å°ï¼Œè°ƒäº®åº¦ï¼Œé¥±å’Œåº¦ï¼Œå¯¹æ¯”åº¦ï¼Œåè‰²ï¼‰ï¼Œå‰ªè£é€å…¥CNNæ¨¡å‹ï¼ŒSoftmaxï¼ŒBackpropã€‚æµ‹è¯•æ—¶å€™ï¼šå°½é‡æŠŠæµ‹è¯•æ•°æ®åˆå„ç§Augmentingï¼ˆå‰ªè£ï¼Œä¸åŒå¤§å°ï¼‰ï¼ŒæŠŠæµ‹è¯•æ•°æ®å„ç§Augmentingååœ¨è®­ç»ƒçš„ä¸åŒæ¨¡å‹ä¸Šçš„ç»“æœå†ç»§ç»­Averagingå‡ºæœ€åçš„ç»“æœã€‚â€ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨VGGNetçš„6ç»„å®éªŒä¸­ï¼Œåé¢çš„4ä¸ªç½‘ç»œå‡ä½¿ç”¨äº†pre-trained model Açš„æŸäº›å±‚æ¥åšå‚æ•°åˆå§‹åŒ–ã€‚è™½ç„¶æå‡ºè€…æ²¡æœ‰æè¯¥æ–¹æ³•å¸¦æ¥çš„æ€§èƒ½å¢ç›Šã€‚å…ˆæ¥çœ‹çœ‹VGGçš„ç‰¹ç‚¹ï¼š å°å·ç§¯æ ¸ã€‚ä½œè€…å°†å·ç§¯æ ¸å…¨éƒ¨æ›¿æ¢ä¸º3x3ï¼ˆæå°‘ç”¨äº†1x1ï¼‰ï¼› å°æ± åŒ–æ ¸ã€‚ç›¸æ¯”AlexNetçš„3x3çš„æ± åŒ–æ ¸ï¼ŒVGGå…¨éƒ¨ä¸º2x2çš„æ± åŒ–æ ¸ï¼› å±‚æ•°æ›´æ·±ç‰¹å¾å›¾æ›´å®½ã€‚åŸºäºå‰ä¸¤ç‚¹å¤–ï¼Œç”±äºå·ç§¯æ ¸ä¸“æ³¨äºæ‰©å¤§é€šé“æ•°ã€æ± åŒ–ä¸“æ³¨äºç¼©å°å®½å’Œé«˜ï¼Œä½¿å¾—æ¨¡å‹æ¶æ„ä¸Šæ›´æ·±æ›´å®½çš„åŒæ—¶ï¼Œè®¡ç®—é‡çš„å¢åŠ æ”¾ç¼“ï¼› å…¨è¿æ¥è½¬å·ç§¯ã€‚ç½‘ç»œæµ‹è¯•é˜¶æ®µå°†è®­ç»ƒé˜¶æ®µçš„ä¸‰ä¸ªå…¨è¿æ¥æ›¿æ¢ä¸ºä¸‰ä¸ªå·ç§¯ï¼Œæµ‹è¯•é‡ç”¨è®­ç»ƒæ—¶çš„å‚æ•°ï¼Œä½¿å¾—æµ‹è¯•å¾—åˆ°çš„å…¨å·ç§¯ç½‘ç»œå› ä¸ºæ²¡æœ‰å…¨è¿æ¥çš„é™åˆ¶ï¼Œå› è€Œå¯ä»¥æ¥æ”¶ä»»æ„å®½æˆ–é«˜ä¸ºçš„è¾“å…¥ã€‚ GoogLeNet GoogLeNetæ˜¯2014å¹´Christian Szegedyæå‡ºçš„ä¸€ç§å…¨æ–°çš„æ·±åº¦å­¦ä¹ ç»“æ„ï¼Œåœ¨è¿™ä¹‹å‰çš„AlexNetã€VGGç­‰ç»“æ„éƒ½æ˜¯é€šè¿‡å¢å¤§ç½‘ç»œçš„æ·±åº¦ï¼ˆå±‚æ•°ï¼‰æ¥è·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæœï¼Œä½†å±‚æ•°çš„å¢åŠ ä¼šå¸¦æ¥å¾ˆå¤šè´Ÿä½œç”¨ï¼Œæ¯”å¦‚overfitã€æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸ç­‰ã€‚inceptionçš„æå‡ºåˆ™ä»å¦ä¸€ç§è§’åº¦æ¥æå‡è®­ç»ƒç»“æœï¼šèƒ½æ›´é«˜æ•ˆçš„åˆ©ç”¨è®¡ç®—èµ„æºï¼Œåœ¨ç›¸åŒçš„è®¡ç®—é‡ä¸‹èƒ½æå–åˆ°æ›´å¤šçš„ç‰¹å¾ï¼Œä»è€Œæå‡è®­ç»ƒç»“æœã€‚ æ¨¡å‹ç‰¹ç‚¹ ä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸ï¼Œä»è€Œæ„Ÿå—ä¸åŒèŒƒå›´çš„è§†é‡ ResNetï¼ˆæ·±åº¦æ®‹å·®ç½‘ç»œï¼‰â€» è¿™é‡Œå•ç‹¬å°†ResNetæ–°å¼€ä¸€ä¸ªç« èŠ‚ï¼Œå·²ç»è¡¨æ˜äº†ä»–åœ¨è¿™ä¸€é¢†åŸŸçš„é‡è¦æ€§ã€‚é¦–å…ˆæ¥çœ‹çœ‹ResNetåœ¨2015å¹´çš„æˆ˜ç»©ï¼š ä»ç»éªŒæ¥çœ‹ï¼Œç½‘ç»œçš„æ·±åº¦å¯¹æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ï¼Œå½“å¢åŠ ç½‘ç»œå±‚æ•°åï¼Œç½‘ç»œå¯ä»¥è¿›è¡Œæ›´åŠ å¤æ‚çš„ç‰¹å¾æ¨¡å¼çš„æå–ï¼Œæ‰€ä»¥å½“æ¨¡å‹æ›´æ·±æ—¶ç†è®ºä¸Šå¯ä»¥å–å¾—æ›´å¥½çš„ç»“æœï¼Œä½†æ˜¯æ›´æ·±çš„ç½‘ç»œå…¶æ€§èƒ½ä¸€å®šä¼šæ›´å¥½å—ï¼Ÿå®éªŒå‘ç°æ·±åº¦ç½‘ç»œå‡ºç°äº†é€€åŒ–é—®é¢˜ï¼ˆDegradation problemï¼‰ï¼šç½‘ç»œæ·±åº¦å¢åŠ æ—¶ï¼Œç½‘ç»œå‡†ç¡®åº¦å‡ºç°é¥±å’Œï¼Œç”šè‡³å‡ºç°ä¸‹é™ã€‚56å±‚çš„ç½‘ç»œæ¯”20å±‚ç½‘ç»œæ•ˆæœè¿˜è¦å·®ã€‚è¿™ä¸ä¼šæ˜¯è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå› ä¸º56å±‚ç½‘ç»œçš„è®­ç»ƒè¯¯å·®åŒæ ·é«˜ã€‚æˆ‘ä»¬çŸ¥é“æ·±å±‚ç½‘ç»œå­˜åœ¨ç€æ¢¯åº¦æ¶ˆå¤±æˆ–è€…çˆ†ç‚¸çš„é—®é¢˜ï¼Œè¿™ä½¿å¾—æ·±åº¦å­¦ä¹ æ¨¡å‹å¾ˆéš¾è®­ç»ƒã€‚ä½†æ˜¯ç°åœ¨å·²ç»å­˜åœ¨ä¸€äº›æŠ€æœ¯æ‰‹æ®µå¦‚BatchNormæ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚å› æ­¤ï¼Œå‡ºç°æ·±åº¦ç½‘ç»œçš„é€€åŒ–é—®é¢˜æ˜¯éå¸¸ä»¤äººè¯§å¼‚çš„ã€‚ä½†æ˜¯ä½•æºæ˜å‘æ˜çš„ResNetæœ‰æ•ˆçš„è§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚ResNetæœ‰æ•ˆè§£å†³äº†æ·±åº¦CNNæ¨¡å‹éš¾è®­ç»ƒçš„é—®é¢˜ï¼ˆç½‘ç»œå¤ªæ·±äº†å®¹æ˜“å‘ç”Ÿæ¢¯åº¦å¼¥æ•£ï¼‰ ResNetæ®‹å·®ç½‘ç»œä¸»è¦æ˜¯é€šè¿‡æ®‹å·®å—ç»„æˆçš„ï¼Œåœ¨æå‡ºæ®‹å·®ç½‘ç»œä¹‹å‰ï¼Œç½‘ç»œç»“æ„æ— æ³•å¾ˆæ·±ï¼Œåœ¨VGGä¸­ï¼Œå·ç§¯ç½‘ç»œè¾¾åˆ°äº†19å±‚ï¼Œåœ¨GoogLeNetä¸­ï¼Œç½‘ç»œè¾¾åˆ°äº†22å±‚ã€‚éšç€ç½‘ç»œå±‚æ•°çš„å¢åŠ ï¼Œç½‘ç»œå‘ç”Ÿäº†é€€åŒ–ï¼ˆdegradationï¼‰çš„ç°è±¡ï¼šéšç€ç½‘ç»œå±‚æ•°çš„å¢å¤šï¼Œè®­ç»ƒé›†lossé€æ¸ä¸‹é™ï¼Œç„¶åè¶‹äºé¥±å’Œï¼Œå½“ä½ å†å¢åŠ ç½‘ç»œæ·±åº¦çš„è¯ï¼Œè®­ç»ƒé›†lossåè€Œä¼šå¢å¤§ã€‚è€Œå¼•å…¥æ®‹å·®å—åï¼Œç½‘ç»œå¯ä»¥è¾¾åˆ°å¾ˆæ·±ï¼Œç½‘ç»œçš„æ•ˆæœä¹Ÿéšä¹‹å˜å¥½ã€‚ è¿™é‡Œæä¾›äº†ä¸€ç§æƒ³æ³•ï¼šæ—¢ç„¶æ·±å±‚ç½‘ç»œç›¸æ¯”äºæµ…å±‚ç½‘ç»œå…·æœ‰é€€åŒ–é—®é¢˜ï¼Œé‚£ä¹ˆæ˜¯å¦å¯ä»¥ä¿ç•™æ·±å±‚ç½‘ç»œçš„æ·±åº¦ï¼Œåˆå¯ä»¥æœ‰æµ…å±‚ç½‘ç»œçš„ä¼˜åŠ¿å»é¿å…é€€åŒ–é—®é¢˜å‘¢ï¼Ÿå¦‚æœå°†æ·±å±‚ç½‘ç»œçš„åé¢è‹¥å¹²å±‚å­¦ä¹ æˆæ’ç­‰æ˜ å°„ h(x)=xh(x)=xh(x)=x ï¼Œé‚£ä¹ˆæ¨¡å‹å°±é€€åŒ–æˆæµ…å±‚ç½‘ç»œã€‚ä½†æ˜¯ç›´æ¥å»å­¦ä¹ è¿™ä¸ªæ’ç­‰æ˜ å°„æ˜¯å¾ˆå›°éš¾çš„ï¼Œé‚£ä¹ˆå°±æ¢ä¸€ç§æ–¹å¼ï¼ŒæŠŠç½‘ç»œè®¾è®¡æˆï¼š H(x)=F(x)+xâ‡’F(x)=H(x)âˆ’xH(x)=F(x)+x \\Rightarrow F(x)=H(x)-x H(x)=F(x)+xâ‡’F(x)=H(x)âˆ’x åªè¦ F(x)=0F(x)=0F(x)=0 å°±æ„æˆäº†ä¸€ä¸ªæ’ç­‰æ˜ å°„ H(x)=xH(x)=xH(x)=x ï¼Œè¿™é‡Œ F(x)F(x)F(x) ä¸ºæ®‹å·®ã€‚ ç›¸å…³èµ„æ–™é“¾æ¥ï¼šæ·±åº¦å­¦ä¹ ä¹‹16â€”â€”æ®‹å·®ç½‘ç»œ(ResNet) PyTorch æ®‹å·®å—å®ç° 12345678910111213141516171819class ResBlk(nn.Module): def __init__(self,ch_in,ch_out): self.conv1=nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1) self.bn1=nn.BatchNorm2d(ch_out) self.conv2=nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1) self.bn2=nn.BatchNorm2d(ch_out) self.extra=nn.Sequential() if ch_out!=ch_in: # å¦‚æœè¾“å…¥è¾“å‡ºé€šé“æ•°é‡ä¸ä¸€æ ·çš„è¯ self.extra!=ch_in: self.extra=nn.Sequential( nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=1), nn.BatchNorm2s(ch_out) ) def forward(self,x): out=F.relu(self.bn1(self.conv1(x))) out=self.bn2(self.conv2(out)) out=self.extra(x)+out return out DenseNet å…¶å®ç›¸å½“äºæ¯ä¸€å±‚éƒ½å’Œå‰é¢æ‰€æœ‰å±‚ä¹‹é—´åˆä¸€ä¸ªshortcut nn.Module PyTorchä¸­çš„nn.Moduleç±»ä¸ºæ‰€æœ‰æˆ‘ä»¬è‡ªå®šä¹‰ç½‘ç»œå±‚çš„ä¸€ä¸ªçˆ¶ç±»ï¼æ‰€ä»¥ä»–éå¸¸çš„é‡è¦ï¼Œä»¥ä¸‹æ˜¯ä»–çš„ä¼˜ç‚¹ æä¾›äº†å¾ˆå¤šçš„æ“ä½œ nn.Linear nn.BatchNorm2d nn.Conv2d etc. æä¾›å®¹å™¨nn.Sequential å¯¹ç½‘ç»œå‚æ•°èƒ½å¤Ÿè¿›è¡Œå¾ˆå¥½çš„ç®¡ç† ä¸‹é¢ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬é‡‡ç”¨çš„æ˜¯ä¸€ä¸ªä¸¤å±‚çš„ç½‘ç»œï¼Œæ‰€ä»¥å‚æ•°æœ‰4ç»„ï¼Œweight0ï¼Œbias0,weight1,bias1 123456789101112131415161718192021In [3]: import torch.nn as nnIn [4]: net=nn.Sequential(nn.Linear(4,2),nn.Linear(2,2))In [5]: dict(net.named_parameters()).items()Out[5]: dict_items([(&#x27;0.weight&#x27;, Parameter containing:tensor([[-0.1411, 0.2698, 0.0457, -0.2939], [-0.3555, -0.3352, -0.3403, 0.4714]], requires_grad=True)), (&#x27;0.bias&#x27;, Parameter containing:tensor([ 0.1076, -0.1325], requires_grad=True)), (&#x27;1.weight&#x27;, Parameter containing:tensor([[ 0.0859, -0.6313], [-0.6823, -0.5285]], requires_grad=True)), (&#x27;1.bias&#x27;, Parameter containing:tensor([ 0.6793, -0.1800], requires_grad=True))])In [6]: list(net.parameters())[0]Out[6]: Parameter containing:tensor([[-0.1411, 0.2698, 0.0457, -0.2939], [-0.3555, -0.3352, -0.3403, 0.4714]], requires_grad=True)In [7]: list(net.parameters())[1]Out[7]: Parameter containing:tensor([ 0.1076, -0.1325], requires_grad=True)In [8]: optimizer=optim.SGD(net.parameters(),lr=1e-3) å¯ä»¥æ¸…æ™°çš„æŸ¥çœ‹ç½‘ç»œç»“æ„ å¯ä»¥å°†ç½‘ç»œæ–¹ä¾¿çš„è½¬ç§»åˆ°GPUä¸Šè¿›è¡ŒåŠ é€Ÿ 123device=torch,device(&#x27;cuda&#x27;)net=Net()net.to(device) å¯ä»¥å¾ˆæ–¹ä¾¿çš„ä¿å­˜å’ŒåŠ è½½ç½‘ç»œçš„ä¸­é—´çŠ¶æ€ è¿™å°±æ–¹ä¾¿æˆ‘ä»¬è¿›è¡Œearly stop 123456789device=torch,device(&#x27;cuda&#x27;)net=Net()net.to(device)net.load_state_dict(torch.load(&#x27;ckpt.mdl&#x27;)) # åŠ è½½æ¨¡å‹# train...torch.save(net.state_dict(),&#x27;ckpt.mdl&#x27;) # ä¿å­˜æ¨¡å‹ æ–¹ä¾¿åˆ‡æ¢ç½‘ç»œçŠ¶æ€ å¯¹äºç½‘ç»œä¸­çš„ä¸€äº›å±‚ï¼Œæ¯”å¦‚BatchNormå±‚ï¼Œä»–åœ¨è®­ç»ƒçŠ¶æ€ä¸‹å’Œæµ‹è¯•çŠ¶æ€ä¸‹çš„è¡Œä¸ºæ˜¯æœ‰ä¸€äº›å·®å¼‚çš„ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ç½‘ç»œä¸­çš„æ¯ä¸€å±‚éƒ½å»æ‰§è¡Œåˆ‡æ¢çŠ¶æ€çš„æ“ä½œæ˜¯éå¸¸éº»çƒ¦çš„ï¼Œä½†æ˜¯nn.Moduleæ”¯æŒå¯¹è‡ªå®šä¹‰ç½‘ç»œæ•´ä½“çŠ¶æ€çš„åˆ‡æ¢ï¼Œå¤§å¤§ç®€åŒ–äº†æ“ä½œã€‚ 12345678910111213device = torch.device(&#x27;cuda&#x27;)net=Net()net.to(device)# trainnet.train()# ...# ...# ...# testnet.eval()# ... æ–¹ä¾¿å®šä¹‰è‡ªå·±çš„ç±» æ¯”å¦‚è¯´PyTorchç°ç›®å‰æš‚æ—¶ä¸æä¾›å°†tensoræ‹å¹³çš„æ“ä½œï¼ˆå±‚ä¹‹é—´ï¼Œä½œç”¨æ˜¯å°†å·ç§¯å±‚è½¬åŒ–ä¸ºå…¨è¿æ¥å±‚ï¼‰ï¼Œå› æ­¤è¿™ä¸ªå±‚éœ€è¦æˆ‘ä»¬è‡ªå·±å»å®ç° 12345class Flatten(nn.Module): def __init__(self): super(Flatten,self).__init__() def forward(self,input): return input.view(input.size(0),-1) ä»¥ä¸Šè¿™ä¸ªç±»ä½¿ç”¨çš„éå¸¸çš„å¹¿æ³› æˆ‘ä»¬ä¹Ÿå¯ä»¥å°è¯•è‡ªå·±å†™ä¸€ä¸ªLinearç±» 123456789101112class MyLinear(nn.Module): def __init__(self,inp,outp): super(MyLinear,self).__init__() # requiers_grad = True self.w = nn.Parameter(torch.randn(outp,inp)) self.b = nn.Parameter(torch.randn(outp)) def forward(self, x): x = x @ self.w.t() + self.b return x æ•°æ®å¢å¼º å…¶å®éå¸¸å¥½ç†è§£ï¼Œæ•°æ®å¢å¼ºè®©æœ‰é™çš„æ•°æ®äº§ç”Ÿæ›´å¤šçš„æ•°æ®ï¼Œå¢åŠ è®­ç»ƒæ ·æœ¬çš„æ•°é‡ä»¥åŠå¤šæ ·æ€§ï¼ˆå™ªå£°æ•°æ®ï¼‰ï¼Œæå‡æ¨¡å‹é²æ£’æ€§ï¼Œä¸€èˆ¬ç”¨äºè®­ç»ƒé›†ã€‚ç¥ç»ç½‘ç»œéœ€è¦å¤§é‡çš„å‚æ•°ï¼Œè®¸è®¸å¤šå¤šçš„ç¥ç»ç½‘è·¯çš„å‚æ•°éƒ½æ˜¯æ•°ä»¥ç™¾ä¸‡è®¡ï¼Œè€Œä½¿å¾—è¿™äº›å‚æ•°å¯ä»¥æ­£ç¡®å·¥ä½œåˆ™éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½†åœ¨å¾ˆå¤šå®é™…çš„é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬éš¾ä»¥æ‰¾åˆ°å……è¶³çš„æ•°æ®æ¥å®Œæˆä»»åŠ¡ã€‚éšæœºæ”¹å˜è®­ç»ƒæ ·æœ¬å¯ä»¥é™ä½æ¨¡å‹å¯¹æŸäº›å±æ€§çš„ä¾èµ–ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ å¸¸ç”¨çš„æ•°ä¸¾å¢å¼ºæ–¹æ³•æœ‰ ç¿»è½¬ æ—‹è½¬ éšæœºç§»åŠ¨å’Œè£å‰ª åŠ å™ª GAN ç¿»è½¬ï¼ˆFlipï¼‰ PyTorch å®ç° 12345678910train_loader=torch.utils.dataDataLoader( datasets.MNIST(&#x27;../data&#x27;,train=True,download=True, transform=transforms.Compose([ transforms.RandomHorizontalFlip(),# å› ä¸ºå‰é¢æ˜¯randomï¼Œæ‰€ä»¥è¯¥æ“ä½œæœ‰å¯èƒ½åšä¹Ÿå¯èƒ½ä¸åš transforms.RandomVerticalFlip(), transforms.ToTensor(), # transforms.Normalize((0.1307,),(0.3081,)) ])), batch_size=batch_size,shuffle=True) transformæ˜¯torchvisionä¸­æä¾›çš„æ“ä½œ æ—‹è½¬ï¼ˆRotateï¼‰ PyTorchå®ç° 123456789101112train_loader=torch.utils.dataDataLoader( datasets.MNIST(&#x27;../data&#x27;,train=True,download=True, transform=transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), transforms.RandomRotation(15),# è¿™é‡Œæ˜¯å¯¹äºæ¯å¼ ç…§ç‰‡éšæœºæ—‹è½¬ä¸€ä¸ªè§’åº¦ï¼Œè§’åº¦çš„èŒƒå›´æ˜¯ä»-15Â°åˆ°15Â° transforms.(RandomRotation([90,180,270]))# è¿™é‡Œæ˜¯å¯¹äºæ¯å¼ ç…§ç‰‡éšæœºæ—‹è½¬ä¸€ä¸ªè§’åº¦ï¼Œè§’åº¦æ˜¯ 90Â°æˆ–180Â°æˆ–270Â° transforms.ToTensor(), # transforms.Normalize((0.1307,),(0.3081,)) ])), batch_size=batch_size,shuffle=True) ç¼©æ”¾ï¼ˆscaleï¼‰ PyTorch å®ç° 12345678910111213train_loader=torch.utils.dataDataLoader( datasets.MNIST(&#x27;../data&#x27;,train=True,download=True, transform=transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), transforms.RandomRotation(15), transforms.(RandomRotation([90,180,270])) transforms.Resize([32,32]) # å°†å¤§å°å˜ä¸º32Ã—32 transforms.ToTensor(), # transforms.Normalize((0.1307,),(0.3081,)) ])), batch_size=batch_size,shuffle=True) éšæœºç§»åŠ¨å’Œè£å‰ªï¼ˆCrop partï¼‰ PyTorch å®ç° 1234567891011121314train_loader=torch.utils.dataDataLoader( datasets.MNIST(&#x27;../data&#x27;,train=True,download=True, transform=transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), transforms.RandomRotation(15), transforms.(RandomRotation([90,180,270])) transforms.Resize([32,32]) # å°†å¤§å°å˜ä¸º32Ã—32 transforms.ToTensor(), transforms.RandomCrop([28,28]) # transforms.Normalize((0.1307,),(0.3081,)) ])), batch_size=batch_size,shuffle=True) ä¸€èˆ¬è¿›è¡Œæ•°æ®å¢å¼ºæ˜¯RandomRotationå’ŒRandomCropç»“åˆèµ·æ¥ä¸€èµ·ä½¿ç”¨çš„ åŠ å™ªï¼ˆNoiseï¼‰ æ€»ç»“ è™½ç„¶æ•°æ®å¢å¼ºç¡®å®å¯ä»¥æé«˜æ¨¡å‹çš„è¡¨ç°ï¼Œä½†æ˜¯ä»–ä¸ä¼šå¸®åŠ©å¤ªå¤šã€‚"},{"title":"PyTorch CNNå®æˆ˜","path":"/wiki/PyTorch/PyTorch CNNå®æˆ˜.html","content":"æœ¬åšå®¢ä¸»è¦ä½¿ç”¨PyTorchå…ˆå®ç°ä¸€ä¸ªç®€å•çš„CNNå¯¹CIFAR-10æ•°æ®é›†å¯¹å›¾ç‰‡ç‰©ä½“è¿›è¡Œåˆ†ç±»æ“ä½œï¼Œç„¶åå®ç°ä¸€ä¸ªResNetåŒæ ·ä¹Ÿæ˜¯åº”ç”¨äºCIFAR-10æ•°æ®é›†å¯¹ç‰©ä½“è¿›è¡Œåˆ†ç±»æ“ä½œã€‚ åœ¨å¼€å§‹ä¹‹å‰æˆ‘ä»¬å…ˆä»‹ç»ä¸€ä¸‹æœ¬æ¬¡å®éªŒæ‰€ä½¿ç”¨çš„æ•°æ®é›†CIFAR-10 CIFAR-10 CIFAR-10 æ˜¯ç”± Hinton çš„å­¦ç”Ÿ Alex Krizhevsky å’Œ Ilya Sutskever æ•´ç†çš„ä¸€ä¸ªç”¨äºè¯†åˆ«æ™®é€‚ç‰©ä½“çš„å°å‹æ•°æ®é›†ã€‚ä¸€å…±åŒ…å« 10 ä¸ªç±»åˆ«çš„ RGB å½©è‰²å›¾ ç‰‡ï¼šé£æœºï¼ˆ aå©lane ï¼‰ã€æ±½è½¦ï¼ˆ automobile ï¼‰ã€é¸Ÿç±»ï¼ˆ bird ï¼‰ã€çŒ«ï¼ˆ cat ï¼‰ã€é¹¿ï¼ˆ deer ï¼‰ã€ç‹—ï¼ˆ dog ï¼‰ã€è›™ç±»ï¼ˆ frog ï¼‰ã€é©¬ï¼ˆ horse ï¼‰ã€èˆ¹ï¼ˆ ship ï¼‰å’Œå¡è½¦ï¼ˆ truck ï¼‰ã€‚å›¾ç‰‡çš„å°ºå¯¸ä¸º 32Ã—32 ï¼Œæ•°æ®é›†ä¸­ä¸€å…±æœ‰ 50000 å¼ è®­ç»ƒå›¾ç‰‡å’Œ 10000 å¼ æµ‹è¯•å›¾ç‰‡ï¼ˆæ¯ä¸€ç±»ç‰©ä½“æœ‰6000å¼ ç…§ç‰‡ï¼‰ã€‚ CIFAR-10 çš„å›¾ç‰‡æ ·ä¾‹å¦‚å›¾æ‰€ç¤ºã€‚ ä¸ MNIST æ•°æ®é›†ä¸­ç›®æ¯”ï¼Œ CIFAR-10 å…·æœ‰ä»¥ä¸‹ä¸åŒç‚¹ï¼š â€¢ CIFAR-10 æ˜¯ 3 é€šé“çš„å½©è‰² RGB å›¾åƒï¼Œè€Œ MNIST æ˜¯ç°åº¦å›¾åƒã€‚ â€¢ CIFAR-10 çš„å›¾ç‰‡å°ºå¯¸ä¸º 32Ã—32ï¼Œ è€Œ MNIST çš„å›¾ç‰‡å°ºå¯¸ä¸º 28Ã—28ï¼Œæ¯” MNIST ç¨å¤§ã€‚ â€¢ ç›¸æ¯”äºæ‰‹å†™å­—ç¬¦ï¼Œ CIFAR-10 å«æœ‰çš„æ˜¯ç°å®ä¸–ç•Œä¸­çœŸå®çš„ç‰©ä½“ï¼Œä¸ä»…å™ªå£°å¾ˆå¤§ï¼Œè€Œä¸”ç‰©ä½“çš„æ¯”ä¾‹ã€ ç‰¹å¾éƒ½ä¸å°½ç›¸åŒï¼Œè¿™ä¸ºè¯†åˆ«å¸¦æ¥å¾ˆå¤§å›°éš¾ã€‚ ç›´æ¥çš„çº¿æ€§æ¨¡å‹å¦‚ Softmax åœ¨ CIFAR-10 ä¸Šè¡¨ç°å¾—å¾ˆå·®ã€‚ ä¸‹é¢è¿™å¹…å›¾å°±æ˜¯åˆ—ä¸¾äº†10å„ç±»ï¼Œæ¯ä¸€ç±»å±•ç¤ºäº†éšæœºçš„10å¼ å›¾ç‰‡ï¼š å®ç°ç®€å•çš„CNN åŠ è½½æ•°æ®é›† æ­¥éª¤åˆ†ä¸ºä¸¤æ­¥ï¼Œé¦–å…ˆæ˜¯å¯¼å…¥æ•°æ®é›†ï¼ˆè¿™ä¸€æ­¥ä¹ŸåŒ…å«äº†æ•°æ®çš„å¢å¼ºï¼Œæ¯”å¦‚æ—‹è½¬åˆ‡å‰²ä¹‹ç±»çš„ï¼‰ï¼Œç„¶åå°±æ˜¯ä½¿ç”¨Dataloaderå¯¼å…¥æ•°æ®ã€‚å¯¹äºè®­ç»ƒé›†å’Œæµ‹è¯•é›†éƒ½è¦å¯¼å…¥æ•°æ®ï¼Œä½†æ˜¯è¦è®°ä½ï¼Œæœ‰ä¸ªboolç±»å‹çš„å‚æ•°è¦è®¾ç½®çš„ä¸åŒã€‚ 12345678910111213141516171819batchsz = 32cifar_train =datasets.CIFAR10(&#x27;cifar_data&#x27;,True, # è¿™ä¸ªTrueä»£è¡¨æ˜¯è®­ç»ƒé›† transform=transforms.Compose([ transforms.Resize([32,32]), transforms.ToTensor() ]), download=True )cifar_train = DataLoader(cifar_train,batch_size=batchsz,shuffle=True)cifar_test =datasets.CIFAR10(&#x27;cifar_data&#x27;,True, transform=transforms.Compose([ transforms.Resize([32,32]), transforms.ToTensor() ]), download=True )cifar_test = DataLoader(cifar_test,batch_size=batchsz,shuffle=True) ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä¸¤è¡Œä»£ç æ¥ç®€å•æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„æ•°æ®æ˜¯å¦å¯¼å…¥æˆåŠŸäº†ï¼š 12x,label = iter(cifar_train).next()print(&#x27;x:&#x27;,x.shape) å®ç°LeNet-5ç½‘ç»œç»“æ„ æ ¹æ®æˆ‘ä»¬å‰é¢æ‰€å­¦çš„ç†è®ºçŸ¥è¯†ï¼Œæˆ‘ä»¬çŸ¥é“LeNet-5ä¸»è¦åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œå·ç§¯éƒ¨åˆ†å’Œå…¨è¿æ¥éƒ¨åˆ†ï¼Œä¸­é—´æœ‰ä¸€ä¸ªFlattenæ“ä½œï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨å¦‚ä¸‹è¿™ç§æ–¹å¼å¯¹ç½‘ç»œç»“æ„è¿›è¡Œå®ç°ï¼š 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class LeNet5(nn.Module): &#x27;&#x27;&#x27; for CIFAR10 dataset &#x27;&#x27;&#x27; def __init__(self): super(LeNet5,self).__init__() self.conv_unit = nn.Sequential( # input: [batchsz,3,32,32] nn.Conv2d(3,6,kernel_size=5, stride=1, padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), nn.Conv2d(6,16,kernel_size=5,stride=1,padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), # ç„¶åä¸‹é¢å°±æ˜¯å·ç§¯å±‚è½¬å…¨è¿æ¥å±‚äº†ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ªæ‰“å¹³æ“ä½œ ) # Flatten # fc unit self.fc_unit=nn.Sequential( nn.Linear(16*5*5,120), nn.ReLU(inplace=True), nn.Linear(120,84), nn.ReLU(inplace=True), nn.Linear(84,10) ) # ä»¥ä¸‹æ˜¯æµ‹è¯•ç”¨çš„ä»£ç ï¼Œç”¨æ¥æµ‹è¯•å·ç§¯ç¥ç»ç½‘ç»œæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å°æ˜¯å¤šå°‘ # [batchsz,3,32,32] tmp = torch.randn(2,3,32,32) out = self.conv_unit(tmp) # æµ‹è¯•è¾“å‡º:[batchsz,16,5,5] print(&#x27;conv out&#x27;,out.shape) def forward(self,x): &#x27;&#x27;&#x27; :param input : [batchsz,3,32,32] :return logits &#x27;&#x27;&#x27; batchsz = x.size(0) # [batchsz,3,32,32] =&gt; [batchsz,16,5,5] x = self.conv_unit(x) x = x.view(batchsz,16*5*5) #view(batchsz,-1) # [batchsz,16*5*5] =&gt; [b,10] logits = self.fc_unit(x) return logits å¯ä»¥å‘ç°ä¸Šé¢æˆ‘ä»¬ä½¿ç”¨äº†ä¸¤ä¸ªSequentialç„¶åæ˜¯æŠŠä»–ä»¬åœ¨forwardä¸­è¿èµ·æ¥çš„ã€‚æˆ–è®¸ä½ å¯èƒ½è§‰å¾—è¿™æ ·å†™æœ‰ä¸€ç‚¹éº»çƒ¦ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠFlattenæ“ä½œç»§æ‰¿ä¸€ä¸ªnn.moduleç±»ï¼Œè¿™æ ·ä»–å°±å¯ä»¥è¢«æ”¾å…¥Sequentialä¸­äº†ï¼Œç„¶åæˆ‘ä»¬å°±æœ‰äº†å¦‚ä¸‹çš„å†™æ³•ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import torchfrom torch import nnimport torch.nn.functional as Fclass Flatten(nn.Module): def __init__(self): super(Flatten,self).__init__() def forward(self,input): return input.view(input.size(0),-1)class LeNet5(nn.Module): &#x27;&#x27;&#x27; for CIFAR10 dataset &#x27;&#x27;&#x27; def __init__(self): super(LeNet5,self).__init__() self.nn_unit = nn.Sequential( # input: [batchsz,3,32,32] nn.Conv2d(3,6,kernel_size=5, stride=1, padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), nn.Conv2d(6,16,kernel_size=5,stride=1,padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), # Flatten Flatten(), # fc unit nn.Linear(16*5*5,120), nn.ReLU(inplace=True), nn.Linear(120,84), nn.ReLU(inplace=True), nn.Linear(84,10) # ç„¶åä¸‹é¢å°±æ˜¯å·ç§¯å±‚è½¬å…¨è¿æ¥å±‚äº†ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ªæ‰“å¹³æ“ä½œ ) # ä»¥ä¸‹æ˜¯æµ‹è¯•ç”¨çš„ä»£ç  # [batchsz,3,32,32] tmp = torch.randn(2,3,32,32) out = self.nn_unit(tmp) print(&#x27;nn out&#x27;,out.shape) def forward(self,x): &#x27;&#x27;&#x27; :param input : [batchsz,3,32,32] :return logits &#x27;&#x27;&#x27; # [batchsz,3,32,32] =&gt; [batchsz,16,5,5] logits = self.nn_unit(x) return logitsdef main(): net = LeNet5() #æµ‹è¯•ç½‘ç»œç»“æ„ï¼ˆç½‘ç»œèƒ½å¦è·‘é€šï¼‰ tmp = torch.randn(2,3,32,32) out = net(tmp) print(&#x27;LeNet out&#x27;,out.shape)if __name__ == &#x27;__main__&#x27;: main() æ­£å¦‚ä¸Šé¢ä»£ç æ‰€å†™ï¼Œå½“æˆ‘ä»¬ä¸ç¡®å®šCNNè¾“å…¥tensorçš„å½¢çŠ¶çš„æ—¶å€™ï¼Œå¯ä»¥åœ¨mainå‡½æ•°ä¸­å†™ï¼š 1234567def main(): net = LeNet5() #æµ‹è¯•ç½‘ç»œç»“æ„ï¼ˆç½‘ç»œèƒ½å¦è·‘é€šï¼‰ tmp = torch.randn(2,3,32,32) out = net(tmp) print(&#x27;LeNet out&#x27;,out.shape) æˆ–è€…å¯ä»¥åœ¨åˆå§‹åŒ–ç½‘ç»œç»“æ„çš„æ—¶å€™ä¹Ÿå¯ä»¥è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä»¬åœ¨æˆ‘ä»¬å®šä¹‰çš„ç±»ä¸‹çš„__init__å‡½æ•°ä¸­å†™ï¼š 123456# ä»¥ä¸‹æ˜¯æµ‹è¯•ç”¨çš„ä»£ç # [batchsz,3,32,32]tmp = torch.randn(2,3,32,32)out = self.nn_unit(tmp)# æµ‹è¯•è¾“å‡º:[batchsz,16,5,5]print(&#x27;nn out&#x27;,out.shape) è®­ç»ƒéƒ¨åˆ† å’Œå‰é¢çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œä¸€æ ·ï¼Œæ­¥éª¤æ˜¯ä¸€æ ·çš„ã€‚è¿™é‡Œå¤šå¢åŠ äº†å¦‚ä½•ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒï¼Œä»¥åŠé‡‡ç”¨äº†ä¸å‰é¢ä¸ä¸€æ ·çš„CrossEntropyLoss()ä½œä¸ºcriteonï¼Œä½¿ç”¨Adamä½œä¸ºä¼˜åŒ–å™¨ã€‚ 123456789101112131415161718192021222324252627# å®šä¹‰GPUdevice = torch.device(&#x27;cuda&#x27;)# å¯¼å…¥æ¨¡å‹model = LeNet5().to(device) # å°†æ¨¡å‹æ”¾åˆ°æ˜¾å¡ä¸Šprint(model)# è®¾ç½®criteoncriteon=nn.CrossEntropyLoss()# è®¾ç½®ä¼˜åŒ–å™¨(ç›®æ ‡ä¼˜åŒ–å‚æ•°ï¼Œå­¦ä¹ ç‡)optimizer=optim.Adam(model.parameters(),lr=1e-3)# è®­ç»ƒå‡½æ•°for epoch in range(1000): #è®­ç»ƒè½®æ•° for batchidx,(x,label) in enumerate(cifar_train): # x: [batchsz,3,32,32] # label: [batchsz] x, label =x.to(device),label.to(device) # å°†æ•°æ®æ”¾åˆ°æ˜¾å¡ä¸Š logits=model(x) loss = criteon(logits,label) # backprop optimizer.zero_grad() # æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ optimizer.step() # æ›´æ–°ä¸€æ¬¡ `enumerate`çš„ä½œç”¨å¦‚ä¸‹ï¼Œç›¸å½“äºæ˜¯å¯¹å¯ä»¥æšä¸¾çš„å¯¹è±¡å‰é¢åŠ ä¸Šç´¢å¼•ï¼š 123arr=[&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;]for idx,item in enumerate(arr): print(idx,&quot;:&quot;,item) 12340 : a1 : b2 : c3 : d å®ç°Val æˆ‘ä»¬æ¯æ¬¡è®­ç»ƒå®Œäº†ä¸€ä¸ªepochéƒ½è¦è¿›è¡ŒValï¼Œè¿™æ ·æˆ‘ä»¬æ‰çŸ¥é“æˆ‘ä»¬çš„æ¨¡å‹æ˜¯å¦è®­ç»ƒçš„åˆé€‚ã€‚Valéƒ¨åˆ†å…¶å®å’Œä¹‹å‰çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œæ˜¯å·®ä¸å¤šçš„ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚ 123456789101112131415# valtotal_correct=0total_num=0for x,label in cifar_test: x,label=x.to(device),label.to(device) # [batchsz, 10] logits = model(x) # [batchsz] pred = logits.argmax(dim=1) total_correct += torch.eq(pred,label).float().sum().item() # eq æ˜¯é€ä¸ªæ¯”è¾ƒæœ€åè¾“å‡ºçŸ©é˜µå¤§å°å’Œlabelçš„å¤§å°æ˜¯ä¸€æ ·çš„ total_num += x.size(0) acc =total_correct / total_num print(&#x27;acc&#x27;,acc) æ³¨æ„torch.eqå’Œtorch.equalçš„åŒºåˆ« Train+Val æ•´ä½“ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223242526272829303132333435# Train+Val for epoch in range(1000): for batchidx,(x,label) in enumerate(cifar_train): # x: [batchsz,3,32,32] # label: [batchsz] x, label =x.to(device),label.to(device) # å°†æ•°æ®æ”¾åˆ°æ˜¾å¡ä¸Š logits=model(x) loss = criteon(logits,label) # backprop optimizer.zero_grad() # æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ optimizer.step() # æ›´æ–°ä¸€æ¬¡ # è¾“å‡ºæ¯ä¸€è½®è®­ç»ƒç»“æŸåçš„loss print(epoch,loss.item()) # val total_correct=0 total_num=0 for x,label in cifar_test: x,label=x.to(device),label.to(device) # [b, 10] logits = model(x) # [b] pred = logits.argmax(dim=1) total_correct += torch.eq(pred,label).float().sum().item() # eq æ˜¯é€ä¸ªæ¯”è¾ƒæœ€åè¾“å‡ºçŸ©é˜µå¤§å°å’Œlabelçš„å¤§å°æ˜¯ä¸€æ ·çš„ total_num += x.size(0) acc =total_correct / total_num print(&#x27;acc&#x27;,acc) å…¶ä»–ç»†èŠ‚ Valä»£ç ä¼˜åŒ– å› ä¸ºValæ˜¯åšæµ‹è¯•çš„ï¼Œæ˜¯ä¸éœ€è¦æ¢¯åº¦ä¿¡æ¯ï¼Œåå‘ä¼ æ’­å¯¹å‚æ•°è¿›è¡Œä¼˜åŒ–çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æŠŠä¸Šè¿°valéƒ¨åˆ†ä»£ç åŒ…å«åˆ°with torch.no_grad():ä¸­ï¼Œè¿™æ®µä»£ç ç›¸å½“äºå‘Šè¯‰PyTorchè¢«è¿™æ®µä»£ç åŒ…å«çš„ä»£ç æ˜¯ä¸éœ€è¦æ¢¯åº¦ä¿¡æ¯çš„ã€‚è¿™ä¹ˆå†™æ›´åŠ çš„å®‰å…¨ã€‚ 12345678910111213141516with torch.no_grad():\t# val total_correct=0 total_num=0 for x,label in cifar_test: x,label=x.to(device),label.to(device) # [batchsz, 10] logits = model(x) # [batchsz] pred = logits.argmax(dim=1) total_correct += torch.eq(pred,label).float().sum().item() # eq æ˜¯é€ä¸ªæ¯”è¾ƒæœ€åè¾“å‡ºçŸ©é˜µå¤§å°å’Œlabelçš„å¤§å°æ˜¯ä¸€æ ·çš„ total_num += x.size(0) acc =total_correct / total_num print(&#x27;acc&#x27;,acc) æ¨¡å‹æ¨¡å¼åˆ‡æ¢ å› ä¸ºå¯¹äºæˆ‘ä»¬æ„é€ çš„éƒ¨åˆ†ç½‘ç»œä¸­çš„ç‰¹å®šå±‚ï¼Œè¿™äº›å±‚åœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­çš„è¡¨ç°æ˜¯ä¸ä¸€æ ·çš„ï¼Œæ¯”å¦‚BatchNormå±‚ä»–åœ¨è®­ç»ƒçŠ¶æ€ä¸‹å’Œæµ‹è¯•çŠ¶æ€ä¸‹çš„è¡Œä¸ºæ˜¯æœ‰ä¸€äº›å·®å¼‚çš„ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ç½‘ç»œä¸­çš„æ¯ä¸€å±‚éƒ½å»æ‰§è¡Œåˆ‡æ¢çŠ¶æ€çš„æ“ä½œæ˜¯éå¸¸éº»çƒ¦çš„ï¼Œä½†æ˜¯nn.Moduleæ”¯æŒå¯¹è‡ªå®šä¹‰ç½‘ç»œæ•´ä½“çŠ¶æ€çš„åˆ‡æ¢ï¼Œå¤§å¤§ç®€åŒ–äº†æ“ä½œã€‚ è¦æƒ³è¾¾åˆ°è¿™ä¸ªç›®çš„ï¼Œæˆ‘ä»¬éœ€è¦æ·»åŠ ä¸¤è¡Œä»£ç  12345678910111213141516171819202122232425262728293031323334353637# Train+Val for epoch in range(1000):+ model.train() for batchidx,(x,label) in enumerate(cifar_train): # x: [batchsz,3,32,32] # label: [batchsz] x, label =x.to(device),label.to(device) # å°†æ•°æ®æ”¾åˆ°æ˜¾å¡ä¸Š logits=model(x) loss = criteon(logits,label) # backprop optimizer.zero_grad() # æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ optimizer.step() # æ›´æ–°ä¸€æ¬¡ # è¾“å‡ºæ¯ä¸€è½®è®­ç»ƒç»“æŸåæœ€åä¸€ä¸ªBatchçš„loss print(epoch,loss.item()) # val+ model.eval() with torch.no_grad(): total_correct=0 total_num=0 for x,label in cifar_test: x,label=x.to(device),label.to(device) # [b, 10] logits = model(x) # [b] pred = logits.argmax(dim=1) total_correct += torch.eq(pred,label).float().sum().item() # eq æ˜¯é€ä¸ªæ¯”è¾ƒæœ€åè¾“å‡ºçŸ©é˜µå¤§å°å’Œlabelçš„å¤§å°æ˜¯ä¸€æ ·çš„ total_num += x.size(0) acc =total_correct / total_num print(&#x27;acc&#x27;,acc) ä»£ç æ±‡æ€» main.py 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889# CIFAR 10import torch import torch.nn as nnfrom torch.utils.data import DataLoaderfrom torchvision import datasetsfrom torchvision import transformsfrom LeNet5 import LeNet5from torch import optimdef main(): batchsz = 32 cifar_train =datasets.CIFAR10(&#x27;cifar_data&#x27;,True, # è¿™ä¸ªTrueä»£è¡¨æ˜¯è®­ç»ƒé›† transform=transforms.Compose([ transforms.Resize([32,32]), transforms.ToTensor() ]), download=True ) cifar_train = DataLoader(cifar_train,batch_size=batchsz,shuffle=True) cifar_test =datasets.CIFAR10(&#x27;cifar_data&#x27;,True, transform=transforms.Compose([ transforms.Resize([32,32]), transforms.ToTensor() ]), download=True ) cifar_test = DataLoader(cifar_test,batch_size=batchsz,shuffle=True) x,label = iter(cifar_train).next() print(&#x27;x:&#x27;,x.shape) # å®šä¹‰GPU device = torch.device(&#x27;cuda&#x27;) # å¯¼å…¥æ¨¡å‹ model = LeNet5().to(device) # å°†æ¨¡å‹æ”¾åˆ°æ˜¾å¡ä¸Š print(model) # è®¾ç½®criteon criteon=nn.CrossEntropyLoss() # è®¾ç½®ä¼˜åŒ–å™¨(ç›®æ ‡ä¼˜åŒ–å‚æ•°ï¼Œå­¦ä¹ ç‡) optimizer=optim.Adam(model.parameters(),lr=1e-3) # Train+Val for epoch in range(1000): model.train() for batchidx,(x,label) in enumerate(cifar_train): # x: [batchsz,3,32,32] # label: [batchsz] x, label =x.to(device),label.to(device) # å°†æ•°æ®æ”¾åˆ°æ˜¾å¡ä¸Š logits=model(x) loss = criteon(logits,label) # backprop optimizer.zero_grad() # æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ optimizer.step() # æ›´æ–°ä¸€æ¬¡ # è¾“å‡ºæ¯ä¸€è½®è®­ç»ƒç»“æŸåæœ€åä¸€ä¸ªBatchçš„loss print(epoch,loss.item()) # val model.eval() with torch.no_grad(): total_correct=0 total_num=0 for x,label in cifar_test: x,label=x.to(device),label.to(device) # [b, 10] logits = model(x) # [b] pred = logits.argmax(dim=1) total_correct += torch.eq(pred,label).float().sum().item() # eq æ˜¯é€ä¸ªæ¯”è¾ƒæœ€åè¾“å‡ºçŸ©é˜µå¤§å°å’Œlabelçš„å¤§å°æ˜¯ä¸€æ ·çš„ total_num += x.size(0) acc =total_correct / total_num print(&#x27;acc&#x27;,acc) if __name__ == &#x27;__main__&#x27;: main() LeNet5.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import torchfrom torch import nnimport torch.nn.functional as Fclass LeNet5(nn.Module): &#x27;&#x27;&#x27; for CIFAR10 dataset &#x27;&#x27;&#x27; def __init__(self): super(LeNet5,self).__init__() self.conv_unit = nn.Sequential( # input: [batchsz,3,32,32] nn.Conv2d(3,6,kernel_size=5, stride=1, padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), nn.Conv2d(6,16,kernel_size=5,stride=1,padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), # ç„¶åä¸‹é¢å°±æ˜¯å·ç§¯å±‚è½¬å…¨è¿æ¥å±‚äº†ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ªæ‰“å¹³æ“ä½œ ) # Flatten # fc unit self.fc_unit=nn.Sequential( nn.Linear(16*5*5,120), nn.ReLU(inplace=True), nn.Linear(120,84), nn.ReLU(inplace=True), nn.Linear(84,10) ) # ä»¥ä¸‹æ˜¯æµ‹è¯•ç”¨çš„ä»£ç ï¼Œç”¨æ¥æµ‹è¯•å·ç§¯ç¥ç»ç½‘ç»œæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å°æ˜¯å¤šå°‘ # [batchsz,3,32,32] tmp = torch.randn(2,3,32,32) out = self.conv_unit(tmp) # æµ‹è¯•è¾“å‡º:[batchsz,16,5,5] print(&#x27;conv out&#x27;,out.shape) def forward(self,x): &#x27;&#x27;&#x27; :param input : [batchsz,3,32,32] :return logits &#x27;&#x27;&#x27; batchsz = x.size(0) # [batchsz,3,32,32] =&gt; [batchsz,16,5,5] x = self.conv_unit(x) x = x.view(batchsz,16*5*5) #view(batchsz,-1) # [batchsz,16*5*5] =&gt; [b,10] logits = self.fc_unit(x) return logitsdef main(): net = LeNet5() #æµ‹è¯•ç½‘ç»œç»“æ„ï¼ˆç½‘ç»œèƒ½å¦è·‘é€šï¼‰ tmp = torch.randn(2,3,32,32) out = net(tmp) print(&#x27;LeNet out&#x27;,out.shape)if __name__ == &#x27;__main__&#x27;: main() ç¬¬äºŒç§æ–¹æ³•å†™çš„LeNet5 LeNet5pro.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import torchfrom torch import nnimport torch.nn.functional as Fclass Flatten(nn.Module): def __init__(self): super(Flatten,self).__init__() def forward(self,input): return input.view(input.size(0),-1)class LeNet5(nn.Module): &#x27;&#x27;&#x27; for CIFAR10 dataset &#x27;&#x27;&#x27; def __init__(self): super(LeNet5,self).__init__() self.nn_unit = nn.Sequential( # input: [batchsz,3,32,32] nn.Conv2d(3,6,kernel_size=5, stride=1, padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), nn.Conv2d(6,16,kernel_size=5,stride=1,padding=0), nn.AvgPool2d(kernel_size=2,stride=2,padding=0), # Flatten Flatten(), # fc unit nn.Linear(16*5*5,120), nn.ReLU(inplace=True), nn.Linear(120,84), nn.ReLU(inplace=True), nn.Linear(84,10) # ç„¶åä¸‹é¢å°±æ˜¯å·ç§¯å±‚è½¬å…¨è¿æ¥å±‚äº†ï¼Œè¿™é‡Œéœ€è¦ä¸€ä¸ªæ‰“å¹³æ“ä½œ ) # ä»¥ä¸‹æ˜¯æµ‹è¯•ç”¨çš„ä»£ç ï¼Œç”¨æ¥æµ‹è¯•å·ç§¯ç¥ç»ç½‘ç»œæœ€åè¾“å‡ºçš„å›¾ç‰‡å¤§å°æ˜¯å¤šå°‘ # [batchsz,3,32,32] tmp = torch.randn(2,3,32,32) out = self.nn_unit(tmp) # æµ‹è¯•è¾“å‡º:[batchsz,16,5,5] print(&#x27;nn out&#x27;,out.shape) def forward(self,x): &#x27;&#x27;&#x27; :param input : [batchsz,3,32,32] :return logits &#x27;&#x27;&#x27; # [batchsz,3,32,32] =&gt; [batchsz,16,5,5] logits = self.nn_unit(x) return logitsdef main(): net = LeNet5() #æµ‹è¯•ç½‘ç»œç»“æ„ï¼ˆç½‘ç»œèƒ½å¦è·‘é€šï¼‰ tmp = torch.randn(2,3,32,32) out = net(tmp) print(&#x27;LeNet out&#x27;,out.shape)if __name__ == &#x27;__main__&#x27;: main() å®ç°ResNet æœ¬æ¬¡å®éªŒä»¥ResNet18ä¸ºä¾‹ï¼Œä½†æ˜¯å’Œè®ºæ–‡ä¸­çš„ResNet18è¿˜æ˜¯æœ‰äº›è®¸å·®å¼‚çš„ ï¼Œå› ä¸ºé‡‡ç”¨çš„æ•°æ®é›†ä¸å¤ªä¸€æ ·ã€‚ å®ç°æ®‹å·®å— æœ¬æ¬¡æ®‹å·®å—çš„å®ç°å’Œä¹‹å‰çš„æœ‰ä¸€äº›åŒºåˆ«ï¼ŒåŠ å…¥äº†æ­¥é•¿ï¼Œè¿™æ ·å°±èƒ½åœ¨æé«˜æ·±åº¦çš„åŒæ—¶ç¼©å°å›¾ç‰‡ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹ã€‚ éœ€è¦æ³¨æ„çš„ç‚¹æ˜¯ï¼Œå¦‚æœè¾“å…¥é€šé“å’Œè¾“å‡ºé€šé“æ•°é‡ä¸ä¸€æ ·ï¼Œshortcutçš„è·¯å¾„ä¸Šå¯èƒ½è¿˜æ˜¯è¦å†åŠ ä¸€å±‚å·ç§¯å±‚ï¼Œæ¥ä½¿é€šé“æ•°é‡ä¸€æ ·ï¼Œè¿™æ ·æ‰èƒ½ç›¸åŠ ã€‚ 123456789101112131415161718192021222324252627282930313233343536class ResBlk(nn.Module): &#x27;&#x27;&#x27; ResNet Block &#x27;&#x27;&#x27; def __init__(self,ch_in,ch_out,stride=1): &#x27;&#x27;&#x27; :param ch_in :param ch_out &#x27;&#x27;&#x27; super(ResBlk,self).__init__() self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=stride,padding=1) self.bn1 = nn.BatchNorm2d(ch_out) self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1) self.bn2 = nn.BatchNorm2d(ch_out) self.extra = nn.Sequential() if ch_out!= ch_in: self.extra=nn.Sequential( nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=stride), nn.BatchNorm2d(ch_out) ) def forward(self,x): &#x27;&#x27;&#x27; :param x: [batchsz,ch,h,w] :return: &#x27;&#x27;&#x27; out = F.relu(self.bn1(self.conv1(x))) out = self.bn2(self.conv2(out)) # short_cut ### è¿™é‡Œä¸€å®šè¦å†™extraï¼ï¼ï¼ # extra module : [batchsz,ch_in,h,w] =&gt; [batchsz,ch_out,h,w] # element-wise add: out = self.extra(x) + out return out å®ç°ResNet18ç½‘ç»œç»“æ„ ä»£ç åŸç†å’Œå®ç°LeNet-5ä¸€æ ·ï¼Œè¿™é‡Œä¸å†èµ˜è¿° 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class ResNet18(nn.Module): def __init__(self): super(ResNet18, self).__init__() #ä»¥ä¸‹conv1ä¸ºé¢„å¤„ç†å±‚ self.conv1 = nn.Sequential( nn.Conv2d(3,64,kernel_size=3,stride=3,padding=0), nn.BatchNorm2d(64) ) # followed 4 blocks # [batchsz,64,h,w] =&gt; [batchsz,128,h,w] self.blk1=ResBlk(64,128,stride=2) # [batchsz,128,h,w] =&gt; [batchsz,256,h,w] self.blk2=ResBlk(128,256,stride=2) # [batchsz,256,h,w] =&gt; [batchsz,512,h,w] self.blk3=ResBlk(256,512,stride=2) # [batchsz,512,h,w] =&gt; [batchsz,512,h,w] self.blk4=ResBlk(512,512,stride=2) self.outlayer = nn.Linear(512, 10) def forward(self,x): &#x27;&#x27;&#x27; :param x: :return: &#x27;&#x27;&#x27; x = F.relu(self.conv1(x)) # [batchsz,64,h,w] =&gt; [batchsz,512,h,w] x = self.blk1(x) x = self.blk2(x) x = self.blk3(x) x = self.blk4(x) # æµ‹è¯•ä»£ç  # print(&#x27;after convolution&#x27;,x.shape) # [batchsz,512,2,2] # [batchsz,512,h,w] =&gt; [batchsz,512,1,1] x =F.adaptive_max_pool2d(x,[1,1]) # æµ‹è¯•ä»£ç  # print(&#x27;after pool:&#x27;, x.shape) # Flatten x=x.view(x.size(0),-1) # Linear x = self.outlayer(x) return x æ³¨æ„ï¼šä¸­é—´è¿˜æ˜¯æœ‰ä¸€ä¸ªFlattenæ“ä½œ å¯ä»¥ä½¿ç”¨ä¸Šè¿°ä»£ç ä¸­è¢«æ³¨é‡Šæ‰çš„`#æµ‹è¯•ä»£ç `éƒ¨åˆ†æ‰“å‡ºä¸­é—´å±‚tensorçš„å½¢çŠ¶ï¼Œè¿™æ ·æœ‰åŠ©äºæŒæ¡ç½‘ç»œçš„å½¢çŠ¶ã€‚ åç»­ä»£ç  è®­ç»ƒéƒ¨åˆ†å’ŒValéªŒè¯å’Œä¸Šé¢çš„LeNet-5å®ç°ä»£ç å®Œå…¨ä¸€æ ·ï¼Œæˆ‘ä»¬åªéœ€è¦æŠŠloadçš„æ¨¡å‹æ›´æ”¹ä¸€ä¸‹å³å¯ã€‚é¦–å…ˆå¯¼å…¥ResNet 1from ResNet import ResNet18 ç„¶åå¯¼å…¥æ¨¡å‹çš„åœ°æ–¹ç¨ä½œä¿®æ”¹å°±OKäº†ï¼š 1234# å¯¼å…¥æ¨¡å‹# model = LeNet5().to(device) # å°†æ¨¡å‹æ”¾åˆ°æ˜¾å¡ä¸Šmodel = ResNet18().to(device) # å°†æ¨¡å‹æ”¾åˆ°æ˜¾å¡ä¸Šprint(model) ä»£ç ä¼˜åŒ– å½’ä¸€åŒ–&amp;æ•°æ®å¢å¼º æ•°æ®é¢„å¤„ç†æ—¶åŠ å…¥å½’ä¸€åŒ–Normalizeæå‡æ¨¡å‹æ€§èƒ½ å½“ç„¶ä¹Ÿå¯ä»¥åœ¨æ•°æ®å¤„ç†éƒ¨åˆ†åŠ å…¥æ•°æ®å¢å¼ºæ¥ç¨å¾®æé«˜æ¨¡å‹æ€§èƒ½ 12345678910111213141516171819cifar_train =datasets.CIFAR10(&#x27;cifar_data&#x27;,True, # è¿™ä¸ªTrueä»£è¡¨æ˜¯è®­ç»ƒé›† transform=transforms.Compose([ transforms.Resize([32,32]), transforms.ToTensor(), transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225]) ]), download=True )cifar_train = DataLoader(cifar_train,batch_size=batchsz,shuffle=True)cifar_test =datasets.CIFAR10(&#x27;cifar_data&#x27;,True, transform=transforms.Compose([ transforms.Resize([32,32]), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]), download=True ) ä»£ç æ±‡æ€» main.py åŒä¸Šä¸€ä¸ªæ±‡æ€»çš„mainï¼ŒæŒ‰ç…§ä¸Šé¢çš„æŒ‡ç¤ºæ”¹ä¸€ç‚¹å°±è¡Œã€‚ ResNet.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import torchfrom torch import nnimport torch.nn.functional as Fclass ResBlk(nn.Module): &#x27;&#x27;&#x27; ResNet Block &#x27;&#x27;&#x27; def __init__(self,ch_in,ch_out,stride=1): &#x27;&#x27;&#x27; :param ch_in :param ch_out &#x27;&#x27;&#x27; super(ResBlk,self).__init__() self.conv1 = nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=stride,padding=1) self.bn1 = nn.BatchNorm2d(ch_out) self.conv2 = nn.Conv2d(ch_out,ch_out,kernel_size=3,stride=1,padding=1) self.bn2 = nn.BatchNorm2d(ch_out) self.extra = nn.Sequential() if ch_out!= ch_in: self.extra=nn.Sequential( nn.Conv2d(ch_in,ch_out,kernel_size=1,stride=stride), nn.BatchNorm2d(ch_out) ) def forward(self,x): &#x27;&#x27;&#x27; :param x: [batchsz,ch,h,w] :return: &#x27;&#x27;&#x27; out = F.relu(self.bn1(self.conv1(x))) out = self.bn2(self.conv2(out)) # short_cut ### è¿™é‡Œä¸€å®šè¦å†™extraï¼ï¼ï¼ # extra module : [batchsz,ch_in,h,w] =&gt; [batchsz,ch_out,h,w] # element-wise add: out = self.extra(x) + out return outclass ResNet18(nn.Module): def __init__(self): super(ResNet18, self).__init__() #ä»¥ä¸‹conv1ä¸ºé¢„å¤„ç†å±‚ self.conv1 = nn.Sequential( nn.Conv2d(3,64,kernel_size=3,stride=3,padding=0), nn.BatchNorm2d(64) ) # followed 4 blocks # [batchsz,64,h,w] =&gt; [batchsz,128,h,w] self.blk1=ResBlk(64,128,stride=2) # [batchsz,128,h,w] =&gt; [batchsz,256,h,w] self.blk2=ResBlk(128,256,stride=2) # [batchsz,256,h,w] =&gt; [batchsz,512,h,w] self.blk3=ResBlk(256,512,stride=2) # [batchsz,512,h,w] =&gt; [batchsz,512,h,w] self.blk4=ResBlk(512,512,stride=2) self.outlayer = nn.Linear(512, 10) def forward(self,x): &#x27;&#x27;&#x27; :param x: :return: &#x27;&#x27;&#x27; x = F.relu(self.conv1(x)) # [batchsz,64,h,w] =&gt; [batchsz,512,h,w] x = self.blk1(x) x = self.blk2(x) x = self.blk3(x) x = self.blk4(x) # æµ‹è¯•ä»£ç  # print(&#x27;after convolution&#x27;,x.shape) # [batchsz,512,2,2] # [batchsz,512,h,w] =&gt; [batchsz,512,1,1] x =F.adaptive_max_pool2d(x,[1,1]) # æµ‹è¯•ä»£ç  # print(&#x27;after pool:&#x27;, x.shape) # Flatten x=x.view(x.size(0),-1) # Linear x = self.outlayer(x) return xdef main(): # ä»¥ä¸‹ä¸ºæµ‹è¯•ä»£ç  tmp = torch.randn(2,3,32,32) model=ResNet18() blk=ResBlk(3,128,stride=4) out = blk(tmp) out = model(tmp) print(out.shape)if __name__==&#x27;__main__&#x27;: main()"},{"title":"Gitå…¥é—¨æ•™ç¨‹","path":"/wiki/Git/Gitå…¥é—¨æ•™ç¨‹.html","content":"åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ æ¯ä¸ªäººéƒ½æ‹¥æœ‰å…¨éƒ¨çš„ä»£ç ï¼ä¸ä¼šå› ä¸ºæœåŠ¡å™¨æŸåæˆ–è€…ç½‘ç»œé—®é¢˜ï¼Œé€ æˆä¸èƒ½å·¥ä½œçš„æƒ…å†µã€‚ æ‰€æœ‰ç‰ˆæœ¬ä¿¡æ¯ä»“åº“å…¨éƒ¨åŒæ­¥åˆ°æœ¬åœ°çš„æ¯ä¸ªç”¨æˆ·ï¼Œè¿™æ ·å°±å¯ä»¥åœ¨æœ¬åœ°æŸ¥çœ‹æ‰€æœ‰ç‰ˆæœ¬å†å²ï¼Œå¯ä»¥ç¦»çº¿åœ¨æœ¬åœ°æäº¤ï¼Œåªéœ€åœ¨è”ç½‘æ—¶pushåˆ°ç›¸åº”çš„æœåŠ¡å™¨æˆ–å…¶ä»–ç”¨æˆ·é‚£é‡Œã€‚ç”±äºæ¯ä¸ªç”¨æˆ·é‚£é‡Œä¿å­˜çš„éƒ½æ˜¯æ‰€æœ‰çš„ç‰ˆæœ¬æ•°æ®ï¼Œåªè¦æœ‰ä¸€ä¸ªç”¨æˆ·çš„è®¾å¤‡æ²¡æœ‰é—®é¢˜å°±å¯ä»¥æ¢å¤æ‰€æœ‰çš„æ•°æ®ï¼Œä½†è¿™å¢åŠ äº†æœ¬åœ°å­˜å‚¨ç©ºé—´çš„å ç”¨ã€‚ Gitæ—¶ç›®å‰ä¸–ç•Œä¸Šæœ€å…ˆè¿›çš„åˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿã€‚ å› ä¸ºGit Bashæˆ‘ä»¬åœ¨æ—¥å¸¸ä¸­æ˜¯ä½¿ç”¨æœ€å¤šçš„ï¼Œè€ŒGit BashåŸºç¡€å‘½ä»¤é£æ ¼æ˜¯åŸºäºLinuxç³»ç»Ÿçš„ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å…ˆä»‹ç»ä¸€äº›åŸºæœ¬çš„Linuxå‘½ä»¤ åŸºæœ¬Linuxå‘½ä»¤ cdï¼šæ”¹å˜ç›®å½• cd ..ï¼šå›åˆ°ä¸Šä¸€çº§ç›®å½• pwdï¼šæ˜¾ç¤ºå½“å‰æ‰€åœ¨çš„ç›®å½•çš„è·¯å¾„ lsï¼šåˆ—å‡ºå½“å‰ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ llï¼šåŒä¸Šä¹Ÿæ˜¯åˆ—å‡ºå½“å‰ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼Œä½†æ˜¯ç›¸æ¯”äºlsåˆ—å‡ºçš„å†…å®¹ä¼šæ›´ä¸ºè¯¦ç»†ã€‚ touchï¼šæ–°å»ºä¸€ä¸ªæ–‡ä»¶ã€‚egï¼štouch index.jså°±ä¼šåœ¨å½“å‰ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªindex.jsçš„æ–‡ä»¶ã€‚ rmï¼šåˆ é™¤ä¸€ä¸ªæ–‡ä»¶ã€‚egï¼šrm index.jså°±ä¼šåœ¨å°†å½“å‰ç›®å½•ä¸‹çš„index.jsæ–‡ä»¶åˆ é™¤ã€‚ mkdirï¼šæ–°å»ºä¸€ä¸ªç›®å½•ï¼Œå°±æ˜¯æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ã€‚ rm-rï¼šåˆ é™¤ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œegï¼šrm-r srcåˆ é™¤srcç›®å½• `rm-rf /` åˆ‡å‹¿åœ¨Linuxç”µè„‘ä¸­å°è¯•æ­¤å‘½ä»¤ï¼Œfæ˜¯é€’å½’åˆ é™¤çš„æ„æ€ï¼Œè¿™é‡Œçš„å«ä¹‰å°±æ˜¯å°†æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹å…¨éƒ¨åˆ æ‰ã€‚ mvç§»åŠ¨æ–‡ä»¶ï¼Œeg:mv index.html src å‘½ä»¤å‰é¢çš„index.htmlæ–‡ä»¶æ˜¯æˆ‘ä»¬è¦ç§»åŠ¨çš„æ–‡ä»¶ã€‚srcæ˜¯ç›®æ ‡æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶å¤¹å¿…é¡»åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚ resetï¼šé‡æ–°åˆå§‹åŒ–ç»ˆç«¯/æ¸…å±ã€‚ clearï¼šæ¸…å±ã€‚ historyï¼šæŸ¥çœ‹å‘½ä»¤å†å²ã€‚ helpï¼šå¸®åŠ© exitï¼šé€€å‡º #ï¼šè¡¨ç¤ºæ³¨é‡Š Gitçš„å¿…è¦é…ç½® æŸ¥çœ‹ä¸åŒçº§åˆ«çš„é…ç½®æ–‡ä»¶ 12345# æŸ¥çœ‹ç³»ç»Ÿconfig$ git config --system --list# æŸ¥çœ‹å½“å‰ç”¨æˆ·(global)é…ç½®$ git config --global --list è®¾ç½®ç”¨æˆ·åå’Œé‚®ç®± 12$ git config --global user.name &quot;xxxxx&quot; #ç”¨æˆ·å$ git config --global user.email 2604932485@qq.com #é‚®ç®± æŸ¥çœ‹ç”¨æˆ·åå’Œé‚®ç®± GitåŸºæœ¬ç†è®º Gitæœ¬åœ°æœ‰ä¸‰ä¸ªå·¥ä½œåŒºåŸŸï¼šå·¥ä½œç›®å½•ï¼ˆWorking Directoryï¼‰ã€æš‚å­˜åŒºï¼ˆStage/Indexï¼‰ã€èµ„æºåº“ï¼ˆRepositoryæˆ–Git Directoryï¼‰ã€‚å¦‚æœåœ¨åŠ ä¸Šè¿œç¨‹çš„gitä»“åº“ï¼ˆRemote Directoryï¼‰å°±å¯ä»¥åˆ†ä¸ºå››ä¸ªå·¥ä½œåŒºåŸŸï¼Œæ–‡ä»¶åœ¨è¿™å››ä¸ªåŒºåŸŸä¹‹é—´çš„è½¬æ¢å…³ç³»å¦‚ä¸‹ï¼š åŸºæœ¬å·¥ä½œæµç¨‹ åœ¨å·¥ä½œç›®å½•ä¸­æ·»åŠ ã€ä¿®æ”¹æ–‡ä»¶ å°†éœ€è¦è¿›è¡Œç‰ˆæœ¬ç®¡ç†çš„æ–‡ä»¶æ”¾å…¥æš‚å­˜åŒºï¼ˆgit add .ï¼‰ å°†æš‚å­˜åŒºåŸŸçš„æ–‡ä»¶æäº¤åˆ°gitä»“åº“ï¼ˆgit commitï¼‰ å°†æœ¬åœ°ä»“åº“æ¨é€åˆ°è¿œç¨‹gitä»“åº“ï¼ˆgit pushï¼‰ å› æ­¤ï¼Œgitç®¡ç†çš„æ–‡ä»¶æœ‰ä¸‰ç§çŠ¶æ€ï¼šå·²ä¿®æ”¹ï¼ˆmodifiedï¼‰ï¼Œå·²æš‚å­˜ï¼ˆstagedï¼‰ï¼Œå·²æäº¤ï¼ˆcommittedï¼‰ Gité¡¹ç›®æ­å»º æœ¬åœ°æ­å»ºä»“åº“ è¿œç¨‹å…‹éš†ä»“åº“ æœ¬åœ°æ­å»ºä»“åº“ åˆ›å»ºä¸€ä¸ªå†™çš„ä»“åº“ï¼Œæˆ‘ä»¬å…ˆåœ¨gitç»ˆç«¯ä¸­ä½¿ç”¨cdå‘½ä»¤è¿›å…¥æˆ‘ä»¬æƒ³è¦åˆ›å»ºä»“åº“çš„ç›®å½•ï¼Œç„¶åæˆ‘ä»¬ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å°†ä¸€ä¸ªå½“å‰ç›®å½•ï¼ˆæ­£å¸¸çš„çš„æ–‡ä»¶å¤¹ï¼‰åˆå§‹åŒ–æˆgitä»“åº“ 12# å°†å½“å‰ç›®å½•æ–‡ä»¶å¤¹åˆå§‹åŒ–ä¸ºä¸€ä¸ªgitä»“åº“$ git init æ‰§è¡Œåå¯ä»¥çœ‹åˆ°ï¼Œåœ¨å½“å‰ç›®å½•ä¸­å¤šå‡ºäº†ä¸€ä¸ª.gitç›®å½•ï¼Œå…³äºç‰ˆæœ¬ç­‰çš„æ‰€æœ‰ä¿¡æ¯éƒ½åœ¨è¿™ä¸ªç›®å½•é‡Œé¢ã€‚ å…‹éš†è¿œç¨‹ä»“åº“åˆ°æœ¬åœ° ä½¿ç”¨git cloneå‘½ä»¤å°†è¿œç¨‹æœåŠ¡å™¨ä¸Šçš„ä»“åº“å®Œå…¨é•œåƒä¸€ä»½åˆ°æœ¬åœ° 12# å…‹éš†ä¸€ä¸ªé¡¹ç›®å’Œä»–çš„æ•´ä¸ªä»£ç å†å²ï¼ˆç‰ˆæœ¬ä¿¡æ¯ï¼‰$ git clone [url] Gitæ–‡ä»¶æ“ä½œ ç‰ˆæœ¬æ§åˆ¶å°±æ˜¯å¯¹æ–‡ä»¶çš„ç‰ˆæœ¬æ§åˆ¶ï¼Œè¦å¯¹æ–‡ä»¶è¿›è¡Œä¿®æ”¹ã€æäº¤ç­‰æ“ä½œï¼Œé¦–å…ˆè¦çŸ¥é“æ–‡ä»¶å½“å‰åœ¨ä»€ä¹ˆçŠ¶æ€ï¼Œä¸ç„¶å¯èƒ½ä¼šæäº¤äº†ç°åœ¨è¿˜ä¸æƒ³æäº¤çš„æ–‡ä»¶ï¼Œæˆ–è€…è¦æäº¤çš„æ–‡ä»¶æ²¡æœ‰æäº¤ä¸Šã€‚ æ–‡ä»¶çš„4ç§çŠ¶æ€ Untrackedï¼šæœªè·Ÿè¸ªï¼Œæ­¤æ–‡ä»¶åœ¨æ–‡ä»¶å¤¹ä¸­ï¼Œä½†å¹¶æ²¡æœ‰åŠ å…¥åˆ°gitåº“ä¸­ï¼Œä¸å‚ä¸ç‰ˆæœ¬æ§åˆ¶ã€‚é€šè¿‡git addçŠ¶æ€å˜ä¸ºStaged Unmodifyï¼šæ–‡ä»¶å·²ç»å…¥åº“(historyçŠ¶æ€)ï¼Œæœªä¿®æ”¹ï¼Œå³ç‰ˆæœ¬åº“ä¸­çš„æ–‡ä»¶å¿«ç…§å†…å®¹ä¸æ–‡ä»¶å¤¹ä¸­å®Œå…¨ä¸€è‡´ï¼Œè¿™ç§ç±»å‹çš„æ–‡ä»¶æœ‰ä¸¤ç§å»å¤„ï¼Œå¦‚æœå®ƒè¢«ä¿®æ”¹ï¼Œè€Œå˜ä¸ºModifiedï¼Œå¦‚æœä½¿ç”¨git rmç§»å‡ºç‰ˆæœ¬åº“ï¼Œåˆ™æˆä¸ºUntrackedæ–‡ä»¶ Modifiedï¼šæ–‡ä»¶å·²ä¿®æ”¹ï¼Œä»…ä»…æ˜¯ä¿®æ”¹ï¼Œå¹¶æ²¡æœ‰è¿›è¡Œå…¶ä»–çš„æ“ä½œï¼Œè¿™ä¸ªæ–‡ä»¶ä¹Ÿæœ‰ä¸¤ä¸ªå»å¤„ï¼Œé€šè¿‡git addå¯è¿›å…¥StagedçŠ¶æ€ï¼Œä½¿ç”¨git checkoutåˆ™ä¸¢å¼ƒä¿®æ”¹è¿‡ï¼Œè¿”å›åˆ°unmodifyçŠ¶æ€ï¼Œè¿™ä¸ªgit checkoutå³ä»åº“ä¸­å–å‡ºæ–‡ä»¶ï¼Œè¦†ç›–å½“å‰ä¿®æ”¹ï¼ Stagedï¼šæš‚å­˜çŠ¶æ€ï¼Œæ‰§è¡Œgit commitåˆ™å°†ä¿®æ”¹åŒæ­¥åˆ°åº“ä¸­ï¼Œè¿™æ—¶åº“ä¸­çš„æ–‡ä»¶å’Œæœ¬åœ°æ–‡ä»¶åˆå˜ä¸ºä¸€è‡´ï¼Œæ–‡ä»¶ä¸ºUnmodifyçŠ¶æ€ã€‚æ‰§è¡Œgit reset HEAD filenameå–æ¶ˆæš‚å­˜ï¼Œæ–‡ä»¶çŠ¶æ€å˜ä¸ºModified æŸ¥çœ‹æ–‡ä»¶çš„çŠ¶æ€ 1234567# æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çŠ¶æ€$ git status [filename]# æŸ¥çœ‹æ‰€æœ‰æ–‡ä»¶çš„çŠ¶æ€$ git status ä¸Šä¼ æäº¤æ–‡ä»¶ 1234# æ·»åŠ æ‰€æœ‰æ–‡ä»¶åˆ°æš‚å­˜åŒº$ git add .# æäº¤æš‚å­˜åŒºä¸­çš„å†…å®¹$ git commit -m &quot;xxx&quot; # -m åè·Ÿç€çš„æ˜¯æäº¤ä¿¡æ¯ å›æ»š 12345# å¯¹äºå°šæœªæäº¤çš„å¤„äºæš‚å­˜åŒºä¸­çš„æ–‡ä»¶ï¼Œå¦‚æœè¦æ’¤é”€ä¿®æ”¹$ git checkout [filename]# å¯¹äºå·²ç»æäº¤çš„ä¸€æ¬¡commitï¼Œå¦‚æœè¦æ’¤é”€è¿™æ¬¡æäº¤$ git reset HEAD^1 ä¸‹é¢æˆ‘ä»¬ä¸¾ä¸€ä¸ªå®Œæ•´çš„æ¡ˆä¾‹ï¼Œå°±æ˜¯å°†ä¸€ä¸ªç©ºçš„æ–‡ä»¶å¤¹åˆå§‹åŒ–æˆä¸€ä¸ªgitä»“åº“ï¼Œç„¶åæ–°å»ºä¸€ä¸ªtest.txtæ–‡ä»¶å¹¶å°†å…¶åŠ å…¥åˆ°ä»“åº“ä¸­çš„æ•´ä¸ªè¿‡ç¨‹ã€‚ æˆ‘ä»¬é‡‡ç”¨æœ¬åœ°åˆå§‹åŒ–ä»“åº“çš„æ–¹å¼ï¼Œé¦–å…ˆåœ¨ç”µè„‘æ¡Œé¢ä¸Šæ–°å»ºæ–‡ä»¶å¤¹ex1ï¼Œç„¶åå³é”®è¯¥æ–‡ä»¶å¤¹è¿›è¡Œgit bash å¯ä»¥å‘ç°git initåè¯¥æ–‡ä»¶å¤¹ä¸­å¤šå‡ºæ¥ä¸€ä¸ªéšè—æ–‡ä»¶å¤¹ï¼Œç„¶åæˆ‘ä»¬åœ¨è¯¥æ–‡ä»¶å¤¹ä¸‹æ–°å»ºä¸€ä¸ªtest.txtæ–‡ä»¶ã€‚ ç„¶åè¿›å…¥gitç»ˆç«¯ï¼Œclearåæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ï¼Œç»“æœå¦‚ä¸‹å›¾ ç°åœ¨æˆ‘ä»¬çš„æ–‡ä»¶æˆåŠŸè¿›å…¥äº†æš‚å­˜åŒºï¼Œä¸‹é¢è¿›è¡Œæäº¤æ“ä½œï¼Œç»“æœå¦‚ä¸‹ å¯ä»¥å‘ç°æœ€åæŸ¥çœ‹çŠ¶æ€çš„æ—¶å€™å·²ç»æ˜¾ç¤ºworking tree cleanã€‚æ‰€ä»¥è¯æ˜æäº¤æˆåŠŸï¼ å¿½ç•¥æ–‡ä»¶â€”â€”.gitgnore æœ‰äº›æ—¶å€™æˆ‘ä»¬ä¸æƒ³æŠŠæŸäº›æ–‡ä»¶çº³å…¥ç‰ˆæœ¬æ§åˆ¶ä¸­ï¼Œæ¯”å¦‚æ•°æ®åº“æ–‡ä»¶ï¼Œä¸´æ—¶æ–‡ä»¶ï¼Œè®¾è®¡æ–‡ä»¶ç­‰ è¿™æ—¶æˆ‘ä»¬å¯ä»¥åœ¨ä¸»ç›®å½•ä¸‹å»ºç«‹&quot;.gitgnore&quot;æ–‡ä»¶ï¼Œæ­¤æ–‡ä»¶æœ‰å¦‚ä¸‹è§„åˆ™ æ–‡ä»¶ä¸­çš„ç©ºè¡Œæˆ–ä»¥ï¼ƒå¼€å§‹çš„è¡Œéƒ½ä¼šè¢«å¿½ç•¥ã€‚ å¯ä»¥ä½¿ç”¨Linuxé€šé…ç¬¦ã€‚ æ˜Ÿå·ï¼ˆ*ï¼‰ä»£è¡¨ä»»æ„å¤šä¸ªå­—ç¬¦ï¼Œé—®å·ï¼ˆ?ï¼‰ä»£è¡¨ä¸€ä¸ªå­—ç¬¦ï¼Œæ–¹æ‹¬å·ï¼ˆ[abc]ï¼‰ä»£è¡¨å¯é€‰å­—ç¬¦èŒƒå›´ï¼Œå¤§æ‹¬å·ï¼ˆ{string1,string2,â€¦}ï¼‰ä»£è¡¨å¯é€‰çš„å­—ç¬¦ä¸²ç­‰ã€‚ å¦‚æœåç§°çš„æœ€å‰é¢æœ‰ä¸€ä¸ªæ„Ÿå¹å·ï¼ˆ!ï¼‰ï¼Œè¡¨ç¤ºä¾‹å¤–è§„åˆ™ï¼Œå°†ä¸è¢«å¿½ç•¥ã€‚ å¦‚æœåç§°çš„æœ€å‰é¢æ˜¯ä¸€ä¸ªè·¯å¾„åˆ†éš”ç¬¦ï¼ˆ/ï¼‰ï¼Œè¡¨ç¤ºè¦å¿½ç•¥çš„æ–‡ä»¶åœ¨æ­¤ç›®å½•ä¸‹ï¼Œè€Œå­ç›®å½•ä¸­çš„æ–‡ä»¶ä¸å¿½ç•¥ã€‚ å¦‚æœåç§°çš„æœ€åé¢æ˜¯ä¸€ä¸ªè·¯å¾„åˆ†éš”ç¬¦ï¼ˆ/ï¼‰ï¼Œè¡¨ç¤ºè¦å¿½ç•¥çš„æ˜¯æ­¤ç›®å½•ä¸‹è¯¥åç§°çš„å­ç›®å½•ï¼Œè€Œéæ–‡ä»¶ï¼ˆé»˜è®¤æ–‡ä»¶æˆ–ç›®å½•éƒ½å¿½ç•¥ï¼‰ 123456# ä¸ºæ³¨é‡Š*.txt # å¿½ç•¥æ‰€æœ‰.txtç»“å°¾çš„æ–‡ä»¶!lib.txt # ä½†æ˜¯lib.txté™¤å¤–/temp # ä»…å¿½ç•¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„tempæ–‡ä»¶å¤¹ï¼Œä¸åŒ…æ‹¬å…¶ä»–ç›®å½•tempbuild/ # å¿½ç•¥buildç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶doc/*.txt # ä¼šå¿½ç•¥ doc/notes.txt ä½†ä¸åŒ…æ‹¬ doc/server/arch.txt åˆ›å»ºè¿œç¨‹ä»“åº“ ä»¥GitHubä¸ºä¾‹ï¼Œå…¶å®éå¸¸çš„ç®€å•ï¼Œåªéœ€è¦è·Ÿç€GitHubçš„æ­¥éª¤ä¸€æ­¥ä¸€æ­¥è¿›è¡Œè®¾ç½®å°±å¯ä»¥æˆåŠŸåˆ›å»ºä¸€ä¸ªä»“åº“äº†ã€‚ å¡«å†™å¥½ä»“åº“åä»¥åŠä»“åº“æè¿°åï¼Œç‚¹å‡»åˆ›å»ºä»“åº“ã€‚GitHubä¼šæä¾›ä¸‹é¢çš„ä»£ç ï¼Œè®©ä½ å°†æœ¬åœ°çš„ä»“åº“å…³è”åˆ°è¿œç«¯è¿™ä¸ªæ–°åˆ›å»ºçš„ä»“åº“ã€‚ï¼ˆå…³è”å·²æœ‰ä»“åº“ä»£ç ç”¨æœ€ä¸‹é¢ä¸‰è¡Œä»£ç ï¼‰ æœ€å¸¸ç”¨çš„ä¸¤ä¸ªå‘½ä»¤ï¼š 1234# æ¨é€å½“å‰åˆ†æ”¯æœ€æ–°çš„æäº¤åˆ°è¿œç¨‹$ git push# æ‹‰å–è¿œç¨‹åˆ†æ”¯æœ€æ–°çš„æäº¤åˆ°æœ¬åœ°$ git pull Gitåˆ†æ”¯ Gitåˆ†æ”¯ä¸­å¸¸ç”¨å‘½ä»¤ 123456789101112131415161718192021222324252627# åˆ—å‡ºæ‰€æœ‰æœ¬åœ°åˆ†æ”¯$ git branch# åˆ—å‡ºæ‰€æœ‰è¿œç¨‹åˆ†æ”¯$ git branch -r# æ–°å»ºä¸€ä¸ªåˆ†æ”¯ï¼Œä½†ä¾ç„¶åœç•™åœ¨å½“å‰åˆ†æ”¯$ git branch [branch-name]# æ–°å»ºä¸€ä¸ªåˆ†æ”¯ï¼Œå¹¶åˆ‡æ¢åˆ°è¯¥åˆ†æ”¯(å·²å½“å‰åˆ†æ”¯ä¸ºåŸºç¡€)$ git checkout -b [branch]# å•çº¯åœ°åˆ‡æ¢åˆ°æŸä¸ªåˆ†æ”¯$ git checkout [branch-name]# åˆå¹¶æŒ‡å®šåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯$ git merge [branch]# æ”¾å¼ƒè¿™æ¬¡åˆå¹¶$ git merge --abort# åˆ é™¤åˆ†æ”¯$ git branch -d [branch-name]# åˆ é™¤è¿œç¨‹åˆ†æ”¯$ git push origin --delete [branch-name]$ git branch -dr [remote/branch] å¤šä¸ªåˆ†æ”¯å¦‚æœå¹¶è¡Œæ‰§è¡Œï¼Œå°±ä¼šå¯¼è‡´æˆ‘ä»¬çš„ä»£ç ä¸å†²çªï¼Œä¹Ÿå°±æ˜¯åŒæ—¶å­˜åœ¨å¤šä¸ªç‰ˆæœ¬ï¼ å¦‚æœåŒä¸€ä¸ªæ–‡ä»¶åœ¨åˆå¹¶åˆ†æ”¯æ—¶éƒ½è¢«ä¿®æ”¹äº†ï¼Œåˆ™ä¼šå¼•èµ·å†²çªï¼šè§£å†³çš„åŠæ³•æ˜¯æˆ‘ä»¬å¯ä»¥ä¿®æ”¹å†²çªæ–‡ä»¶åé‡æ–°æäº¤ï¼é€‰æ‹©è¦ä¿ç•™ä»–çš„ä»£ç è¿˜æ˜¯ä½ çš„ä»£ç ï¼ masterä¸»åˆ†æ”¯ä¸€èˆ¬éå¸¸ç¨³å®šï¼Œç”¨æ¥å‘å¸ƒæ–°çš„ç‰ˆæœ¬ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ä¸å…è®¸åœ¨ä¸Šé¢è¿›è¡Œå¼€å‘ï¼Œå·¥ä½œä¸€èˆ¬æƒ…å†µä¸‹åœ¨æ–°å»ºçš„devåˆ†æ”¯ä¸Šå·¥ä½œï¼Œå·¥ä½œå®Œæˆåï¼Œæ¯”å¦‚è¦å‘å¸ƒï¼Œåˆ™å¯å°†devåˆ†æ”¯åˆå¹¶åˆ°ä¸»åˆ†æ”¯masterä¸Šæ¥ã€‚ Vscode æ’ä»¶æ¨è GitLens â€” Git supercharged Git History Diff"},{"title":"PyTorch è‡ªç¼–ç å™¨","path":"/wiki/PyTorch/PyTorch è‡ªç¼–ç å™¨.html","content":"æˆ‘ä»¬ä¹‹å‰æ‰€å­¦ä¹ çš„çŸ¥è¯†éƒ½æ˜¯ç›‘ç£å­¦ä¹ ï¼Œç›‘ç£å­¦ä¹ å¾ˆå¤šæ˜¯åŸºäºäººçš„ç»éªŒæ¥å¯¹åˆ†ç±»å›å½’é—®é¢˜è¿›è¡Œåˆ¤æ–­ï¼Œç°åœ¨æˆ‘ä»¬æ¥ç ”ç©¶ä¸€äº›å…³äºéç›‘ç£å­¦ä¹ çš„å†…å®¹ã€‚ é¦–å…ˆä¾¿æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ç ”ç©¶éç›‘ç£å­¦ä¹ ã€‚ éç›‘ç£å­¦ä¹ çš„æ„ä¹‰ æ•°æ®ç»´åº¦å‡å°‘ï¼ˆDimension reductionï¼‰ é¢„å¤„ç†ï¼ˆPreprocessingï¼‰ å¯è§†åŒ–ï¼ˆVisualizationï¼‰ æ›´å¥½çš„åˆ©ç”¨çœ‹ä¸Šå»ä¸é‡è¦çš„æ•°æ®(Taking advantage of unsupervised data) å‹ç¼©ï¼Œé™å™ªï¼Œè¶…åˆ†è¾¨ç‡(Compression,denoising,super-resolution) ä¸€ä¸ªå¯ä»¥å¯è§†åŒ–æ•°æ®çš„ç½‘ç«™ï¼šhttps://projector.tensorflow.org æ€»è€Œè¨€ä¹‹å°±æ˜¯æ›´å¥½çš„åˆ©ç”¨æ•°æ®ï¼Œå¹¶ä»æ•°æ®ä¸­å‘ç°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿ã€‚ Auto-Encoders è‡ªç¼–ç å™¨ï¼ˆautoencoder, AEï¼‰æ˜¯ä¸€ç±»åœ¨åŠç›‘ç£å­¦ä¹ å’Œéç›‘ç£å­¦ä¹ ä¸­ä½¿ç”¨çš„ç¥ç»ç½‘ç»œï¼ˆArtificial Neural Networks, ANNsï¼‰ï¼Œå…¶åŠŸèƒ½æ˜¯é€šè¿‡å°†è¾“å…¥ä¿¡æ¯ä½œä¸ºå­¦ä¹ ç›®æ ‡ï¼Œå¯¹è¾“å…¥ä¿¡æ¯è¿›è¡Œè¡¨å¾å­¦ä¹ ï¼ˆrepresentation learningï¼‰ è‡ªç¼–ç å™¨å…·æœ‰ä¸€èˆ¬æ„ä¹‰ä¸Šè¡¨å¾å­¦ä¹ ç®—æ³•çš„åŠŸèƒ½ï¼Œè¢«åº”ç”¨äº**é™ç»´ï¼ˆdimensionality reductionï¼‰**å’Œå¼‚å¸¸å€¼æ£€æµ‹ï¼ˆanomaly detectionï¼‰ è¾“å…¥è¾“å‡ºä¸€æ ·ï¼Œé‡å»ºè¾“å…¥æ•°æ® ä¸­é—´é‚£ä¸ªå¾ˆå°‘ç¥ç»å…ƒçš„å±‚å«åšneckï¼ˆä¸€èˆ¬æ˜¯å¯¹æ•°æ®è¿›è¡Œé™ç»´ï¼‰ Auto Encoderå°±æ˜¯ä¸€ä¸ªéå¸¸æ™®é€šçš„ç¥ç»ç½‘ç»œ å¦‚ä½•è®­ç»ƒ Loss Function Lose function for real-valued inputs l(f(x))=12âˆ‘k(x^kâˆ’xk)2l(f(x))=\\frac{1}{2}\\sum_k(\\hat{x}_k-x_k)^2 l(f(x))=21â€‹kâˆ‘â€‹(x^kâ€‹âˆ’xkâ€‹)2 x^k\\hat{x}_kx^kâ€‹æ˜¯é‡å»ºåæ•°æ®kä½ç½®çš„å€¼ xkx_kxkâ€‹æ˜¯è¾“å…¥æ•°æ®kä½ç½®çš„å€¼ Loss function for binary inputs l(f(x))=âˆ’âˆ‘k(xkÂ log(x^k)+(1âˆ’xk)log(1âˆ’x^k))l(f(x))=-\\sum_k(x_k\\ log(\\hat{x}_k)+(1-x_k)log(1-\\hat{x}_k)) l(f(x))=âˆ’kâˆ‘â€‹(xkâ€‹Â log(x^kâ€‹)+(1âˆ’xkâ€‹)log(1âˆ’x^kâ€‹)) Cross-entropy error function ä¸€èˆ¬ç”¨äºåˆ†ç±»é—®é¢˜ï¼Œç±»ä¼¼one-hotç¼–ç  å…¶å®è¿˜æ˜¯å’Œæ™®é€šç¥ç»ç½‘ç»œå·®ä¸å¤š AE vs PCA ä½¿ç”¨MNISTæ•°æ®é›†ä½œä¸ºè¾“å…¥ï¼Œç„¶ååˆ†åˆ«ä½¿ç”¨PCAæˆ–AEå¯¹æ•°æ®è¿›è¡Œé™ç»´ï¼Œç„¶åå†é‡æ„ï¼Œæ•ˆæœå›¾å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ äººè„¸æ•°æ®é›†ç¬¬äºŒè¡Œæ˜¯AEï¼Œç¬¬ä¸‰è¡Œæ˜¯PCAï¼Œç»¼ä¸Šï¼Œå¯ä»¥çœ‹å‡ºAEçš„æ•ˆæœè¿˜æ˜¯è¦å¥½ä¸€äº›çš„ã€‚ Denoising Auto-Encoders å°±æ˜¯å¯¹è¾“å…¥æ•°æ®åŠ å™ªå£°ï¼Œä»¥æ­¤è®©æ¨¡å‹ä¸è¦è®°ä½æŸäº›ç‰¹å¾ï¼Œè€Œæ˜¯ç†è§£æŸäº›ç‰¹å¾ï¼Œè®©æ¨¡å‹å‘æ˜ä¸€äº›æ•°æ®é«˜å±‚æ¬¡çš„ç‰¹å¾ã€‚è¿™ç§ç±»å‹çš„AEå¯ä»¥å¯¹å›¾ç‰‡è¿›è¡Œé™å™ªæ“ä½œã€‚ Dropout Auto-Encoders æ­£å¦‚å…¶åï¼Œå’Œæˆ‘ä»¬å‰é¢è®²çš„Dropoutæ˜¯ä¸€ä¸ªæ„æ€ã€‚ Adversarial Auto-Encoders Discriminatorè¿™ä¸€éƒ¨åˆ†çŸ¥è¯†æ¶‰åŠåˆ°GANï¼Œä¼šåœ¨GANéƒ¨åˆ†è®²è§£æ¸…æ¥š æˆ‘ä»¬ç›®å‰åªéœ€è¦çŸ¥é“ï¼Œéšç€è®­ç»ƒæ¬¡æ•°çš„å¢åŠ ï¼Œä¸­é—´çš„éšè—å±‚hæ‰€å¾—çš„æ•°æ®ä¼šå‘ˆç°å‡ºä¸€ç§åˆ†å¸ƒçš„çŠ¶æ€ã€‚ Variational Auto-Encodersï¼ˆVAEï¼‰â€» VAEéå¸¸çš„é‡è¦ï¼Œå…·ä½“åŸç†å¯ä»¥çœ‹è¿™ä¸ªè§†é¢‘æˆ–è¿™ç¯‡åšå®¢ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°äº†ã€‚ï¼ˆå› ä¸ºæœ¬äººè¡¨è¾¾èƒ½åŠ›é—®é¢˜å’Œæ¯”è¾ƒèœï¼Œå¯èƒ½è¯´ä¸å¤ªæ¸…æ¥šï¼‰ é“¾æ¥ï¼šæå®æ¯…è€å¸ˆVAEåŸç† ç›´è§‚ç†è§£ æ³¨æ„ï¼šè¿˜æ˜¯å’ŒAEä¸å¤ªä¸€æ ·ï¼Œå› ä¸ºä¸­é—´æœ‰ä¸€ä¸ªé‡‡æ ·çš„æ“ä½œï¼Œé‡‡æ ·çš„å€¼ä½œä¸ºæå–å‡ºæ¥çš„ç‰¹å¾ã€‚å› æ­¤è¿™ä¸¤å±‚çš„è¿æ¥ä¹Ÿå’Œå…¶ä»–å±‚ä¹‹é—´çš„è¿æ¥ä¹Ÿä¸ä¸€æ ·ï¼Œå¹¶ä¸æ˜¯å…¨è¿æ¥ï¼ï¼ï¼ è¿˜è¦æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬çš„Losså‡½æ•°ä¸ä»…è¦æœ€å°AEä¸­çš„å‡æ–¹å·®ï¼Œè¿˜è¦æœ€å°åŒ–KLdivï¼ˆä¸Šå›¾æ ‡æœ‰Minimizeçš„é»„æ¡†ï¼‰ï¼Œæ‰€ä»¥è¦å°†ä»–ä»¬ä¸¤ä¸ªåŠ èµ·æ¥ä½œä¸ºæœ€ç»ˆçš„lossè¿›è¡Œåå‘ä¼ æ’­ï¼ï¼ï¼ï¼ˆè¿™ä¸ªä¸œè¥¿å¯ä»¥åœ¨ä¸Šé¢çš„é“¾æ¥ä¸­äº†è§£åˆ°è¿™æ˜¯ä»€ä¹ˆï¼‰ VAEä¸åŒäºAEï¼Œå­¦ä¹ çš„ä¸æ˜¯å•ä¸ªå‘é‡ï¼Œè€Œæ˜¯åˆ†å¸ƒï¼ï¼ï¼å› æ­¤å…·æœ‰ä¸€å®šçš„æ¨ç†èƒ½åŠ›ï¼Œç›´è§‚ç†è§£è§ä¸‹å›¾çš„ä¾‹å­ ç»¼ä¸Šï¼ŒVAEè™½ç„¶æ•ˆæœæ¯”AEå¥½ï¼Œä½†æ˜¯æ ¹æ®ä»–çš„åŸç†ï¼Œä»–æœ¬è´¨ä¸Šåªæ˜¯è®°ä½äº†ç°æœ‰æ•°æ®çš„ç‰¹å¾ï¼Œå¹¶æ²¡æœ‰å­¦ä¹ å¦‚ä½•ç”Ÿæˆæ•°æ®ï¼ˆåªæ˜¯å†ä¸€ä¸ªç¡®å®šåˆ†å¸ƒå†…éšæœºï¼‰ï¼Œè¿™æ˜¯VAEæœ€å¤§çš„ä¸€ä¸ªé—®é¢˜ï¼Œè§£å†³è¿™ä¸ªé—®é¢˜éœ€è¦ä½¿ç”¨æˆ‘ä»¬åé¢é©¬ä¸Šä¼šè®²è§£çš„GANã€‚ Pytochå®æˆ˜ Auto-Encoderå®éªŒ ç›®æ ‡ æœ¬æ¬¡å®éªŒçš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªAuto-Encoderé‡æ„MNISTæ•°æ®é›†ã€‚ ä»£ç å®ç° å…¶å®ä»£ç éƒ½å’Œæœ€ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œéå¸¸çš„ç›¸ä¼¼ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ï¼Œç›´æ¥è´´ä»£ç ã€‚ é¦–å…ˆæ˜¯ç½‘ç»œç»“æ„çš„ä»£ç ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041class AE(nn.Module): def __init__(self) -&gt; None: super(AE,self).__init__() # Encoder # [b,784] =&gt; [b,20] self.encoder = nn.Sequential( nn.Linear(784,256), nn.ReLU(), nn.Linear(256,64), nn.ReLU(), nn.Linear(64, 20), nn.ReLU() ) # Decoder # [b,20] =&gt; [b,784] self.decoder = nn.Sequential( nn.Linear(20,64), nn.ReLU(), nn.Linear(64,256), nn.ReLU(), nn.Linear(256,784), nn.Sigmoid() ) def forward(self, x): batchsz = x.size(0) # flatten x = x.view(batchsz,784) # encoder x = self.encoder(x) # decoder x = self.decoder(x) # reshape x = x.view(batchsz,1,28,28) return x æ³¨æ„è¿™é‡Œæˆ‘ä»¬ç½‘ç»œç»“æ„æ˜¯æ‹†æˆäº†encoderå’Œdecoderçš„ï¼Œè¿™æ ·ä½¿å¾—ç½‘ç»œç»“æ„æ›´åŠ çš„æ¸…æ™°ï¼ è®­ç»ƒæµ‹è¯•éƒ¨åˆ†ä¸»ä»£ç ï¼ˆæ²¡æœ‰åŒºåˆ«ï¼Œ åªæ˜¯å¤šåšäº†ä¸€ä¸ªå¯è§†åŒ– ï¼‰ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142def main(): mnist_train = datasets.MNIST(&#x27;mnist&#x27;, True, transform=transforms.Compose([ transforms.ToTensor() ]), download=True) mnist_train = DataLoader(mnist_train,batch_size=32,shuffle=True) mnist_test = datasets.MNIST(&#x27;mnist&#x27;, False, transform=transforms.Compose([ transforms.ToTensor() ]), download=True) mnist_test = DataLoader(mnist_test,batch_size=32,shuffle=True) x,_ = iter(mnist_train).next() print(&#x27;x:&#x27;, x.shape) device = torch.device(&#x27;cuda&#x27;) model = AE().to(device) print(model) criteon = nn.MSELoss() optimizer = optim.Adam(model.parameters(),lr=1e-3) viz =visdom.Visdom() for epoch in range(1000): for batchidx, (x,_) in enumerate(mnist_train): x = x.to(device) x_hat = model(x) loss = criteon(x_hat,x) # backprop optimizer.zero_grad() loss.backward() optimizer.step() print(epoch , &quot;loss:&quot;, loss.item()) x,_ = iter(mnist_test).next() x = x.to(device) with torch.no_grad(): x_hat = model(x) viz.images(x,nrow=8,win=&#x27;x&#x27;,opts=dict(title=&#x27;x&#x27;)) viz.images(x_hat,nrow=8,win=&#x27;x_hat&#x27;,opts=dict(title=&#x27;x_hat&#x27;)) ç»“æœ é‡å»ºç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå°½ç®¡è¿™ä¸ªæ•°æ®é›†éå¸¸çš„ç®€å•ï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜æ˜¯å¯ä»¥çœ‹å‡ºï¼Œè¿˜æ˜¯æœ‰ä¸€äº›æ•°æ®é‡å»ºçš„å¹¶ä¸æ˜¯éå¸¸çš„ç†æƒ³ã€‚ VAEå®éªŒ ç›®æ ‡ æœ¬æ¬¡å®éªŒçš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªVAEé‡æ„MNISTæ•°æ®é›†ã€‚ å› ä¸ºVAEä¸­é—´æœ‰ä¸€ä¸ªæ“ä½œæ˜¯é‡‡æ ·ï¼Œè€Œé‡‡æ ·è¿™ä¸ªæ“ä½œæ˜¯ä¸å¯å¯¼çš„ï¼Œå› æ­¤åœ¨å®é™…ä»£ç å®ç°ä¸­è¿™é‡Œæœ‰ä¸€ä¸ªå°trickã€‚ ä»£ç å®ç° ç½‘ç»œç»“æ„ä»£ç å’ŒAEä»£ç æ˜¯ä¸€æ ·çš„ï¼ˆè¿˜æ˜¯æœ‰ä¸€ç‚¹ä¸ä¸€æ · decoderèµ·å§‹ç¥ç»å…ƒæ•°é‡å˜ä¸º10ï¼Œæ³¨æ„æ”¹ä¸€ä¸‹ï¼ ï¼‰ï¼Œä¸ä¸€æ ·çš„éƒ¨åˆ†ä½“ç°åœ¨forwardéƒ¨åˆ†ï¼ˆåœ¨encoderå’Œdecoderä¸­é—´å¢åŠ äº†é‡‡æ ·ï¼‰ï¼Œè¿™é‡Œå°±ä½¿ç”¨åˆ°äº†æˆ‘ä»¬çš„trickï¼Œåˆ©ç”¨pytorchè‡ªå¸¦çš„åˆ†å¸ƒç”Ÿæˆå™¨ï¼Œå¯ä»¥ç”Ÿæˆå¯å¯¼çš„é‡‡æ ·æ“ä½œã€‚æ³¨æ„forwardæœ€åè¿”å›äº†kldå“¦ï¼ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class VAE(nn.Module): def __init__(self): super(VAE, self).__init__() # [b, 784] =&gt; [b, 20] # u: [b, 10] # sigma: [b, 10] self.encoder = nn.Sequential( nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 64), nn.ReLU(), nn.Linear(64, 20), nn.ReLU() ) # [b, 20] =&gt; [b, 784] self.decoder = nn.Sequential( nn.Linear(10, 64), nn.ReLU(), nn.Linear(64, 256), nn.ReLU(), nn.Linear(256, 784), nn.Sigmoid() ) self.criteon = nn.MSELoss() def forward(self, x): &quot;&quot;&quot; :param x: [b, 1, 28, 28] :return: &quot;&quot;&quot; batchsz = x.size(0) # flatten x = x.view(batchsz, 784) # encoder # [b, 20], including mean and sigma h_ = self.encoder(x) # [b, 20] =&gt; [b, 10] and [b, 10] mu, sigma = h_.chunk(2, dim=1) # reparametrize trick, epison~N(0, 1) h = mu + sigma * torch.randn_like(sigma) # decoder x_hat = self.decoder(h) # reshape x_hat = x_hat.view(batchsz, 1, 28, 28) kld = 0.5 * torch.sum( torch.pow(mu, 2) + torch.pow(sigma, 2) - torch.log(1e-8 + torch.pow(sigma, 2)) - 1 ) / (batchsz*28*28) return x_hat, kld ç„¶åå°±æ˜¯è®­ç»ƒéƒ¨åˆ†çš„ä»£ç äº†ï¼Œè¿™é‡Œä¹Ÿå°±åªæœ‰losså‡½æ•°æ”¹äº†ä¸€ä¸‹ã€‚ 12345x_hat, kld = model(x)loss = criteon(x_hat, x)if kld is not None: elbo = - loss - 1.0 * kld loss = - elbo å®Œæ•´ä»£ç ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def main(): mnist_train = datasets.MNIST(&#x27;mnist&#x27;, True, transform=transforms.Compose([ transforms.ToTensor() ]), download=True) mnist_train = DataLoader(mnist_train, batch_size=32, shuffle=True) mnist_test = datasets.MNIST(&#x27;mnist&#x27;, False, transform=transforms.Compose([ transforms.ToTensor() ]), download=True) mnist_test = DataLoader(mnist_test, batch_size=32, shuffle=True) x, _ = iter(mnist_train).next() print(&#x27;x:&#x27;, x.shape) device = torch.device(&#x27;cuda&#x27;) # model = AE().to(device) model = VAE().to(device) criteon = nn.MSELoss() optimizer = optim.Adam(model.parameters(), lr=1e-3) print(model) viz = visdom.Visdom() for epoch in range(1000): for batchidx, (x, _) in enumerate(mnist_train): # [b, 1, 28, 28] x = x.to(device) x_hat, kld = model(x) loss = criteon(x_hat, x) if kld is not None: elbo = - loss - 1.0 * kld loss = - elbo # backprop optimizer.zero_grad() loss.backward() optimizer.step() print(epoch, &#x27;loss:&#x27;, loss.item(), &#x27;kld:&#x27;, kld.item()) x, _ = iter(mnist_test).next() x = x.to(device) with torch.no_grad(): x_hat, kld = model(x) viz.images(x, nrow=8, win=&#x27;x&#x27;, opts=dict(title=&#x27;x&#x27;)) viz.images(x_hat, nrow=8, win=&#x27;x_hat&#x27;, opts=dict(title=&#x27;x_hat&#x27;)) ç»“æœ é‡å»ºç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒVAEé‡å»ºçš„æ‰€æœ‰æ•°å­—åŸºæœ¬ä¸Šæ˜¯å¯ä»¥çœ‹æ¸…æ¥šçš„ï¼Œä½†æ˜¯å› ä¸ºæ­¤æ•°æ®é›†æ¯”è¾ƒç®€å•çš„ç¼˜æ•…ï¼ŒVAEç›¸æ¯”äºAEçš„ä¼˜åŠ¿å¹¶æ²¡æœ‰å¾ˆå¥½çš„ä½“ç°å‡ºæ¥ã€‚"},{"title":"PyTorchå…¥é—¨-ç®€å•BPå…¨è¿æ¥ç¥ç»ç½‘ç»œ","path":"/wiki/PyTorch/PyTorchå…¥é—¨-ç®€å•BPç¥ç»ç½‘ç»œ.html","content":"ç®€ä»‹ å› ä¸ºè¯¾ç¨‹éœ€è¦å­¦ä¹ PyTorchï¼Œæ‰€ä»¥è¿™é‡Œå°±å…ˆç®€å•çš„å…¥ä¸ªé—¨ï¼Œä½¿ç”¨PyTorchå®ç°ä¸€ä¸ªç®€å•çš„3å±‚BPå…¨è¿æ¥ç¥ç»ç½‘ç»œå®éªŒã€‚å®éªŒä½¿ç”¨çš„æ•°æ®é›†æ˜¯MNISTæ‰‹å†™æ•°å­—è¯†åˆ«æ•°æ®é›†ã€‚ æˆ‘ä»¬è®¾è®¡çš„ç½‘ç»œç»“æ„æ˜¯4å±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œå› ä¸ºä¸€ä¸ªæ•°å­—æ‰€å­˜å‚¨çš„åƒç´ ä¿¡æ¯æ˜¯28Ã—28Ã—128\\times 28\\times 128Ã—28Ã—1å› æ­¤ï¼Œç½‘ç»œçš„ç¬¬ä¸€å±‚æœ‰28Ã—28Ã—1=78428\\times 28 \\times 1=78428Ã—28Ã—1=784ä¸ªç¥ç»å…ƒï¼Œç¬¬äºŒå±‚è®¾è®¡çš„æœ‰ 256ä¸ªç¥ç»å…ƒï¼Œç¬¬ä¸‰å±‚æœ‰64ä¸ªç¥ç»å…ƒï¼Œç¬¬å››å±‚æœ‰10ä¸ªç¥ç»å…ƒã€‚å…¶ä¸­ç¬¬ä¸€å±‚å’Œç¬¬äºŒå±‚ï¼Œç¬¬äºŒå±‚å’Œç¬¬ä¸‰å±‚ï¼Œç¬¬ä¸‰å±‚å’Œç¬¬å››å±‚ä¹‹é—´ï¼Œéƒ½æœ‰ä¸€ä¸ªreluæ¿€æ´»å‡½æ•°ã€‚æœ€åç¬¬å››å±‚çš„1Ã—101\\times 101Ã—10è¾“å‡ºå‘é‡ç›¸å½“äºæ˜¯å¯¹10ä¸ªæ•°å­—çš„è¯†åˆ«ç›¸ä¼¼åº¦ï¼Œæœ€å¤§çš„æ•°çš„indexä»£è¡¨è¯†åˆ«å‡ºæ¥ç›¸ä¼¼åº¦æœ€é«˜çš„æ•°å­—ã€‚ ç½‘ç»œæ„å»ºéƒ¨åˆ†çš„ä»£ç å®ç°å¦‚ä¸‹ï¼š 1234567891011121314151617181920class Net(nn.Module): def __init__(self): super(Net, self).__init__() # xw+b self.fc1 = nn.Linear(28*28, 256) self.fc2 = nn.Linear(256, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): # x: [b, 1, 28, 28] # h1 = relu(xw1+b1) x = F.relu(self.fc1(x)) # h2 = relu(h1w2+b2) x = F.relu(self.fc2(x)) # h3 = h2w3+b3 x = self.fc3(x) return x å®šä¹‰æŸå¤±å‡½æ•°æ˜¯ï¼š cost=âˆ‘(predâˆ’Y)2cost=\\sum(pred-Y)^2 cost=âˆ‘(predâˆ’Y)2 ä»£ç å®ç°ä¸è®²è§£ æ•°æ®è½½å…¥ 123456789101112131415161718192021222324252627282930313233343536import torchfrom torch import nnfrom torch.nn import functional as Ffrom torch import optimimport torchvisionfrom matplotlib import pyplot as pltfrom utils import plot_image, plot_curve, one_hotbatch_size = 512 #æ‰¹# step1. load datasettrain_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(&#x27;mnist_data&#x27;, train=True, download=True, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)test_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(&#x27;mnist_data/&#x27;, train=False, download=True, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=False)x, y = next(iter(train_loader))print(x.shape, y.shape, x.min(), x.max())plot_image(x, y, &#x27;image sample&#x27;) è¿™é‡Œå°±æ˜¯è½½å…¥äº†è®­ç»ƒé›†train_loaderå’Œtest_loader ç„¶åå€’æ•°ç¬¬ä¸‰è¡Œçš„nextè¿”å›çš„æ˜¯è®­ç»ƒé›†ä¸­ä¸‹ä¸€ä¸ªå…ƒç´ ï¼ˆä¸‹ä¸€ä¸ªbatchï¼‰ï¼Œå› ä¸ºæ˜¯batchå¤§å°æ˜¯512ï¼Œæ‰€ä»¥printå‡ºæ¥çš„xå’Œyçš„ç»´åº¦å¦‚ä¸‹æ‰€ç¤ºã€‚ 1torch.Size([512, 1, 28, 28]) torch.Size([512]) tensor(-0.4242) tensor(2.8215) å»ºç«‹ç½‘ç»œ ä¸Šé¢å·²ç»è¿›è¡Œè¿‡è®²è§£äº†ï¼Œè¿™é‡Œä¸å†èµ˜è¿° 1234567891011121314151617181920class Net(nn.Module): def __init__(self): super(Net, self).__init__() # xw+b self.fc1 = nn.Linear(28*28, 256) self.fc2 = nn.Linear(256, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): # x: [b, 1, 28, 28] # h1 = relu(xw1+b1) x = F.relu(self.fc1(x)) # h2 = relu(h1w2+b2) x = F.relu(self.fc2(x)) # h3 = h2w3+b3 x = self.fc3(x) return x åˆå§‹åŒ–å‚æ•° 123net = Net() # å®ä¾‹åŒ–å¯¹è±¡ï¼Œè¿™é‡Œå°±æ˜¯æˆ‘ä»¬å»ºç«‹çš„ç½‘ç»œ# [w1, b1, w2, b2, w3, b3]optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) # åˆå§‹åŒ–å‚æ•°ï¼ˆè®¾ç½®è¶…å‚æ•°å’Œéšæœºåˆå§‹åŒ–å‚æ•°ï¼‰ å¼€å§‹è®­ç»ƒ 1234567891011121314151617181920212223for epoch in range(3): for batch_idx, (x, y) in enumerate(train_loader): # x: [b, 1, 28, 28], y: [512] # [b, 1, 28, 28] =&gt; [b, 784] x = x.view(x.size(0), 28*28) # =&gt; [b, 10] out = net(x) # [b, 10] y_onehot = one_hot(y) # loss = mse(out, y_onehot) loss = F.mse_loss(out, y_onehot) optimizer.zero_grad() loss.backward() # w&#x27; = w - lr*grad optimizer.step() train_loss.append(loss.item()) if batch_idx % 10==0: print(epoch, batch_idx, loss.item()) epochä»£è¡¨è®­ç»ƒçš„è½®æ•°ï¼Œè¿™é‡Œä¸€å…±è®­ç»ƒä¸‰è½®ã€‚ç„¶åæ¯ä¸€è½®ä¸­æ¯æ¬¡è®­ç»ƒå–å‡ºåŒä¸€batchä¸‹çš„æ‰€æœ‰è®­ç»ƒæ•°æ®ï¼ˆä¸€å…±512ç»„ï¼‰ï¼Œæ³¨é‡Šä¸­çš„b=512 ç„¶åå…ˆè¿›è¡Œreshapeã€‚ä»£ç ä¸­çš„viewå®ç°çš„åŠŸèƒ½ç±»ä¼¼numpyä¸­reshapeã€‚è¿™é‡Œå°±å°†Xä»ä¸€ä¸ªå››ç»´æ•°ç»„512Ã—1Ã—28Ã—28512\\times 1 \\times 28\\times 28512Ã—1Ã—28Ã—28è½¬åŒ–ä¸ºäº†512Ã—784512 \\times 784512Ã—784çš„äºŒç»´æ•°ç»„ã€‚ç„¶åæ‰”å…¥ç½‘ç»œè¿›è¡Œè®­ç»ƒï¼Œå°†yæ ‡ç­¾å…ˆè½¬åŒ–ä¸ºç‹¬çƒ­ç¼–ç å’Œç½‘ç»œæ‰”å‡ºçš„å€¼ç»“åˆè®¡ç®—lossã€‚è®¡ç®—ç»“æŸåå°±è¿›è¡Œä»¥ä¸‹ä¸‰æ­¥ï¼š 1234optimizer.zero_grad() # å°†æ¨¡å‹çš„å‚æ•°æ¢¯åº¦åˆå§‹åŒ–ä¸º0 loss.backward() # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ # w&#x27; = w - lr*grad optimizer.step() # æ›´æ–°æ‰€æœ‰å‚æ•° æ€»ç»“ä¸€ä¸‹ï¼Œè®­ç»ƒè¿‡ç¨‹çš„ä»£ç ä¸€èˆ¬å°±ä»¥ä¸‹å‡ å—ï¼š 12345678910optimizer.zero_grad() # å°†æ¨¡å‹çš„å‚æ•°æ¢¯åº¦åˆå§‹åŒ–ä¸º0outputs=modelï¼ˆinputsï¼‰ # å‰å‘ä¼ æ’­è®¡ç®—é¢„æµ‹å€¼loss = cost(outputs, y_train) # è®¡ç®—å½“å‰æŸå¤±loss.backward() # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦optimizer.step() # æ›´æ–°æ‰€æœ‰å‚æ•° ç„¶åè®­ç»ƒè¿‡ç¨‹å°±ç»“æŸäº†ï¼Œä¸‹é¢å°±æ˜¯æµ‹è¯•ç¯èŠ‚äº†ã€‚ è¿›è¡Œæµ‹è¯• 1234567891011121314151617total_correct = 0for x,y in test_loader: x = x.view(x.size(0), 28*28) out = net(x) # out: [b, 10] =&gt; pred: [b] pred = out.argmax(dim=1) correct = pred.eq(y).sum().float().item() total_correct += correcttotal_num = len(test_loader.dataset)acc = total_correct / total_numprint(&#x27;test acc:&#x27;, acc)x, y = next(iter(test_loader))out = net(x.view(x.size(0), 28*28))pred = out.argmax(dim=1)plot_image(x, pred, &#x27;test&#x27;) åŒç†ï¼Œå’Œè®­ç»ƒè¿‡ç¨‹å¾ˆåƒï¼Œä¹Ÿæ˜¯å…ˆä½¿ç”¨viewï¼Œreshapeä¸€ä¸‹åï¼Œæ‰”å…¥ç½‘ç»œï¼Œå¾—åˆ°outåï¼Œå¯»æ‰¾æ•°å€¼æœ€å¤§çš„ä¸‹æ ‡è®°å½•åœ¨predä¸­ï¼Œpredå°±æ˜¯æµ‹è¯•é¢„æµ‹çš„æ•°å€¼ï¼Œç„¶åå°±å¯ä»¥è®¡ç®—æ­£ç¡®ç‡ç­‰è¯„ä»·æŒ‡æ ‡äº†ã€‚ æ€»ç»“ ä¸åŒäºtensorflowçš„place_holder,pytorchç½‘ç»œå®šä¹‰æ›´åŠ ç®€å•ä¾¿æ·ï¼Œåªéœ€è¦ä½¿ç”¨ç±»ä¼¼nn.Linear(a,b)çš„å‡½æ•°å®šä¹‰è¿æ¥æ–¹å¼ï¼Œç„¶åæœ€åå®ä¾‹åŒ–ç½‘ç»œçš„æ—¶å€™ä¼ å…¥ä¸€ä¸ªparameter()å°±å¯ä»¥äº†ï¼Œç›¸æ¯”äºtensorflowç¡®å®æ›´åŠ ç®€å•ã€‚ æœ€ç»ˆä»£ç  mnist_train.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114import torchfrom torch import nnfrom torch.nn import functional as Ffrom torch import optimimport torchvisionfrom matplotlib import pyplot as pltfrom utils import plot_image, plot_curve, one_hotbatch_size = 512 #æ‰¹# step1. load datasettrain_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(&#x27;mnist_data&#x27;, train=True, download=True, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)test_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(&#x27;mnist_data/&#x27;, train=False, download=True, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize( (0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=False)x, y = next(iter(train_loader))print(x.shape, y.shape, x.min(), x.max())plot_image(x, y, &#x27;image sample&#x27;)class Net(nn.Module): def __init__(self): super(Net, self).__init__() # xw+b self.fc1 = nn.Linear(28*28, 256) self.fc2 = nn.Linear(256, 64) self.fc3 = nn.Linear(64, 10) def forward(self, x): # x: [b, 1, 28, 28] # h1 = relu(xw1+b1) x = F.relu(self.fc1(x)) # h2 = relu(h1w2+b2) x = F.relu(self.fc2(x)) # h3 = h2w3+b3 x = self.fc3(x) return xnet = Net()# [w1, b1, w2, b2, w3, b3]optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)train_loss = []for epoch in range(3): for batch_idx, (x, y) in enumerate(train_loader): # x: [b, 1, 28, 28], y: [512] # [b, 1, 28, 28] =&gt; [b, 784] x = x.view(x.size(0), 28*28) # =&gt; [b, 10] out = net(x) # [b, 10] y_onehot = one_hot(y) # loss = mse(out, y_onehot) loss = F.mse_loss(out, y_onehot) optimizer.zero_grad() loss.backward() # w&#x27; = w - lr*grad optimizer.step() train_loss.append(loss.item()) if batch_idx % 10==0: print(epoch, batch_idx, loss.item())plot_curve(train_loss) # ç”»å‡ºæŸå¤±å‡½æ•°# we get optimal [w1, b1, w2, b2, w3, b3]total_correct = 0for x,y in test_loader: x = x.view(x.size(0), 28*28) out = net(x) # out: [b, 10] =&gt; pred: [b] pred = out.argmax(dim=1) correct = pred.eq(y).sum().float().item() total_correct += correcttotal_num = len(test_loader.dataset)acc = total_correct / total_numprint(&#x27;test acc:&#x27;, acc)x, y = next(iter(test_loader))out = net(x.view(x.size(0), 28*28))pred = out.argmax(dim=1)plot_image(x, pred, &#x27;test&#x27;) utils.py 1234567891011121314151617181920212223242526272829303132import torchfrom matplotlib import pyplot as pltdef plot_curve(data): fig = plt.figure() plt.plot(range(len(data)), data, color=&#x27;blue&#x27;) plt.legend([&#x27;value&#x27;], loc=&#x27;upper right&#x27;) plt.xlabel(&#x27;step&#x27;) plt.ylabel(&#x27;value&#x27;) plt.show()def plot_image(img, label, name): fig = plt.figure() for i in range(6): plt.subplot(2, 3, i + 1) plt.tight_layout() plt.imshow(img[i][0]*0.3081+0.1307, cmap=&#x27;gray&#x27;, interpolation=&#x27;none&#x27;) plt.title(&quot;&#123;&#125;: &#123;&#125;&quot;.format(name, label[i].item())) plt.xticks([]) plt.yticks([]) plt.show()def one_hot(label, depth=10): out = torch.zeros(label.size(0), depth) idx = torch.LongTensor(label).view(-1, 1) out.scatter_(dim=1, index=idx, value=1) return out ç»“æœ æœ€ç»ˆå¯ä»¥å‘ç°æ‰“å°å‡ºæ¥çš„å‡é¢„æµ‹æ­£ç¡®ã€‚accä¸º0.8794ï¼Œæ˜¯å¯ä»¥æ¥å—çš„æ­£ç¡®ç‡ã€‚"},{"title":"PyTorchæ¢¯åº¦","path":"/wiki/PyTorch/PyTorchæ¢¯åº¦.html","content":"æ¢¯åº¦ æ¢¯åº¦çš„æ–¹å‘ä»£è¡¨çš„æ˜¯ä»å°åˆ°å¤§çš„æ–¹å‘ Î¸t+1=Î¸tâˆ’Î±tâˆ‡f(Î¸t)\\theta_{t+1}=\\theta_t-\\alpha_t abla f(\\theta_t) Î¸t+1â€‹=Î¸tâ€‹âˆ’Î±tâ€‹âˆ‡f(Î¸tâ€‹) An overview of gradient descent optimization algorithms (ruder.io) æœä¸åˆ°å…¨å±€æœ€å°å€¼çš„åŸå›  å±€éƒ¨æœ€å°å€¼ éç‚¹ å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œéç‚¹æ¯”å±€éƒ¨æœ€å°å€¼å¸¦æ¥çš„å½±å“æ›´ä¸ºä¸¥é‡ å¸¸è§å‡½æ•°çš„æ¢¯åº¦ æ¿€æ´»å‡½æ•°å’Œæ¢¯åº¦ sigmoid sigmoid(x)=11+eâˆ’xsigmoid(x)=\\frac{1}{1+e^{-x}} sigmoid(x)=1+eâˆ’x1â€‹ ä¼˜ç‚¹ è¿ç»­ å…‰æ»‘ èŒƒå›´01ï¼Œé€‚åˆäºä¸€äº›è¾“å‡ºéœ€è¦æ§åˆ¶åœ¨01çš„åœºæ™¯ï¼ˆeg:æ¦‚ç‡ï¼Œrgbå€¼ï¼‰ ç¼ºç‚¹ å½“èŒƒå›´è¶‹äº+âˆ+\\infty+âˆæˆ–âˆ’âˆ-\\inftyâˆ’âˆæ—¶ï¼Œå› ä¸ºå¯¼æ•°è¾ƒå°ï¼Œæ‰€ä»¥å‚æ•°æ›´æ–°ä¼šéå¸¸çš„ç¼“æ…¢ï¼Œæ”¶æ•›é€Ÿåº¦æ…¢ PyTorchå®ç° 1234567891011121314151617In [3]: a=torch.linspace(-100,100,10)In [4]: aOut[4]: tensor([-100.0000, -77.7778, -55.5556, -33.3333, -11.1111, 11.1111, 33.3333, 55.5556, 77.7778, 100.0000])In [5]: torch.sigmoid(a)Out[5]: tensor([0.0000e+00, 1.6655e-34, 7.4564e-25, 3.3382e-15, 1.4945e-05, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])In [6]: from torch.nn import functional as FIn [7]: F.sigmoid(a)D:\\App\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch n\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead. warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)Out[7]: tensor([0.0000e+00, 1.6655e-34, 7.4564e-25, 3.3382e-15, 1.4945e-05, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00]) tanh tanh(x)=exâˆ’eâˆ’xex+eâˆ’x=2sigmoid(2x)âˆ’1tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}=2sigmoid(2x)-1 tanh(x)=ex+eâˆ’xexâˆ’eâˆ’xâ€‹=2sigmoid(2x)âˆ’1 ddxtanh(x)=1âˆ’tanh2(x)\\frac{d}{dx}tanh(x)=1-tanh^2(x) dxdâ€‹tanh(x)=1âˆ’tanh2(x) åœ¨RNNä¸­ä½¿ç”¨è¾ƒå¤šã€‚ PyTorchå®ç° 12345In [3]: a=torch.linspace(-1,1,10)In [4]: torch.tanh(a)Out[4]: tensor([-0.7616, -0.6514, -0.5047, -0.3215, -0.1107, 0.1107, 0.3215, 0.5047, 0.6514, 0.7616]) Rectified Linear Unit(ReLU) f(x)={0forÂ x&lt;0xforÂ xâ‰¥0f(x)=\\begin{cases} 0\\quad for\\ x&lt;0\\\\ x\\quad for\\ x\\ge0 \\end{cases} f(x)={0forÂ x&lt;0xforÂ xâ‰¥0â€‹ ç»è¿‡å¤§é‡å®éªŒéªŒè¯ï¼ŒReLUå‡½æ•°è¢«è¯æ˜éå¸¸é€‚ç”¨äºæ·±åº¦å­¦ä¹ ã€‚ Pytochå®ç° 12345678910In [3]: a=torch.linspace(-1,1,10)In [4]: torch.relu(a)Out[4]: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1111, 0.3333, 0.5556, 0.7778, 1.0000])In [5]: aOut[5]: tensor([-1.0000, -0.7778, -0.5556, -0.3333, -0.1111, 0.1111, 0.3333, 0.5556, 0.7778, 1.0000]) Losså‡½æ•°å’Œæ¢¯åº¦ å¸¸è§çš„Losså‡½æ•° å‡æ–¹å·®Losså‡½æ•°ï¼ˆMean Square Errorï¼‰ Cross Entropy Loss äºŒåˆ†ç±»ï¼ˆbinaryï¼‰ å¤šåˆ†ç±»ï¼ˆmulti-classï¼‰ softmax MSE loss=âˆ‘[yâˆ’(xw+b)2]loss=\\sum[y-(xw+b)^2] loss=âˆ‘[yâˆ’(xw+b)2] æ³¨æ„å’Œ2èŒƒæ•°è¿›è¡ŒåŒºåˆ†ï¼ˆL2_normï¼‰ L2_norm=âˆ£âˆ£yâˆ’(xw+b)âˆ£âˆ£2L2\\_norm=||y-(xw+b)||_2 L2_norm=âˆ£âˆ£yâˆ’(xw+b)âˆ£âˆ£2â€‹ loss=norm(yâˆ’(xw+b))2loss=norm(y-(xw+b))^2 loss=norm(yâˆ’(xw+b))2 PyTorchä¸­è¿›è¡Œè¡¨ç¤ºç»“æœå¦‚ä¸‹ï¼š 1torch.norm(y-pred,2).pow(2) å¯¹mseå‡½æ•°æ±‚å¯¼è¡¨è¾¾å¼å¦‚ä¸‹ï¼š loss=âˆ‘[yâˆ’fÎ¸(x)]2loss=\\sum[y-f_\\theta(x)]^2 loss=âˆ‘[yâˆ’fÎ¸â€‹(x)]2 âˆ‡lossâˆ‡Î¸=2âˆ‘[yâˆ’fÎ¸(x)]âˆ—âˆ‡fÎ¸(x)âˆ‡Î¸\\frac{ abla loss}{ abla \\theta}=2\\sum[y-f_\\theta(x)]*\\frac{ abla f_\\theta(x)}{ abla\\theta} âˆ‡Î¸âˆ‡lossâ€‹=2âˆ‘[yâˆ’fÎ¸â€‹(x)]âˆ—âˆ‡Î¸âˆ‡fÎ¸â€‹(x)â€‹ è¡¥å……ï¼šåœ¨PyTorchä¸­å®ç°è‡ªåŠ¨æ±‚å¯¼â€» autograd.grad 123456789In [3]: x=torch.ones(1)In [4]: w=torch.tensor([2.],requires_grad=True)# importantIn [5]: from torch.nn import functional as FIn [6]: mse=F.mse_loss(torch.ones(1),x*w)#label,predIn [7]: mseOut[7]: tensor(1., grad_fn=&lt;MseLossBackward0&gt;)In [8]: torch.autograd.grad(mse,[w])Out[8]: (tensor([2.]),) loss.backwardâ€» æ¥ä¸Šé¢ 1234In [9]: mse=F.mse_loss(torch.ones(1),x*w)In [10]: mse.backward()In [11]: w.gradOut[11]: tensor([2.]) ä¸€èˆ¬ä½¿ç”¨ä¸‹é¢è¿™ç§ è¡¥å……ï¼šsoftmax soft version of max æˆ‘ä»¬å‡è®¾ï¼Œå·¦è¾¹æ²¡æœ‰è¿›å…¥softmaxå±‚çš„ç‰¹å¾å‘é‡ä¸ºaaaå³è¾¹ç»è¿‡äº†softmaxå±‚çš„ç‰¹å¾å‘é‡ä¸ºppp,é‚£ä¹ˆæœ‰ã€‚ âˆ‚piâˆ‚aj={pi(1âˆ’pj)ifÂ i=jâˆ’pjpiifÂ iâ‰ j\\frac{\\partial p_i}{\\partial a_j}=\\begin{cases} p_i(1-p_j)\\quad if \\ i=j\\\\ -p_jp_i\\quad if\\ i e j \\end{cases} âˆ‚ajâ€‹âˆ‚piâ€‹â€‹={piâ€‹(1âˆ’pjâ€‹)ifÂ i=jâˆ’pjâ€‹piâ€‹ifÂ iî€ =jâ€‹ pytorch ä»£ç éªŒè¯å¦‚ä¸‹ï¼š 12345678910In [3]: a=torch.rand(3)In [4]: a.requires_grad_()Out[4]: tensor([0.1714, 0.4650, 0.7201], requires_grad=True)In [5]: from torch.nn import functional as FIn [6]: p=F.softmax(a,dim=0)In [7]: p.sum().backward()# å¦‚æœè¿™é‡Œä¸æ±‚å’Œï¼Œå°±è¦åœ¨backwardä¸­ æŒ‡å®šä¸€ä¸ªå’Œpä¸€æ ·å¤§çš„tensorï¼Œè¯¦æƒ…è§ï¼šä¸‹é¢çš„çº¢è‰²æ¡†ä¸­çš„blogIn [8]: a.gradOut[8]: tensor([0., 0., 0.])In [9]: p.gradOut[9]: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won&#x27;t be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:417.) [gradcan be implicitly created only for scalar outputs_](https://blog.csdn.net/qq_39208832/article/details/117415229#:~:text=1.1 grad can be implicitly created only for,æ˜¯ä¸€ä¸ª æ ‡é‡ (å³å®ƒåŒ…å«ä¸€ä¸ªå…ƒç´ çš„æ•°æ®ï¼‰ï¼Œåˆ™ä¸éœ€è¦ä¸º backward () æŒ‡å®šä»»ä½•å‚æ•°ï¼Œä½†æ˜¯å¦‚æœå®ƒæœ‰æ›´å¤šçš„å…ƒç´ ï¼Œåˆ™éœ€è¦æŒ‡å®šä¸€ä¸ª gradient å‚æ•°ï¼Œè¯¥å‚æ•°æ˜¯å½¢çŠ¶åŒ¹é…çš„å¼ é‡ã€‚) Psï¼šè¿™é‡Œå°†pæ±‚å’Œï¼Œå’Œä¸å°†pæ±‚å’Œå¯¹aæ±‚å¯¼çš„æœ€ç»ˆç»“æœæ˜¯ä¸€æ ·çš„ï¼Œå› ä¸ºæ ¹æ®é“¾å¼æ³•åˆ™ï¼Œæœ€åæ±‚å’Œæ¯ä¸ªpçš„éƒ¨åˆ†å‰é¢çš„ç³»æ•°éƒ½æ˜¯1ï¼Œæ‰€ä»¥ä¹˜ä¸Š1ä¸å½±å“æœ€ç»ˆçš„ç»“æœã€‚ å¯ä»¥å‘ç°æœ€åæˆ‘ä»¬æ˜¯**æ— æ³•æŸ¥çœ‹**æœ€ç»ˆçš„p.sum()å¯¹ä¸­é—´å˜é‡pçš„æ±‚å¯¼å‚æ•°çš„(**ä¸ä¿å­˜ä¸­é—´å˜é‡çš„æ¢¯åº¦ä¿¡æ¯**)ã€‚è¯¦æƒ…è§ä¸‹é¢è¿™ç¯‡åšå®¢ï¼š é€šä¿—è®²è§£PyTorchæ¢¯åº¦çš„ç›¸å…³é—®é¢˜ï¼šè®¡ç®—å›¾ã€torch.no_gradã€zero_gradã€detachå’Œbackwardï¼›Variableã€Parameterå’Œtorch.tensor è¿™å…¶ä¸­ä¹Ÿæœ‰è®²é‡å¤backwardæŠ¥é”™çš„é—®é¢˜ï¼è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ¯æ¬¡backwardå°†retain_graphè®¾ä¸ºTrueå°±å¥½äº†ã€‚ backward(retain_graph=True) è®°å¾—å†æ¬¡è¿›è¡Œbackwardå‰ï¼Œè¦æ ¹æ®è‡ªå·±éœ€æ±‚ç¡®å®šæ˜¯å¦ä½¿ç”¨a.grad.zero_()å°†æ¢¯åº¦æ¸…é›¶ã€‚ä¸ç„¶æ¢¯åº¦ä¼šåœ¨ä¸Šä¸€æ¬¡æ±‚å‡ºæ¥çš„åŸºç¡€ä¸Šè¿›è¡Œå åŠ ã€‚ Cross Entropy Lossï¼ˆäº¤å‰ç†µï¼‰ ç†µï¼ˆEntropyï¼‰ ä¸ç¡®å®šæ€§ ç”¨äºè¡¡é‡æƒŠå–œç¨‹åº¦ ç†µå€¼è¶Šé«˜ï¼šè¶Šé«˜çš„ä¸ç¡®å®šæ€§ Entropy=âˆ’âˆ‘iP(i)logP(i)Entropy=-\\sum_iP(i)logP(i) Entropy=âˆ’iâˆ‘â€‹P(i)logP(i) äº¤å‰ç†µï¼ˆCross Entropyï¼‰ æ•°å­¦å®šä¹‰ H(p,q)=âˆ’âˆ‘p(x)logÂ q(x)H(p,q)=-\\sum p(x)log \\ q(x) H(p,q)=âˆ’âˆ‘p(x)logÂ q(x) H(p,q)=H(p)+DKL(pâˆ£q)H(p,q)=H(p)+D_{KL}(p|q) H(p,q)=H(p)+DKLâ€‹(pâˆ£q) DKLD_{KL}DKLâ€‹æ˜¯æ•£åº¦ï¼Œç”¨äºè¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒçš„æ¥è¿‘ç¨‹åº¦çš„ï¼Œæ•£åº¦è¶Šå°ï¼Œåˆ†å¸ƒè¶Šæ¥è¿‘ã€‚ è¿™é‡Œpæ˜¯æˆ‘ä»¬å°†på®šä¸ºç½‘ç»œå­¦ä¹ å‡ºæ¥çš„åˆ†å¸ƒï¼Œqä¸ºå®é™…æ•°æ®çš„åˆ†å¸ƒï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´è§‚ç†è§£ä¼˜åŒ–ç›®æ ‡å°±æ˜¯ï¼Œç½‘ç»œå­¦ä¹ å‡ºæ¥çš„åˆ†å¸ƒè¦æœ‰è¾ƒé«˜çš„ç¡®å®šæ€§ï¼ˆä¸èƒ½è§‰å¾—åŒæ—¶å½’å±äºå‡ ä¸ªç§ç±»çš„æ¦‚ç‡æ˜¯ä¸€æ ·çš„ï¼‰ã€‚ä¹Ÿè¦å’Œå®é™…åˆ†å¸ƒæ¥è¿‘ï¼ˆæ•£åº¦å°ï¼‰ã€‚ å› æ­¤å¯¹äºäºŒåˆ†ç±»ï¼Œæˆ‘ä»¬çš„ Cross Ebtropy Losså‡½æ•°å¯ä»¥å†™ä¸ºï¼š H(P,Q)=âˆ’(ylog(p)+(1âˆ’y)log(1âˆ’p))H(P,Q)=-(ylog(p)+(1-y)log(1-p)) H(P,Q)=âˆ’(ylog(p)+(1âˆ’y)log(1âˆ’p)) ä¸ºä»€ä¹ˆä½¿ç”¨äº¤å‰ç†µ å¯¹äºåˆ†ç±»é—®é¢˜ åŸºäºsigmoidçš„mseå®¹æ˜“å‘ç”Ÿæ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ æ”¶æ•›ç¼“æ…¢ PyTorchå®ä¾‹ æ³¨æ„:cross_entropyå‡½æ•°åŒ…å«äº†æ±‚softmaxï¼Œlogè¿™äº›æ­¥éª¤ã€‚ PyTorchå•å±‚å•è¾“å‡ºæ„ŸçŸ¥æœºå®æˆ˜ ä¸Šæ ‡ä»£è¡¨ç¬¬å‡ å±‚ï¼Œä¸‹æ ‡ä»£è¡¨ç‰¹å¾å‘é‡çš„ç¬¬å‡ ä¸ªå…ƒç´ ã€‚ æ±‚å¯¼è¿‡ç¨‹å¦‚ä¸‹ï¼š è¿™æ ·å¾—çŸ¥äº†âˆ‚Eâˆ‚wj0\\frac{\\partial E}{\\partial w_{j0}}âˆ‚wj0â€‹âˆ‚Eâ€‹åï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥æ›´æ–°wäº†ã€‚ ä¸‹é¢ä½¿ç”¨PyTorchç®€å•çš„å®ç°ä¸Šè¿°å•å±‚å•è¾“å‡ºæ„ŸçŸ¥æœºã€‚ 123456789101112131415In [3]: x=torch.randn(1,10)In [4]: w=torch.randn(1,10,requires_grad=True)In [5]: o=torch.sigmoid(x@w.t())In [6]: o.shapeOut[6]: torch.Size([1, 1])In [7]: from torch.nn import functional as FIn [8]: loss=F.mse_loss(torch.ones(1,1),o)In [9]: loss.shapeOut[9]: torch.Size([])In [10]: loss.backward()In [11]: w.gradOut[11]: tensor([[-0.1147, -0.2456, -0.2645, 0.1144, -0.0162, 0.1094, -0.3674, -0.0048, -0.1127, -0.1605]]) ç„¶åï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥ä½¿ç”¨w.gradå¯¹wè¿›è¡Œæ›´æ–°å•¦ï¼ PyTorchå¤šè¾“å‡ºæ„ŸçŸ¥æœºå®æˆ˜ æ±‚å¯¼æ¨å¯¼è¿‡ç¨‹å¦‚ä¸‹ï¼š ä¸‹é¢ä½¿ç”¨PyTorchç®€å•çš„å®ç°ä¸Šè¿°å•å±‚å¤šè¾“å‡ºæ„ŸçŸ¥æœºã€‚ 1234567891011121314151617In [3]: x=torch.randn(1,10)In [4]: w=torch.randn(2,10,requires_grad=True)In [5]: o=torch.sigmoid(x@w.t())In [6]: o.shapeOut[6]: torch.Size([1, 2])In [7]: from torch.nn import functional as FIn [8]: loss=F.mse_loss(torch.ones(1,2),o)In [9]: lossOut[9]: tensor(0.6030, grad_fn=&lt;MseLossBackward0&gt;)In [10]: loss.backward(retain_graph=True)In [11]: w.gradOut[11]: tensor([[-0.1720, -0.1305, -0.0129, 0.0506, -0.0449, 0.1076, 0.0133, 0.0291, 0.0757, 0.0186], [-0.0033, -0.0025, -0.0002, 0.0010, -0.0009, 0.0021, 0.0003, 0.0006, 0.0015, 0.0004]]) é“¾å¼æ³•åˆ™â€» é€šè¿‡ä½¿ç”¨é“¾å¼æ³•åˆ™ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠæœ€åä¸€å±‚çš„è¯¯å·®ï¼Œä¸€å±‚ä¸€å±‚çš„è¾“å‡ºåˆ°ä¸­é—´å±‚çš„æƒå€¼ä¸Šé¢å»ï¼Œä»è€Œå¾—åˆ°ä¸­é—´å±‚çš„æ¢¯åº¦ä¿¡æ¯ï¼Œè¿›è€Œå¾ˆå¥½çš„æ›´æ–°æƒå€¼ï¼Œè¾¾åˆ°åå‘ä¼ æ’­ä¼˜åŒ–æ¨¡å‹çš„æ•ˆæœ PyTorchå®éªŒ 12345678910111213141516In [3]: from torch import autogradIn [4]: x=torch.tensor(1.)In [5]: w1=torch.tensor(2.,requires_grad=True)In [6]: b1=torch.tensor(1.)In [7]: w2=torch.tensor(2.,requires_grad=True)In [8]: b2=torch.tensor(1.)In [9]: y1=x*w1+b1In [10]: y2=y1*w2+b2In [11]: dy2_dy1=autograd.grad(y2,[y1],retain_graph=True)[0]In [12]: dy1_dw1=autograd.grad(y1,[w1],retain_graph=True)[0]In [13]: dy2_dw1=autograd.grad(y2,[w1],retain_graph=True)[0]In [14]: dy2_dy1*dy1_dw1Out[14]: tensor(2.)In [15]: dy2_dw1Out[15]: tensor(2.) ç”±ä¸Šè¯æ˜äº†é“¾å¼æ³•åˆ™çš„æ­£ç¡®æ€§ï¼ MLPåå‘ä¼ æ’­ å¤šå±‚æ„ŸçŸ¥æœº å…¶å®åŸç†éå¸¸çš„ç®€å•ï¼Œå°±æ˜¯æ­£å‘ä¼ æ’­å®Œæˆåï¼Œå€’ç€ä¸€å±‚ä¸€å±‚è®¡ç®—å¯¼æ•°ï¼Œæ¯ä¸€å±‚çš„å€’æ•°è®¡ç®—åŒä¸Šé¢çš„å•å±‚å•è¾“å‡ºæ„ŸçŸ¥æœºå’Œå•å±‚å¤šè¾“å‡ºæ„ŸçŸ¥æœºã€‚æ‰€ä»¥æ•´ä¸ªåå‘ä¼ æ’­çš„è¿‡ç¨‹ç›¸å½“äºæ˜¯å¾ˆå¤šä¸ªå•å±‚nè¾“å‡ºæ„ŸçŸ¥æœºæ¥åœ¨ä¸€èµ·ã€‚ï¼ˆæ„ŸçŸ¥æœºçš„æ¨åˆ°æ­¥éª¤è§ä¸Šé¢ï¼‰ 2Då‡½æ•°ä¼˜åŒ–å®ä¾‹ Himmelblau function è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨çš„å‡½æ•°è¡¨è¾¾å¼å¦‚ä¸‹ï¼š f(x,y)=(x2+yâˆ’11)2+(x+y2âˆ’7)2f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2 f(x,y)=(x2+yâˆ’11)2+(x+y2âˆ’7)2 å¦‚ä¸‹å›¾æ‰€ç¤º è¯¥å‡½æ•°åœ¨ä»¥ä¸‹å››ç‚¹å–å¾—å…¨å±€æœ€å°å€¼ï¼š f(3.0,2.0)=0.0f(3.0,2.0)=0.0f(3.0,2.0)=0.0 f(âˆ’2.805118,3.131312)=0.0f(-2.805118,3.131312)=0.0f(âˆ’2.805118,3.131312)=0.0 f(âˆ’3.779310,âˆ’3.283186)=0.0f(-3.779310,-3.283186)=0.0f(âˆ’3.779310,âˆ’3.283186)=0.0 f(3.584428,âˆ’1.848126)=0.0f(3.584428,-1.848126)=0.0f(3.584428,âˆ’1.848126)=0.0 é¦–å…ˆæ˜¯ç”»å›¾ä»£ç ï¼š 1234567891011121314151617181920import numpy as npimport matplotlib.pyplot as pltimport torchdef himmelblau(x): return (x[0]**2+x[1]-11)**2+(x[0]+x[1]**2-7)**2x=np.arange(-6,6,0.1)y=np.arange(-6,6,0.1)print(&#x27;x,y range:&#x27;,x.shape,y.shape)X,Y=np.meshgrid(x,y)print(&#x27;X,Y maps:&#x27;,X.shape,Y.shape)Z=himmelblau([X,Y])fig=plt.figure(&#x27;himmelblau&#x27;)ax=fig.gca(projection=&#x27;3d&#x27;)ax.plot_surface(X,Y,Z)ax.view_init(60,-30)ax.set_xlabel(&#x27;x&#x27;)ax.set_ylabel(&#x27;y&#x27;)plt.show() ç”»å›¾ç»“æœå¦‚ä¸‹ï¼š ç„¶åå°±æ˜¯æ±‚å¯¼æ‰¾å‡ºæœ€ä¼˜è§£äº†ï¼Œä»£ç å¦‚ä¸‹ï¼š å…·ä½“ç»†èŠ‚è§ä»£ç ä¸­çš„æ³¨é‡Š 12345678910111213141516# ä¸‹é¢ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™çš„æ–¹å¼è¿›è¡Œæ±‚è§£å…¨å±€æœ€å°å€¼x=torch.tensor([0.,0.],requires_grad=True)# ä½¿ç”¨ä¼˜åŒ–å™¨ï¼Œä¼˜åŒ–å™¨ä¼šè‡ªåŠ¨æ ¹æ®æ¢¯åº¦ä¿¡æ¯å’Œå­¦ä¹ ç‡æ¥æ›´æ–°ç›®æ ‡ï¼ˆè¿™é‡Œæ˜¯xï¼‰çš„å€¼optimizer=torch.optim.Adam([x],lr=1e-3)# åˆå§‹åŒ–ä¼˜åŒ–å™¨for step in range(20000): pred=himmelblau(x) optimizer.zero_grad()# æ¸…é›¶æ¢¯åº¦ï¼ˆä¸ç„¶ä¼šå‡ºç°æ¢¯åº¦ç´¯åŠ ï¼‰ pred.backward() # è‡ªåŠ¨æ±‚å¯¼è·å–æ¢¯åº¦ä¿¡æ¯ optimizer.step()# ä¼˜åŒ–å™¨æ‰§è¡Œä¸€æ¬¡æ›´æ–° if step%2000==0: print(&#x27;step &#123;&#125;: x = &#123;&#125;, f(x) = &#123;&#125;&#x27; .format(step,x.tolist(),pred.item())) æœ€ç»ˆè¿è¡Œç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼Œå¯ä»¥å‘ç°æœ€ç»ˆæ˜¯æ‰¾åˆ°äº†ä¸€ä¸ªå…¨å±€æœ€ä¼˜è§£ï¼š äº†è§£äº†PyTorchæœ€åŸºæœ¬çš„æ¢¯åº¦çŸ¥è¯†åï¼Œä¸‹é¢æˆ‘ä»¬å°†ç»§ç»­å­¦ä¹ å¦‚ä½•ä½¿ç”¨PyTorchæ„é€ ç®€å•çš„ç¥ç»ç½‘ç»œäº†ã€‚"},{"title":"PyTorchç¥ç»ç½‘ç»œ","path":"/wiki/PyTorch/PyTorchç¥ç»ç½‘ç»œ.html","content":"Logistic Regression è¯¥æ¦‚å¿µç°ç›®å‰å·²ç»å®Œå…¨è¢«Classificationæ›¿æ¢æ‰ å°±æ˜¯é€šè¿‡è¾“å‡ºåŠ sigmoidå‡½æ•°ï¼Œè®©è¾“å‡ºæ¥è¿‘0æˆ–1ï¼Œè¾¾åˆ°åˆ†ç±»çš„æ•ˆæœã€‚ ç›®æ ‡ï¼šæœ€å°åŒ–dist(pred,y) Logistic Regression ä¸€èˆ¬ä½¿ç”¨äº¤å‰ç†µä½œä¸ºLosså‡½æ•°ï¼Œåœ¨Pytochæ¢¯åº¦ä¸­çš„äº¤å‰ç†µä¸€èŠ‚æœ‰å¯¹äº¤å‰ç†µlosså‡½æ•°è¯¦ç»†çš„è®²è§£ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚ å¤šåˆ†ç±»é—®é¢˜å®æˆ˜â€”â€”å‡½æ•°APIå®ç° å‰é¢å¯¹è¿™ä¸€éƒ¨åˆ†çš„ä»‹ç»å·²ç»éå¸¸è¯¦ç»†äº†ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚ ç½‘ç»œç»“æ„ 123456789101112131415161718192021w1, b1 = torch.randn(200, 784, requires_grad=True),\\ torch.zeros(200, requires_grad=True)w2, b2 = torch.randn(200, 200, requires_grad=True),\\ torch.zeros(200, requires_grad=True)w3, b3 = torch.randn(10, 200, requires_grad=True),\\ torch.zeros(10, requires_grad=True)# ä»¥ä¸‹ä¸‰è¡Œæ˜¯kaimingåˆå§‹åŒ–torch.nn.init.kaiming_normal_(w1)torch.nn.init.kaiming_normal_(w2)torch.nn.init.kaiming_normal_(w3)def forward(x): x = x@w1.t() + b1 x = F.relu(x) x = x@w2.t() + b2 x = F.relu(x) x = x@w3.t() + b3 x = F.relu(x) # logits return x æ³¨æ„ï¼šåˆå§‹åŒ–ä¸­tensorç¬¬ä¸€ä¸ªç»´åº¦æ˜¯outï¼ˆä¸‹ä¸€å±‚å‘é‡é•¿åº¦ï¼‰ï¼Œç¬¬äºŒä¸ªç»´åº¦æ˜¯inï¼ˆè¿™ä¸€å±‚å‘é‡é•¿åº¦ï¼‰ è®­ç»ƒè¿‡ç¨‹ è®­ç»ƒè¿‡ç¨‹çš„åŸç†å’Œåšå®¢PyTorchæ¢¯åº¦æœ€åè®²çš„ä¸€æ ·ï¼Œè¿™é‡Œä¸å†èµ˜è¿° 123456789101112131415161718192021optimizer = optim.SGD([w1, b1, w2, b2, w3, b3], lr=learning_rate)criteon = nn.CrossEntropyLoss()for epoch in range(epochs): for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28) logits = forward(data) loss = criteon(logits, target) # åŒ…å«äº†softmaxå’Œlogæ±‚å¯¼éƒ¨åˆ† optimizer.zero_grad() loss.backward() # print(w1.grad.norm(), w2.grad.norm()) optimizer.step() if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) æ±‡æ€» é‡‡ç”¨çš„æ˜¯MINISTæ•°æ®é›†,ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformsbatch_size=200learning_rate=0.01epochs=10train_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)test_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)w1, b1 = torch.randn(200, 784, requires_grad=True),\\ torch.zeros(200, requires_grad=True)w2, b2 = torch.randn(200, 200, requires_grad=True),\\ torch.zeros(200, requires_grad=True)w3, b3 = torch.randn(10, 200, requires_grad=True),\\ torch.zeros(10, requires_grad=True)# ä»¥ä¸‹ä¸‰è¡Œæ˜¯kaimingåˆå§‹åŒ–torch.nn.init.kaiming_normal_(w1)torch.nn.init.kaiming_normal_(w2)torch.nn.init.kaiming_normal_(w3)def forward(x): x = x@w1.t() + b1 x = F.relu(x) x = x@w2.t() + b2 x = F.relu(x) x = x@w3.t() + b3 x = F.relu(x) return xoptimizer = optim.SGD([w1, b1, w2, b2, w3, b3], lr=learning_rate)criteon = nn.CrossEntropyLoss()for epoch in range(epochs): for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28) logits = forward(data) loss = criteon(logits, target) # åŒ…å«äº†softmaxå’Œlogæ±‚å¯¼éƒ¨åˆ† optimizer.zero_grad() loss.backward() # print(w1.grad.norm(), w2.grad.norm()) optimizer.step() if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) test_loss = 0 correct = 0 for data, target in test_loader: data = data.view(-1, 28 * 28) logits = forward(data) test_loss += criteon(logits, target).item() pred = logits.data.max(1)[1] correct += pred.eq(target.data).sum() test_loss /= len(test_loader.dataset) print(&#x27; Test set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) &#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) å…¨è¿æ¥å±‚â€”â€”ç±»APIå®ç° ç½‘ç»œç»“æ„ åœ¨ä¸Šä¸€æ¬¡çš„å®è·µä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨åˆ†æ•£çš„wï¼Œb tensorå®ç°äº†ä¸€ä¸ªéå¸¸ç®€å•çš„ä¸‰å±‚å…¨è¿æ¥å±‚ï¼ˆå‡½æ•°APIå®ç°ï¼‰ã€‚ä½†æ˜¯è¿™æ ·è™½ç„¶ç®€å•ï¼Œä½†æ˜¯ä¸å¤Ÿç›´è§‚ï¼Œå˜é‡ç¨å¾®æœ‰ç‚¹å¤šï¼Œè¿™æ¬¡æˆ‘ä»¬ä»‹ç»ä½¿ç”¨PyTorchè‡ªå¸¦çš„APIå®ç°ä¸€ä¸ªå’Œä¸Šé¢ä¸€æ ·çš„ä¸‰å±‚å…¨è¿æ¥å±‚ã€‚ 1234567891011121314151617In [3]: x=torch.randn(1,784)In [4]: x.shapeOut[4]: torch.Size([1, 784])In [5]: from torch import nnIn [6]: layer1=nn.Linear(784,200)In [7]: layer2=nn.Linear(200,200)In [8]: layer3=nn.Linear(200,10)In [9]: x=layer1(x)In [10]: x.shapeOut[10]: torch.Size([1, 200])In [11]: x=layer2(x)In [12]: x.shapeOut[12]: torch.Size([1, 200])In [13]: x=layer3(x)In [14]: x.shapeOut[14]: torch.Size([1, 10]) è¿™ä¸ªåªæ˜¯æ¯”è¾ƒåƒï¼Œä½†æ˜¯è¿˜æ˜¯æœ‰äº›åŒºåˆ«ï¼Œå› ä¸ºæˆ‘ä»¬è¿˜æ²¡æœ‰åŠ å±‚ä¹‹é—´çš„æ¿€æ´»å‡½æ•°ã€‚ ä¸‹é¢æˆ‘ä»¬åœ¨å±‚ä¹‹é—´æ·»åŠ æ¿€æ´»å‡½æ•°ï¼š 12345678910111213141516171819In [3]: from torch import nnIn [4]: import torch.nn.functional as FIn [5]: x=torch.randn(1,784)In [6]: layer1=nn.Linear(784,200)In [7]: layer2=nn.Linear(200,200)In [8]: layer3=nn.Linear(200,10)In [9]: x=layer1(x)In [10]: x=F.relu(x,inplace=True)In [11]: x.shapeOut[11]: torch.Size([1, 200])In [12]: x=layer2(x)In [13]: x=F.relu(x,inplace=True)In [14]: x.shapeOut[14]: torch.Size([1, 200])In [15]: x=layer3(x)In [16]: x=F.relu(x,inplace=True)In [17]: x.shapeOut[17]: torch.Size([1, 10]) reluä¸­çš„inplaceå‚æ•°å¦‚æœè®¾ç½®ä¸ºtrueçš„è¯ï¼ŒèŠ‚çœäº†å†…å­˜ï¼Œç›¸å½“äºè¾“å‡ºå’Œè¾“å…¥ç”¨åŒä¸€ä»½å†…å­˜ã€‚ å­¦ä¼šäº†å¦‚ä¸ŠAPIå®šä¹‰ç½‘ç»œï¼Œå› ä¸ºä¸€èˆ¬æƒ…å†µä¸‹çš„å·¥ç¨‹ï¼Œç½‘ç»œéƒ½ä¼šå®šä¹‰æˆä¸ºä¸€ä¸ªç±»ï¼Œæ‰€ä»¥è¿™é‡Œï¼Œæˆ‘ä»¬å­¦ä¹ å¦‚ä½•å°†ç½‘ç»œå®šä¹‰ä¸ºä¸€ä¸ªç±»ã€‚ 12345678910111213141516class MPL(nn.Module): def __init__(self): super(MLP,self).__init__() self.model=nn.Sequential( #çº¿æ€§å®¹å™¨ï¼Œå¯ä»¥å®¹çº³æ‰€æœ‰nn.Moduleç±» nn.Linear(784,200), nn.ReLU(inplace=True), nn.Linear(200,200), nn.ReLU(inplace=True), nn.Linear(200,10), nn.ReLU(inplace=True), ) def forward(self,x): x=self.model(x) return x æ³¨æ„åŒºåˆ†F.relu(x,inplace=True)å’Œä¸Šé¢nn.ReLU(inplace=True)è¿™ä¸¤ç§ç±»å‹çš„APIï¼Œå‰è€…æ˜¯å‡½æ•°ç±»å‹APIï¼Œå…¶ä¸­çš„tensoræ”¯æŒè‡ªå·±ç®¡ç†ï¼Œåè€…æ˜¯ç±»-ç±»å‹APIï¼Œtensorä¸ºç±»å†…éƒ¨å˜é‡ä¸èƒ½éšæ„è®¿é—®ï¼Œä½¿ç”¨ä¹Ÿå¿…é¡»å°†ç±»å®ä¾‹åŒ–åæ‰å¯ä»¥ä½¿ç”¨ã€‚ è®­ç»ƒè¿‡ç¨‹ ä»£ç å¦‚ä¸‹ï¼Œè¯¦æƒ…è§æ³¨é‡Šï¼š 123456789101112131415net=MLP()# å®ä¾‹åŒ–ç½‘ç»œoptimizer=optim.SGD(net.parameters(),lr=learning_rate) # è¿™é‡Œä½¿ç”¨parameters()è‡ªåŠ¨åŠ è½½ç›®æ ‡å˜é‡criteon = nn.CrossEntropyLoss()for epoch in range(epochs): for batch_idx, (data,target) in enumerate(train_loader): data=data.view(-1,28*28) logits=net(data) # é‡è½½forwardåï¼Œç›´æ¥ä¼ å…¥å‚æ•°é»˜è®¤forward loss=criteon(logits,target) optimizer.zero_grad() loss.backward() optimizer.step() æ±‡æ€» é‡‡ç”¨ç±»APIä¹¦å†™ï¼Œä½¿ç”¨çš„æ˜¯MINISTæ•°æ®é›†,ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformsbatch_size=200learning_rate=0.01epochs=10train_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)test_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)class MLP(nn.Module): def __init__(self): super(MLP, self).__init__() self.model = nn.Sequential( nn.Linear(784, 200), nn.ReLU(inplace=True), nn.Linear(200, 200), nn.ReLU(inplace=True), nn.Linear(200, 10), nn.ReLU(inplace=True), ) def forward(self, x): x = self.model(x) return xnet = MLP()optimizer = optim.SGD(net.parameters(), lr=learning_rate)criteon = nn.CrossEntropyLoss()for epoch in range(epochs): for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28) logits = net(data) loss = criteon(logits, target) optimizer.zero_grad() loss.backward() # print(w1.grad.norm(), w2.grad.norm()) optimizer.step() if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) test_loss = 0 correct = 0 for data, target in test_loader: data = data.view(-1, 28 * 28) logits = net(data) test_loss += criteon(logits, target).item() pred = logits.data.max(1)[1] correct += pred.eq(target.data).sum() test_loss /= len(test_loader.dataset) print(&#x27; Test set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) &#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) ä»¥ä¸Šä¸ºç›®å‰çš„ä¸»æµç‰ˆæœ¬ï¼Œå€¼å¾—å­¦ä¹ ä¸å‚è€ƒï¼ æ¿€æ´»å‡½æ•°ä¸GPUåŠ é€Ÿ æ¿€æ´»å‡½æ•° tanhâ€”â€”RNN sigmoidâ€”â€”probability ReLUâ€”â€”DL LeakyReLUâ€”â€”DL SELUâ€”â€”ä¼˜åŒ–äº†ReLUåœ¨0ç‚¹å¯¼æ•°ä¸è¿ç»­çš„æƒ…å†µ softplusâ€”â€”åŒSELUï¼Œå…‰æ»‘äº†ReLUåœ¨0ç‚¹å¤„çš„è¿æ¥ GPUåŠ é€Ÿ ç°ç›®å‰è¾ƒé«˜ç‰ˆæœ¬çš„PyTorchå·²ç»å¯ä»¥ä½¿ç”¨toæ–¹æ³•æŒ‡å®šä½¿ç”¨ç‰¹å®šè®¾å¤‡è¿›è¡Œè¿ç®—ï¼Œè€Œä¸å¿…åƒåŸæ¥ä½¿ç”¨ä¸åŒè®¾å¤‡è¿›è¡Œç›¸åŒçš„è¿ç®—éœ€è¦è°ƒç”¨ä¸åŒçš„APIã€‚ ä½¿ç”¨GPU cudaåŠ é€Ÿè¿ç®—çš„ä»£ç å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š 12345678910device = torch.device(&#x27;cuda:0&#x27;)net = MLP().to(device)optimizer = optim.SGD(net.parameters(), lr=learning_rate)criteon = nn.CrossEntropyLoss().to(device)for epoch in range(epochs): for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28) data, target = data.to(device), target.cuda()# å»ºè®®ç»Ÿä¸€ç”¨toï¼Œè¿™é‡Œåªæ˜¯æƒ³è¯´æ˜ç”¨.cuda()ä¹Ÿæ˜¯å¯ä»¥çš„ ä¸Šè¿°ä»£ç ç›¸å½“äºæ˜¯å°†ç½‘ç»œï¼Œlosså‡½æ•°å’Œæ‰€æœ‰çš„æ•°æ®éƒ½æ¬è¿åˆ°äº†GPUä¸Šå»ã€‚ æ±‡æ€» é‡‡ç”¨çš„æ˜¯MINISTæ•°æ®é›†, ä¼˜åŒ–æ¿€æ´»å‡½æ•°å˜ä¸ºLeakyReLU ä½¿ç”¨äº†GPU cudaåŠ é€Ÿ ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformsbatch_size=200learning_rate=0.01epochs=10train_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)test_loader = torch.utils.data.DataLoader( datasets.MNIST(&#x27;../data&#x27;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=batch_size, shuffle=True)class MLP(nn.Module): def __init__(self): super(MLP, self).__init__() self.model = nn.Sequential( nn.Linear(784, 200), nn.LeakyReLU(inplace=True), nn.Linear(200, 200), nn.LeakyReLU(inplace=True), nn.Linear(200, 10), nn.LeakyReLU(inplace=True), ) def forward(self, x): x = self.model(x) return xdevice = torch.device(&#x27;cuda:0&#x27;)net = MLP().to(device)optimizer = optim.SGD(net.parameters(), lr=learning_rate)criteon = nn.CrossEntropyLoss().to(device)for epoch in range(epochs): for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28) data, target = data.to(device), target.cuda() logits = net(data) loss = criteon(logits, target) optimizer.zero_grad() loss.backward() # print(w1.grad.norm(), w2.grad.norm()) optimizer.step() if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item())) test_loss = 0 correct = 0 for data, target in test_loader: data = data.view(-1, 28 * 28) data, target = data.to(device), target.cuda() logits = net(data) test_loss += criteon(logits, target).item() pred = logits.data.max(1)[1] correct += pred.eq(target.data).sum() test_loss /= len(test_loader.dataset) print(&#x27; Test set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) &#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) æµ‹è¯•ç¯èŠ‚ å¯ä»¥å‘ç°å‰é¢æ‰€è®²çš„å†…å®¹åªæ˜¯è¦†ç›–äº†ç½‘ç»œç»“æ„çš„åˆå§‹åŒ–ä»¥åŠè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶æ²¡æœ‰è®²è§£æµ‹è¯•è¿‡ç¨‹ï¼Œä¸‹é¢æˆ‘ä»¬å°±æ¥å­¦ä¹ ä¸€ä¸‹å½“PyTorchè®­ç»ƒå®Œæˆåï¼Œå¦‚ä½•è¿›è¡Œæµ‹è¯•ã€‚ å¯¹äºMINISTæ•°æ®é›†å…¶å®å°±æ˜¯å°†æœ€åçš„ç®—losså’Œloss.backward()å»æ‰ï¼Œç›´æ¥å°†logitsæ¥ä¸€ä¸ªsoftmaxå±‚ï¼ˆå…¶å®ä¹Ÿå¯ä»¥ä¸åŠ ï¼‰ç„¶åæ‰¾åˆ°æœ€å¤§å€¼çš„indexå³å¯ï¼ˆä½¿ç”¨argmaxå‡½æ•°ï¼‰ã€‚ è®¡ç®—å‡†ç¡®ç‡å°±æ˜¯ç”¨é¢„æµ‹æ­£ç¡®çš„æ•°é‡é™¤ä»¥æ€»æ•°é‡ã€‚ ä»£ç å®ç° ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•ç¯èŠ‚çš„æ¨¡æ‹Ÿä»£ç ï¼Œå…¶ä¸­è®¡ç®—å‡†ç¡®ç‡è¿™ä¸€éƒ¨åˆ†è¿˜æ˜¯æœ‰ä¸€äº›æŠ€æœ¯æ€§çš„ã€‚ 1234567891011121314151617In [3]: logits=torch.rand(4,10)In [4]: import torch.nn.functional as FIn [5]: pred=F.softmax(logits,dim=1)In [6]: pred.shapeOut[6]: torch.Size([4, 10])In [7]: pred_label=pred.argmax(dim=1)In [8]: pred_labelOut[8]: tensor([8, 0, 0, 0])In [9]: logits.argmax(dim=1)Out[9]: tensor([8, 0, 0, 0])In [10]: label=torch.tensor([8,0,1,2])In [11]: correct=torch.eq(pred_label,label)In [12]: correctOut[12]: tensor([ True, True, False, False])In [13]: correct.sum().float().item()/4Out[13]: 0.5 è¿˜æœ‰ä¸€äº›å…¶ä»–çš„è¯„ä»·å‚æ•°ï¼Œæ¯”å¦‚precisionæˆ–recallï¼Œè¿™äº›åé¢ä¼šå•ç‹¬å†™ä¸€ç¯‡åšå®¢è¿›è¡Œè®²è§£ã€‚ ä»€ä¹ˆæ—¶å€™æµ‹è¯•ï¼Ÿ åœ¨è¿è¡Œå®Œå‡ ä¸ªBatchåè¿›è¡Œä¸€æ¬¡test è¿è¡Œå®Œä¸€ä¸ªepochåè¿›è¡Œä¸€æ¬¡æµ‹è¯• æ±‡æ€» ä»£ç æ±‡æ€»è§ä¸Šé¢çš„æ±‡æ€»æ¨¡å— Visdomå¯è§†åŒ– step1ï¼šå®‰è£…visdom 1pip install visdom step2ï¼šå¼€å¯visdom WebæœåŠ¡å™¨ å‘½ä»¤è¡Œä¸­è¾“å…¥ï¼š 1python -m visdom.server step3ï¼šç„¶åå°±å¯ä»¥å°†æ•°æ®ä¸¢å…¥visdomè¿›è¡Œå¯è§†åŒ–æŸ¥çœ‹äº† 1234from visdom import Visdomviz=Visdom()viz.line([0.],[0.],win=&#x27;train_loss&#x27;,opts=dict(title=&#x27;train_loss_title&#x27;))# åˆ›å»ºä¸€æ¡ç›´çº¿ï¼Œå‰ä¸¤ä¸ªå‚æ•°ç¬¬ä¸€ä¸ªæ˜¯yï¼Œç¬¬äºŒä¸ªæ˜¯xviz.line([loss.item()],[global_step],win=&#x27;train_loss&#x27;,update=&#x27;append&#x27;)# ä¼ å…¥ä»æ˜¯numpyæ•°æ®ï¼ˆimageå¯ä»¥æ¥æ”¶tensorï¼‰ `win`ï¼šå°çª—å£IDenv:å¤§çª—å£IDï¼Œå¤§çª—å£ä¸­å¯ä»¥æœ‰å¾ˆå¤šä¸ªå°çª—å£ï¼Œé»˜è®¤æ˜¯mainå¤§çª—å£ update:è‹¥ä¸ºappendè¡¨ç¤ºæ·»åŠ åœ¨å½“å‰ç›´çº¿çš„åé¢ï¼Œè‹¥ä¸æŒ‡å®šä¼šè¢«è¦†ç›–æ‰ å¤šæ¡æ›²çº¿ä¸€ä¸ªçª—å£ ä¸Šé¢çš„ä»£ç å®ç°çš„æ˜¯ä¸€æ¡æ›²çº¿ä¸€ä¸ªçª—å£ï¼Œä¸‹é¢æˆ‘ä»¬æ¥è®²ä¸€ä¸‹å¦‚ä½•å®ç°å¤šæ¡æ›²çº¿ç”»åœ¨ä¸€ä¸ªçª—å£ã€‚ 12345from matplotlib.pyplot import legendfrom visdom import Visdomviz=Visdom()viz.line([0.,0.],[0.],win=&#x27;test&#x27;,opts=dict(title=&#x27;train_loss&amp;acc&#x27;,legend=[&#x27;loss&#x27;,&#x27;acc&#x27;]))viz.line([test_loss,correct/len(test_loader.dataset)],[global_step],win=&#x27;train_loss&#x27;,update=&#x27;append&#x27;) å…¶å®å°±æ˜¯å°†yå‚æ•°çš„listå¢åŠ äº†ä¸€ä¸ªé•¿åº¦ï¼Œå°±å¯ä»¥ä¸€ä¸ªå°çª—å£ç”»ä¸¤æ¡æ›²çº¿ã€‚ visual x è¿™æ˜¯visdomæä¾›çš„ä¸€ä¸ªå¯è§†åŒ–çš„åŠŸèƒ½ 123456from matplotlib.pyplot import legendfrom visdom import Visdomviz=Visdom()#MINSTä¸ºä¾‹viz.images(data.view(-1,1,28,28)ï¼Œwin=&#x27;x&#x27;) # å¯¹äºå›¾ç‰‡ï¼Œè¿™é‡Œå¯ä»¥ç›´æ¥æ¥æ”¶tensorï¼ï¼ï¼viz.text(str(pred.detach().cpu().numpy()),win=&#x27;pred&#x27;,opts=dict(title=&#x27;pred&#x27;)) # å¯¹äºStringç±»å‹è¿˜æ˜¯è¦å…ˆè½¬åˆ°cpuç„¶å¹´è½¬numpyç„¶åè½¬string"},{"title":"PyTorchç»ˆç« ï¼šå¼€GANï¼","path":"/wiki/PyTorch/PyTorchç»ˆç« ï¼šå¼€GANï¼.html","content":"GANç®€ä»‹ GANçš„ç»ˆæç›®çš„å°±æ˜¯å­¦ä¹ p(x)p(x)p(x),p(x)p(x)p(x)æ˜¯ä¸€ä¸ªåˆ†å¸ƒï¼Œæ¯”å¦‚å®ƒå¯ä»¥æ˜¯äºŒæ¬¡å…ƒå¤´åƒå›¾ç‰‡ç‰¹å¾çš„åˆ†å¸ƒï¼Œå¯ä»¥æ˜¯ä¸€ç§ç±»å‹çš„ç”»ä½œçš„ç‰¹å¾é›†åˆï¼Œæˆ‘ä»¬å­¦ä¼šäº†p(x)p(x)p(x)åï¼Œæˆ‘ä»¬ä¾¿å¯ä»¥åœ¨å…¶ä¸­è¿›è¡Œsampleç„¶åå°±å¯ä»¥è¿›è¡Œåˆ›ä½œäº†ã€‚è¿™ä¾¿æ˜¯GANçš„åŸç†è§£é‡Šã€‚ GAN ç»“æ„ ç”Ÿæˆå™¨ï¼ˆPainter or Generatorï¼‰ é‰´åˆ«å™¨ï¼ˆCritic or Discriminatorï¼‰ å¤§è‡´ç»“æ„å¦‚ä¸Šï¼Œç”Ÿæˆå™¨æ ¹æ®éšæœºç”Ÿæˆçš„ä¿¡å·ï¼Œäº§ç”Ÿä¸€å¹…â€œç”»â€ã€‚é‰´åˆ«å™¨ä½¿ç”¨å¾ˆå¤šçœŸçš„å’Œå‡çš„â€œç”»â€è¿›è¡Œè®­ç»ƒï¼Œæ¥åˆ†è¾¨ç”»çš„çœŸå‡ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ªæ‰“åˆ†å€¼ã€‚åˆ†å€¼è¶Šé«˜è¡¨æ˜ç”»è¶ŠçœŸå®ï¼ˆé‰´åˆ«å™¨çœ‹æ¥ï¼‰ã€‚é‰´åˆ«å™¨çš„ç›®æ ‡æ˜¯å°½å¯èƒ½çš„åˆ†è¾¨å‡ºçœŸâ€œç”»â€å’Œå‡â€œç”»â€ã€‚ç”Ÿæˆå™¨çš„ç›®æ ‡æ˜¯å°½å¯èƒ½çš„æœ€å¤§åŒ–é‰´åˆ«å™¨çš„æ‰“åˆ†ï¼ˆç›¸å½“äºå°½å¯èƒ½çš„æ¬ºéª—é‰´åˆ«å™¨ï¼‰ GANçš„å‡ºç°è®©ç¥ç»ç½‘ç»œå…·æœ‰äº†åˆ›é€ æ€§ï¼Œå½“æˆ‘ä»¬éœ€è¦ä½¿ç”¨ç¥ç»ç½‘ç»œå®Œæˆä¸€äº›å…·æœ‰åˆ›é€ åŠ›çš„ä»»åŠ¡æ—¶ï¼ŒGANæ˜¯ä¸€ä¸ªéå¸¸ä¸é”™çš„é€‰æ‹©ã€‚ è¿™é‡Œæ¨èä¸€ä¸ªéå¸¸ä¸é”™çš„å…³äºGANåœ¨çº¿è®­ç»ƒçš„ç½‘é¡µé“¾æ¥ [GANplayground: Experiment with Generative Adversarial Networks in your browser ](https://reiinakano.com/gan-playground/) ä¸‹å›¾æ˜¯GANç½‘ç»œçš„å½¢è±¡è§£é‡Šï¼Œç»¿çº¿æ˜¯æˆ‘ä»¬è¦å­¦ä¹ çš„ç‰©ä½“çš„ç‰¹å¾ï¼ˆæ¯”å¦‚äºŒæ¬¡å…ƒå¤´åƒçš„ç‰¹å¾ï¼‰çš„åˆ†å¸ƒï¼Œé»‘çº¿æ˜¯æˆ‘ä»¬å­¦ä¹ åˆ°çš„ç‰¹å¾çš„åˆ†å¸ƒï¼Œè“çº¿æ˜¯é‰´åˆ«å™¨çš„è¾“å‡ºï¼Œä¸€å¼€å§‹ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨éƒ½æ²¡æœ‰è¿›è¡Œè®­ç»ƒï¼Œæ‰€ä»¥ç”Ÿæˆå™¨ç”Ÿæˆçš„åˆ†å¸ƒéå¸¸çš„çƒ‚ï¼Œé‰´åˆ«å™¨ä¹Ÿæ— æ³•å¾ˆå¥½çš„é‰´åˆ«å›¾ç‰‡æ˜¯å¦æ˜¯ç”Ÿæˆå™¨ç”Ÿæˆçš„ï¼ˆå¦‚å›¾(a)æ‰€ç¤ºï¼‰ï¼Œç´§æ¥ç€æˆ‘ä»¬è®­ç»ƒé‰´åˆ«å™¨ï¼Œç„¶åå¯ä»¥å‘ç°åœ¨è®­ç»ƒä¸€æ®µæ—¶é—´åé‰´åˆ«å™¨å·²ç»å¯ä»¥å¾ˆå¥½çš„é‰´åˆ«å›¾ç‰‡çš„çœŸä¼ªäº†ï¼ˆå›¾bï¼‰ã€‚æ¥ç€æˆ‘ä»¬è®­ç»ƒç”Ÿæˆå™¨ï¼Œç”Ÿæˆå™¨çš„ç›®æ ‡æ˜¯å°½é‡è®©é‰´åˆ«å™¨è®¤ä¸ºå›¾ç‰‡æ˜¯çœŸçš„ï¼Œä»è€Œç»™å‡ºé«˜åˆ†ï¼Œéšç€è®­ç»ƒæ¬¡æ•°çš„å¢åŠ ï¼Œç”Ÿæˆå™¨ç”Ÿæˆçš„åˆ†å¸ƒä¼šè¶Šæ¥è¶Šæ¥è¿‘çœŸå®çš„åˆ†å¸ƒï¼ˆå¦‚å›¾Â©æ‰€ç¤ºï¼‰ï¼Œåœ¨æœ€åçš„æ—¶å€™è¿é‰´åˆ«å™¨ä¹Ÿæ— æ³•è¯†åˆ«ç”Ÿæˆå™¨ç”Ÿæˆå›¾ç‰‡çš„çœŸä¼ªæ—¶ï¼Œè®­ç»ƒç»“æŸã€‚ï¼ˆå›¾dï¼‰ GANåŸç† GANçš„è®­ç»ƒåˆ†ä¸ºä¸¤æ­¥ã€‚ å›ºå®šç”Ÿæˆå™¨ï¼ˆGï¼‰è®­ç»ƒé‰´åˆ«å™¨ï¼ˆDï¼‰ä½¿å…¶æ”¶æ•› å›ºå®šé‰´åˆ«å™¨ï¼ˆDï¼‰è®­ç»ƒç”Ÿæˆå™¨ï¼ˆGï¼‰ä½¿å…¶æ”¶æ•› ä¸‹é¢æˆ‘ä»¬å°±åˆ†åˆ«æ¥è¯¦ç»†è¯´æ˜ä¸€ä¸‹è¿™ä¸¤æ­¥ä¸­çš„æ•°å­¦åŸç†ã€‚ é¦–å…ˆæˆ‘ä»¬è¦æ˜ç™½æˆ‘ä»¬çš„æœ€ç»ˆç›®æ ‡ minâ¡Gmaxâ¡DL(D,G)=Exâˆ¼pr(x)[logâ¡D(x)]+Ezâˆ¼pz(z)[logâ¡(1âˆ’D(G(z)))]\\min\\limits_{G}\\max\\limits_{D} L(D,G)=\\mathbb{E}_{x\\sim p_r(x)}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z(z)}[\\log(1- D(G(z)))] Gminâ€‹Dmaxâ€‹L(D,G)=Exâˆ¼prâ€‹(x)â€‹[logD(x)]+Ezâˆ¼pzâ€‹(z)â€‹[log(1âˆ’D(G(z)))] minâ¡Gmaxâ¡DL(D,G)=Exâˆ¼pr(x)[logâ¡D(x)]+Exâˆ¼pg(x)[logâ¡(1âˆ’D(x))]\\min\\limits_{G}\\max\\limits_{D} L(D,G)=\\mathbb{E}_{x\\sim p_r(x)}[\\log D(x)] + \\mathbb{E}_{x\\sim p_g(x)}[\\log(1- D(x))] Gminâ€‹Dmaxâ€‹L(D,G)=Exâˆ¼prâ€‹(x)â€‹[logD(x)]+Exâˆ¼pgâ€‹(x)â€‹[log(1âˆ’D(x))] çº³ä»€å‡è¡¡â€”â€”D å¯¹äºå›ºå®šçš„Gï¼Œæœ€å¥½çš„Dæ˜¯ï¼š DGâˆ—(x)=pdata(x)pdata(x)+pg(x)D^*_G(x)=\\frac{p_{data}(x)}{p_{data}(x)+p_g(x)} DGâˆ—â€‹(x)=pdataâ€‹(x)+pgâ€‹(x)pdataâ€‹(x)â€‹ è®­ç»ƒDçš„å‡†åˆ™ï¼ˆcriterionï¼‰æ˜¯å¯¹äºç»™å®šçš„Gæœ€å¤§åŒ–V(G,D)V(G,D)V(G,D) V(G,D)=âˆ«xpdata(x)logâ¡(D(x))dx+âˆ«zp(z)logâ¡(1âˆ’D(g(z)))dz=âˆ«xpdata(x)logâ¡(D(x))+pg(x)logâ¡(1âˆ’D(x))dx\\begin{aligned} V(G,D) &amp;= \\int_x p_{data}(x)\\log(D(x))dx + \\int_z p(z)\\log(1-D(g(z)))dz\\\\ &amp;= \\int_xp_{data}(x)\\log(D(x))+p_g(x)\\log(1-D(x))dx \\end{aligned} V(G,D)â€‹=âˆ«xâ€‹pdataâ€‹(x)log(D(x))dx+âˆ«zâ€‹p(z)log(1âˆ’D(g(z)))dz=âˆ«xâ€‹pdataâ€‹(x)log(D(x))+pgâ€‹(x)log(1âˆ’D(x))dxâ€‹ è¿™ä¸ªå…¶å®å°±æ˜¯æ±‚æœŸæœ›ï¼Œåªæ˜¯æŠŠå®ƒå†™æˆäº†ç§¯åˆ†å½¢å¼ã€‚ æˆ‘ä»¬å¯¹ä¸Šé¢è¿™ä¸ªå¼å­æ±‚å¯¼ï¼Œå°±å¯ä»¥çŸ¥é“æœ€å¥½çš„DDDæ˜¯ä¸Šé¢çš„Dâˆ—D^*Dâˆ— çº³ä»€å‡è¡¡â€”â€”G å½“æˆ‘ä»¬è®­ç»ƒå®ŒDåï¼Œä¸‹é¢å°±è½®åˆ°Gè¿›è¡Œè®­ç»ƒäº†ã€‚ L(G,Dâˆ—)=2DJS(prâˆ£âˆ£pg)âˆ’2logâ¡2L(G,D^*)=2D_{JS}(p_r||p_g)-2\\log2 L(G,Dâˆ—)=2DJSâ€‹(prâ€‹âˆ£âˆ£pgâ€‹)âˆ’2log2 è¿™ä¾¿æ˜¯æ¬ºéª—é‰´åˆ«å™¨è¿™ä¸€ç›´è§‚ç†è§£çš„ç›®æ ‡å‡½æ•°è¡¨è¾¾å½¢å¼ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯æœ€å°åŒ–è¿™ä¸ªå‡½æ•°ã€‚ GANçš„é—®é¢˜ è®­ç»ƒç¨³å®šæ€§å·® å¯¼è‡´è¿™ä¸ªæƒ…å†µä¸»è¦æ˜¯æœ‰ä¸¤ä¸ªåŸå› ï¼š æ•°æ®æœ¬èº«çš„ç‰¹å¾ å› ä¸ºåœ¨å¾ˆå¤šæƒ…å†µä¸‹PGP_GPGâ€‹å’ŒPdataP_{data}Pdataâ€‹æ˜¯å‡ ä¹ä¸å¯èƒ½é‡åˆçš„ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªåˆ†å¸ƒçš„ç‰¹å¾æ˜¯åœ¨é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­å°±å‡ ä¹æ˜¯ä¸¤æ¡çº¿ï¼ˆä»…ç”¨äºè¯´æ˜ï¼‰ï¼Œä»–ä»¬é‡åˆçš„éƒ¨åˆ†å‡ ä¹å¯ä»¥å¿½ç•¥ã€‚ é‡‡æ · å°±ç®—PGP_GPGâ€‹å’ŒPdataP_{data}Pdataâ€‹è¿˜æ˜¯æœ‰ä¸€éƒ¨åˆ†é‡åˆçš„ï¼Œä½†æ˜¯å¦‚æœæˆ‘ä»¬é‡‡æ ·æ²¡æœ‰é‡‡å¤Ÿçš„è¯ï¼Œè¿˜æ˜¯æœ‰å¯èƒ½å‡ºç°ä¸‹å›¾çš„æƒ…å†µï¼Œè®©æˆ‘ä»¬è®¤ä¸ºä¸¤ä¸ªåˆ†å¸ƒæ²¡æœ‰é‡åˆã€‚ï¼ˆç‚¹ä¸ºå®é™…çš„é‡‡æ ·ç‚¹ï¼Œä¸¤ä¸ªæ¤­åœ†è¡¨ç¤ºçš„æ˜¯å®é™…çš„ä¸¤ä¸ªåˆ†å¸ƒæƒ…å†µã€‚ï¼‰ JS ç»è¿‡æ•°å­¦æ¨å¯¼ï¼Œåªè¦ä¸¤ä¸ªåˆ†å¸ƒä¸é‡å ï¼ŒJS Divergenceçš„å–å€¼æ°¸è¿œéƒ½æ˜¯logâ¡2\\log 2log2ã€‚è¿™ä¸ªå°±æ²¡æœ‰å¾ˆå¥½çš„é‡åŒ–åˆ†å¸ƒä¹‹é—´è·ç¦»çš„è¿™ç§å…³ç³»ã€‚è€Œä¸”æ ¹æ®æ•°æ®çš„è‡ªç„¶ç‰¹æ€§æˆ‘ä»¬ä¹ŸçŸ¥é“è¿™ä¸¤ä¸ªåˆ†å¸ƒæ˜¯ä¸å¥½é‡å çš„ï¼Œæˆ–è€…è¯´å¤§æ¦‚ç‡æ˜¯ä¸ä¼šé‡å çš„ï¼ŒJS Divergenceä¸€ç›´ä¸å˜ä¼šç»™æ¢¯åº¦ä¸‹é™å¸¦æ¥å¾ˆå¤§çš„é—®é¢˜ï¼Œå¯¼è‡´æ¨¡å‹ä¸€ç›´ä¸æ”¶æ•›ã€‚è¿™ä¾¿æ˜¯JS Divergenceåœ¨GANä¸­ä½¿ç”¨çš„ä¸€ä¸ªéå¸¸ä¸¥é‡çš„é—®é¢˜ã€‚ è§£å†³JSçš„é—®é¢˜ æˆ‘ä»¬é‡‡ç”¨äº†Wasserstein Distanceæ¥ä»£æ›¿JSã€‚å…¶æ ¹æœ¬æ€æƒ³å°±æ˜¯è¡¡é‡å°†ä¸€ä¸ªåˆ†å¸ƒå˜æˆå¦ä¸€ä¸ªåˆ†å¸ƒæ‰€éœ€è¦çš„æœ€å°ä»£ä»·ã€‚ï¼ˆç›´è§‚ç†è§£å°±æ˜¯æ¬ç –ï¼ŒæŠŠä¸€ä¸ªç –å †å˜æˆå¦å¤–ä¸€ç§ç –å †æ‰€éœ€çš„æœ€å°ä»£ä»·ï¼‰ã€‚ é‡‡ç”¨Wasserstein Distanceæ¥ä»£æ›¿JSçš„GANè¢«ç§°ä¸ºWGAN ç®€è¦è®¡ç®—æ­¥éª¤å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ WGANçš„æå‡ºä»æ ¹æœ¬ä¸Šè§£å†³äº†éƒ¨åˆ†GANæ— æ³•æ”¶æ•›(è®­ç»ƒä¸ç¨³å®š)çš„é—®é¢˜ã€‚ å®æˆ˜GAN ç½‘ç»œç»“æ„ é¦–å…ˆæ˜¯å»ºç«‹ç½‘ç»œç»“æ„ï¼ŒGANçš„ç½‘ç»œç»“æ„åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªæ˜¯ç”Ÿæˆå™¨ï¼ˆGeneratorï¼‰ï¼Œè¿˜æœ‰ä¸€ä¸ªæ˜¯é‰´åˆ«å™¨ï¼ˆDiscriminatorï¼‰ã€‚ä»£ç éå¸¸ç®€ç­”ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°äº†ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041h_dim = 400batchsz = 512class Generator(nn.Module): def __init__(self): super(Generator, self).__init__() self.net = nn.Sequential( nn.Linear(2, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, 2), ) def forward(self, z): output = self.net(z) return output class Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.net = nn.Sequential( nn.Linear(2, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, 1), nn.Sigmoid() ) def forward(self, x): output = self.net(x) return output.view(-1) ç”Ÿæˆæ•°æ®é›† æˆ‘ä»¬æœ¬æ¬¡å®éªŒé‡‡ç”¨çš„æ•°æ®é›†æ˜¯ç»Ÿè®¡å­¦ä¸­ç»å¸¸ä½¿ç”¨çš„æ··åˆé«˜æ–¯æ¨¡å‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼ŒäºŒç»´å¹³é¢ä¸Šä¸€å…±æ˜¯æœ‰8ä¸ªé«˜æ–¯åˆ†å¸ƒç»„åˆè€Œæˆçš„ä¸€ä¸ªæ··åˆåˆ†å¸ƒå›¾å½¢ã€‚ ç›¸ä¿¡å¤§å®¶ä¹Ÿæ˜ç™½äº†ä¸ºä»€ä¹ˆè¾“å‡ºæ˜¯ä¸¤ä¸ªç¥ç»å…ƒâ€”â€”å› ä¸ºè¦åœ¨å¹³é¢åæ ‡ç³»ä¸Šè¿›è¡Œå¯è§†åŒ–è¾“å‡ºå˜›ğŸ˜‚ æ•°æ®é›†ç”Ÿæˆä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819202122232425262728def data_generator(): &#x27;&#x27;&#x27; 8-gaussian mixture models :return: &#x27;&#x27;&#x27; scale = 2. centers = [ (1, 0), (-1, 0), (0, 1), (0, -1), (1. / np.sqrt(2), 1. / np.sqrt(2)), (1. / np.sqrt(2), -1. / np.sqrt(2)), (-1. / np.sqrt(2), 1. / np.sqrt(2)), (-1. / np.sqrt(2), -1. / np.sqrt(2)) ] centers = [(scale * x, scale * y) for x, y in centers] while True: dataset = [] for i in range(batchsz): point = np.random.randn(2) * .02 center = random.choice(centers) point[0] += center[0] point[1] += center[1] dataset.append(point) dataset = np.array(dataset, dtype=&#x27;float32&#x27;) dataset /= 1.414 # stdev yield dataset yield è¿™é‡Œå¤§å®¶å¯èƒ½å¥½å¥‡yieldæ˜¯å¹²ä»€ä¹ˆçš„ï¼Œä¸‹é¢æˆ‘ä¸¾ä¸¤ä¸ªä¾‹å­å¸®åŠ©å¤§å®¶ç†è§£ã€‚ ä»¥ä¸‹å…³äºyieldçš„éƒ¨åˆ†è®²è§£è½¬è½½è‡ª:https://blog.csdn.net/mieleizhi0522/article/details/82142856 ä¾‹ä¸€ 123456789101112def dataset_generator(): i=0 while True: i=i+1 yield iif __name__ == &#x27;__main__&#x27;: g = dataset_generator() for ii in range (10): print(next(g)) print(&quot;*&quot;*20) ä»£ç è¿è¡Œç»“æœæ˜¯ï¼š 12345678910111213141516171819201********************2********************3********************4********************5********************6********************7********************8********************9********************10******************** ä¾‹äºŒ 1234567891011def foo(): print(&quot;starting...&quot;) while True: res = yield 4 print(&quot;res:&quot;,res)if __name__ == &#x27;__main__&#x27;: g = foo() print(&#x27;ok&#x27;) print(next(g)) print(&quot;*&quot;*20) print(next(g)) ä»£ç è¿è¡Œç»“æœæ˜¯ï¼š 123456okstarting...4********************res: None4 åˆ°è¿™é‡Œä½ å¯èƒ½å°±æ˜ç™½yieldå’Œreturnçš„å…³ç³»å’ŒåŒºåˆ«äº†ï¼Œå¸¦yieldçš„å‡½æ•°æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå‡½æ•°äº†ï¼Œè¿™ä¸ªç”Ÿæˆå™¨æœ‰ä¸€ä¸ªå‡½æ•°å°±æ˜¯nextå‡½æ•°ï¼Œnextå°±ç›¸å½“äºâ€œä¸‹ä¸€æ­¥â€ç”Ÿæˆå“ªä¸ªæ•°ï¼Œè¿™ä¸€æ¬¡çš„nextå¼€å§‹çš„åœ°æ–¹æ˜¯æ¥ç€ä¸Šä¸€æ¬¡çš„nextåœæ­¢çš„åœ°æ–¹æ‰§è¡Œçš„ï¼Œæ‰€ä»¥è°ƒç”¨nextçš„æ—¶å€™ï¼Œç”Ÿæˆå™¨å¹¶ä¸ä¼šä»fooå‡½æ•°çš„å¼€å§‹æ‰§è¡Œï¼Œåªæ˜¯æ¥ç€ä¸Šä¸€æ­¥åœæ­¢çš„åœ°æ–¹å¼€å§‹ï¼Œç„¶åé‡åˆ°yieldåï¼Œreturnå‡ºè¦ç”Ÿæˆçš„æ•°ï¼Œæ­¤æ­¥å°±ç»“æŸã€‚ è®­ç»ƒéƒ¨åˆ† GANçš„è®­ç»ƒå’Œå…¶ä»–ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿˜æœ‰ä¸€ç‚¹ä¸å¤ªä¸€æ ·ï¼ŒGANçš„è®­ç»ƒæ˜¯Då’ŒGåˆ†å¼€è®­ç»ƒï¼ŒDå…ˆè®­ç»ƒå‡ è½®åï¼Œå®šä½Dè®­ç»ƒGï¼Œç„¶åä¾æ¬¡å¾€å¤ã€‚æœ‰ç‚¹åƒå·¦è„šè¸©å³è„šï¼ŒåŸåœ°å‡å¤©é‚£ç§æ„Ÿè§‰ã€‚ è®­ç»ƒD è®­ç»ƒé‰´åˆ«å™¨åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œè®­ç»ƒçœŸå®æ•°æ®ï¼Œè®­ç»ƒå‡æ•°æ®ï¼ˆGç”Ÿæˆçš„ï¼‰ï¼Œåå‘ä¼ æ’­ï¼Œé¦–å…ˆæ˜¯æˆ‘ä»¬å…ˆç»™é‰´åˆ«å™¨è¾“å…¥çœŸå®çš„æ•°æ®ï¼ˆä»£ç ä¸­æ˜¯xrï¼Œä½¿ç”¨åˆšæ‰æˆ‘ä»¬å†™çš„data_generatorç”Ÿæˆï¼‰,é‰´åˆ«å™¨çš„è¾“å‡ºæ˜¯predrã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–è¿™ä¸€éƒ¨åˆ†çš„è¾“å‡ºï¼ˆç›¸å½“äºæœ€å°åŒ–predrçš„ç›¸åæ•°ï¼‰ã€‚å› æ­¤lossr = - (predr.mean())ã€‚ç„¶åæˆ‘ä»¬å†ç»™é‰´åˆ«å™¨è¾“å…¥Gç”Ÿæˆçš„æ•°æ®ï¼ˆä»£ç ä¸­æ˜¯xfï¼‰,é‰´åˆ«å™¨çš„è¾“å‡ºæ˜¯predfã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å°åŒ–è¿™ä¸€éƒ¨åˆ†çš„è¾“å‡ºï¼ˆç›¸å½“äºæœ€å°åŒ–predrçš„ç›¸åæ•°ï¼‰ã€‚å› æ­¤lossf = (predr.mean())ã€‚ 1234567891011121314151617181920212223242526272829# 1. train discriminator for k stepsfor _ in range(5): x = next(data_iter) xr = torch.from_numpy(x).cuda() # [b] predr = (D(xr)) # max log(lossr) lossr = - (predr.mean()) # [b, 2] z = torch.randn(batchsz, 2).cuda() # stop gradient on G # [b, 2] xf = G(z).detach() # [b] predf = (D(xf)) # min predf lossf = (predf.mean()) # gradient penalty gp = gradient_penalty(D, xr, xf) loss_D = lossr + lossf + gp optim_D.zero_grad() loss_D.backward() # for p in D.parameters(): # print(p.grad.norm()) optim_D.step() æ³¨æ„ï¼šä»£ç ä¸­æœ‰ä¸€å¥`xf= G(z).detach()ã€‚è¿™å¥è¯çš„ä½œç”¨æ˜¯æ–­å¼€Gå’ŒDä¹‹é—´ç›¸è¿çš„åå‘ä¼ æ’­é“¾ï¼Œè¿™æ ·å°±ä¸ä¼šå†æˆ‘ä»¬æ›´æ–°Dçš„æ—¶å€™åŒæ—¶æ›´æ–°å‰é¢Dçš„å‚æ•°ã€‚ è¯¦ç»†è§£é‡Šï¼š tensor.detach()è¿”å›ä¸€ä¸ªæ–°çš„tensorï¼Œä»å½“å‰è®¡ç®—å›¾ä¸­åˆ†ç¦»ä¸‹æ¥ã€‚ä½†æ˜¯ä»æŒ‡å‘åŸå˜é‡çš„å­˜æ”¾ä½ç½®ï¼Œä¸åŒä¹‹å¤„åªæ˜¯requirse_gradä¸ºfalse.å¾—åˆ°çš„è¿™ä¸ªtensiræ°¸è¿œä¸éœ€è¦è®¡ç®—å™¨æ¢¯åº¦ï¼Œä¸å…·æœ‰grad. å³ä½¿ä¹‹åé‡æ–°å°†å®ƒçš„requires_gradç½®ä¸ºtrue,å®ƒä¹Ÿä¸ä¼šå…·æœ‰æ¢¯åº¦grad.è¿™æ ·æˆ‘ä»¬å°±ä¼šç»§ç»­ä½¿ç”¨è¿™ä¸ªæ–°çš„tensorè¿›è¡Œè®¡ç®—ï¼Œåé¢å½“æˆ‘ä»¬è¿›è¡Œåå‘ä¼ æ’­æ—¶åˆ°è¯¥è°ƒç”¨detach()çš„tensorå°±ä¼šåœæ­¢ï¼Œä¸èƒ½å†ç»§ç»­å‘å‰è¿›è¡Œä¼ æ’­. æ³¨æ„ï¼šæ˜¯ç»§ç»­ä½¿ç”¨è¿™ä¸ªæ–°çš„tensor`è¿›è¡Œè®¡ç®—ï¼ è®­ç»ƒG ç„¶åæ¥ä¸‹æ¥å°±æ˜¯è®­ç»ƒç”Ÿæˆå™¨Gäº†ï¼Œç”Ÿæˆå™¨çš„è®­ç»ƒæ˜¯æ ¹æ®éšæœºæ­£æ€åˆ†å¸ƒä¸­çš„é‡‡æ ·æ¥å­¦ä¹ æˆ‘ä»¬è¦å­¦ä¹ çš„åˆ†å¸ƒçš„ç‰¹å¾ã€‚ 12345678910# 2. train Generatoroptim_D.zero_grad()z = torch.randn(batchsz, 2).cuda()xf = G(z)predf = (D(xf))# max predfloss_G = - (predf.mean())optim_G.zero_grad()loss_G.backward()optim_G.step() æ³¨æ„ï¼šDè®­ç»ƒå®Œäº†ä»¥åä¸€å®šè¦æ¸…é›¶ï¼Œé˜²æ­¢Gæ›´æ–°çš„æ—¶å€™åå‘ä¼ æ’­æ›´æ–°Dçš„ç½‘ç»œå‚æ•°ã€‚ ç»“æœ è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¤§æ¦‚ç‡å¾—åˆ°çš„GANçš„è®­ç»ƒç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬ä¼šå‘ç°Dçš„é‰´åˆ«å¾ˆå‡†ç¡®ï¼Œè¯¯å·®æ˜¯0ï¼Œè€ŒGå› ä¸ºç”Ÿæˆçš„å¾ˆçƒ‚æ‰€ä»¥æ˜¯-1ï¼Œä½†æ˜¯åˆå› ä¸ºJSçš„ç‰¹æ€§ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•æ›´æ–°ï¼ˆåˆ†å¸ƒä¸é‡åˆï¼ŒJSæ’å®šï¼Œæ¢¯åº¦ä¸º0ï¼‰ã€‚å› æ­¤ä¸ºäº†è§£å†³è¿™ç§é—®é¢˜æˆ‘ä»¬éœ€è¦å¼•å…¥ä¸Šæ–‡æ‰€è¯´çš„WGANã€‚ å®æˆ˜WGAN ç•¥å¾®ä¸åŒäºGANï¼Œä¸»è¦æ˜¯è®­ç»ƒé‰´åˆ«å™¨éƒ¨åˆ†æœ‰ä¸€äº›å·®åˆ«ã€‚è®­ç»ƒé‰´åˆ«å™¨åœ¨WGANä¸­åˆ†ä¸ºå››ä¸ªéƒ¨åˆ†ï¼Œè®­ç»ƒçœŸå®æ•°æ®ï¼Œè®­ç»ƒå‡æ•°æ®ï¼ˆGç”Ÿæˆçš„ï¼‰ï¼Œæ¢¯åº¦æƒ©ç½šï¼ˆgradient penaltyï¼‰ï¼Œåå‘ä¼ æ’­ï¼Œé¦–å…ˆæ˜¯æˆ‘ä»¬å…ˆç»™é‰´åˆ«å™¨è¾“å…¥çœŸå®çš„æ•°æ®ï¼ˆä»£ç ä¸­æ˜¯xrï¼Œä½¿ç”¨åˆšæ‰æˆ‘ä»¬å†™çš„data_generatorç”Ÿæˆï¼‰,é‰´åˆ«å™¨çš„è¾“å‡ºæ˜¯predrã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–è¿™ä¸€éƒ¨åˆ†çš„è¾“å‡ºï¼ˆç›¸å½“äºæœ€å°åŒ–predrçš„ç›¸åæ•°ï¼‰ã€‚å› æ­¤lossr = - (predr.mean())ã€‚ç„¶åæˆ‘ä»¬å†ç»™é‰´åˆ«å™¨è¾“å…¥Gç”Ÿæˆçš„æ•°æ®ï¼ˆä»£ç ä¸­æ˜¯xfï¼‰,é‰´åˆ«å™¨çš„è¾“å‡ºæ˜¯predfã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å°åŒ–è¿™ä¸€éƒ¨åˆ†çš„è¾“å‡ºï¼ˆç›¸å½“äºæœ€å°åŒ–predrçš„ç›¸åæ•°ï¼‰ã€‚å› æ­¤lossf = (predr.mean())ã€‚ ç„¶åæ¥ç€æ˜¯æ¢¯åº¦æƒ©ç½šæ“ä½œï¼Œè¿™ä¸€æ­¥éå¸¸é‡è¦åé¢æˆ‘ä»¬å•ç‹¬è®²ï¼Œç®—å‡ºéœ€è¦æˆ‘ä»¬æœ€å°åŒ–çš„gpã€‚ç„¶åæˆ‘ä»¬å°±å¯ä»¥å†™å‡ºæˆ‘ä»¬æœ€åéœ€è¦æœ€å°åŒ–çš„å‡½æ•°loss_D = lossr + lossf + gpã€‚ç„¶åè¿›è¡Œæœ€åä¸€æ­¥åå‘ä¼ æ’­ã€‚ ç½‘ç»œç»“æ„ å’ŒGANåŸºæœ¬ä¸€æ ·ï¼Œä¸å†èµ˜è¿°ã€‚ ç›¸æ¯”äºGANåªæ˜¯å¤šäº†ä¸€ä¸ª**æ¢¯åº¦æƒ©ç½š(gradient_penalty)**éƒ¨åˆ†ã€‚ æ¢¯åº¦æƒ©ç½š(gradient_penalty) ç¨å¾®ç†è§£ä¸€ä¸‹å³å¯ï¼Œæˆ‘ä»¬æœ€åæ˜¯è¦æœ€å°åŒ–è¯¥å‡½æ•°è¿”å›çš„gpçš„ï¼Œå…·ä½“ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 123456789101112131415161718192021222324252627282930def gradient_penalty(D, xr, xf): &quot;&quot;&quot; :param D: :param xr: :param xf: :return: &quot;&quot;&quot; LAMBDA = 0.3 # only constrait for Discriminator xf = xf.detach() xr = xr.detach() # [b, 1] =&gt; [b, 2] alpha = torch.rand(batchsz, 1).cuda() alpha = alpha.expand_as(xr) interpolates = alpha * xr + ((1 - alpha) * xf) interpolates.requires_grad_() disc_interpolates = D(interpolates) gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones_like(disc_interpolates), create_graph=True, retain_graph=True, only_inputs=True)[0] # å¯¹ä¸­é—´ç‚¹é‰´åˆ«ç»“æœå…³äºä¸­é—´ç‚¹ä¿¡æ¯æ±‚å¯¼ gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA return gp å¤–é¢è°ƒç”¨å¦‚ä¸‹ä»£ç æ‰€ç¤ºï¼š 12# gradient penaltygp = gradient_penalty(D, xr, xf) æ³¨æ„ï¼šè¿™é‡Œçš„xfåœ¨å‰é¢æ˜¯ç»è¿‡äº†detach()æ“ä½œçš„ã€‚ ä»£ç æ±‡æ€» æœ€ååœ¨åŠ ä¸Šä¸€äº›ç»†èŠ‚ï¼Œæœ€ç»ˆçš„WGANä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249import torch from torch import nn, optim, autogradimport numpy as npimport visdomfrom torch.nn import functional as Ffrom matplotlib import pyplot as pltimport randomh_dim = 400batchsz = 512viz = visdom.Visdom()class Generator(nn.Module): def __init__(self): super(Generator, self).__init__() self.net = nn.Sequential( nn.Linear(2, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, 2), ) def forward(self, z): output = self.net(z) return outputclass Discriminator(nn.Module): def __init__(self): super(Discriminator, self).__init__() self.net = nn.Sequential( nn.Linear(2, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, h_dim), nn.ReLU(True), nn.Linear(h_dim, 1), nn.Sigmoid() ) def forward(self, x): output = self.net(x) return output.view(-1)def data_generator(): scale = 2. centers = [ (1, 0), (-1, 0), (0, 1), (0, -1), (1. / np.sqrt(2), 1. / np.sqrt(2)), (1. / np.sqrt(2), -1. / np.sqrt(2)), (-1. / np.sqrt(2), 1. / np.sqrt(2)), (-1. / np.sqrt(2), -1. / np.sqrt(2)) ] centers = [(scale * x, scale * y) for x, y in centers] while True: dataset = [] for i in range(batchsz): point = np.random.randn(2) * .02 center = random.choice(centers) point[0] += center[0] point[1] += center[1] dataset.append(point) dataset = np.array(dataset, dtype=&#x27;float32&#x27;) dataset /= 1.414 # stdev yield dataset # for i in range(100000//25): # for x in range(-2, 3): # for y in range(-2, 3): # point = np.random.randn(2).astype(np.float32) * 0.05 # point[0] += 2 * x # point[1] += 2 * y # dataset.append(point) # # dataset = np.array(dataset) # print(&#x27;dataset:&#x27;, dataset.shape) # viz.scatter(dataset, win=&#x27;dataset&#x27;, opts=dict(title=&#x27;dataset&#x27;, webgl=True)) # # while True: # np.random.shuffle(dataset) # # for i in range(len(dataset)//batchsz): # yield dataset[i*batchsz : (i+1)*batchsz]def generate_image(D, G, xr, epoch): &quot;&quot;&quot; Generates and saves a plot of the true distribution, the generator, and the critic. &quot;&quot;&quot; N_POINTS = 128 RANGE = 3 plt.clf() points = np.zeros((N_POINTS, N_POINTS, 2), dtype=&#x27;float32&#x27;) points[:, :, 0] = np.linspace(-RANGE, RANGE, N_POINTS)[:, None] points[:, :, 1] = np.linspace(-RANGE, RANGE, N_POINTS)[None, :] points = points.reshape((-1, 2)) # (16384, 2) # print(&#x27;p:&#x27;, points.shape) # draw contour with torch.no_grad(): points = torch.Tensor(points).cuda() # [16384, 2] disc_map = D(points).cpu().numpy() # [16384] x = y = np.linspace(-RANGE, RANGE, N_POINTS) cs = plt.contour(x, y, disc_map.reshape((len(x), len(y))).transpose()) plt.clabel(cs, inline=1, fontsize=10) # plt.colorbar() # draw samples with torch.no_grad(): z = torch.randn(batchsz, 2).cuda() # [b, 2] samples = G(z).cpu().numpy() # [b, 2] plt.scatter(xr[:, 0], xr[:, 1], c=&#x27;orange&#x27;, marker=&#x27;.&#x27;) plt.scatter(samples[:, 0], samples[:, 1], c=&#x27;green&#x27;, marker=&#x27;+&#x27;) viz.matplot(plt, win=&#x27;contour&#x27;, opts=dict(title=&#x27;p(x):%d&#x27;%epoch))def weights_init(m): if isinstance(m, nn.Linear): # m.weight.data.normal_(0.0, 0.02) nn.init.kaiming_normal_(m.weight) m.bias.data.fill_(0)def gradient_penalty(D, xr, xf): &quot;&quot;&quot; :param D: :param xr: :param xf: :return: &quot;&quot;&quot; LAMBDA = 0.3 # only constrait for Discriminator xf = xf.detach() xr = xr.detach() # [b, 1] =&gt; [b, 2] alpha = torch.rand(batchsz, 1).cuda() alpha = alpha.expand_as(xr) interpolates = alpha * xr + ((1 - alpha) * xf) interpolates.requires_grad_() disc_interpolates = D(interpolates) gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates, grad_outputs=torch.ones_like(disc_interpolates), create_graph=True, retain_graph=True, only_inputs=True)[0] gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA return gpdef main(): torch.manual_seed(23) np.random.seed(23) G = Generator().cuda() D = Discriminator().cuda() G.apply(weights_init) D.apply(weights_init) optim_G = optim.Adam(G.parameters(), lr=1e-3, betas=(0.5, 0.9)) optim_D = optim.Adam(D.parameters(), lr=1e-3, betas=(0.5, 0.9)) data_iter = data_generator() print(&#x27;batch:&#x27;, next(data_iter).shape) viz.line([[0,0]], [0], win=&#x27;loss&#x27;, opts=dict(title=&#x27;loss&#x27;, legend=[&#x27;D&#x27;, &#x27;G&#x27;])) for epoch in range(50000): # 1. train discriminator for k steps for _ in range(5): x = next(data_iter) xr = torch.from_numpy(x).cuda() # [b] predr = (D(xr)) # max log(lossr) lossr = - (predr.mean()) # [b, 2] z = torch.randn(batchsz, 2).cuda() # stop gradient on G # [b, 2] xf = G(z).detach() # [b] predf = (D(xf)) # min predf lossf = (predf.mean()) # gradient penalty gp = gradient_penalty(D, xr, xf) loss_D = lossr + lossf + gp optim_D.zero_grad() loss_D.backward() # for p in D.parameters(): # print(p.grad.norm()) optim_D.step() # 2. train Generator optim_D.zero_grad() z = torch.randn(batchsz, 2).cuda() xf = G(z) predf = (D(xf)) # max predf loss_G = - (predf.mean()) optim_G.zero_grad() loss_G.backward() optim_G.step() if epoch % 100 == 0: viz.line([[loss_D.item(), loss_G.item()]], [epoch], win=&#x27;loss&#x27;, update=&#x27;append&#x27;) generate_image(D, G, xr, epoch) print(loss_D.item(), loss_G.item())if __name__ == &#x27;__main__&#x27;: main()"},{"title":"PyTorch è‡ªå®šä¹‰æ•°æ®é›†å®æˆ˜","path":"/wiki/PyTorch/PyTorchè‡ªå®šä¹‰æ•°æ®é›†å®æˆ˜.html","content":"åœ¨å‰é¢çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å·²ç»è¾ƒä¸ºç†Ÿç»ƒçš„æŒæ¡äº†ä¸åŒç§ç±»ç¥ç»ç½‘ç»œçš„åŸç†å’ŒåŸºæœ¬PyTorchå®ç°ï¼Œä½†æ˜¯ä¹‹å‰æˆ‘ä»¬æ‰€ä½¿ç”¨çš„æ•°æ®é›†å¤šä¸ºPyTorchä¸­ç°æˆçš„ï¼Œå¹¶æ²¡æœ‰è‡ªå·±æå–æ•°æ®çš„è¿™ä¸€è¿‡ç¨‹ï¼Œæ‰€ä»¥æœ¬ç¯‡åšå®¢æ—¨åœ¨é‡‡ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼Œå¸®åŠ©å¤§å®¶ä½“éªŒä¸€æ¬¡åŒ…å«æ•°æ®æå–ï¼Œæ•°æ®è®­ç»ƒï¼Œæ•°æ®æµ‹è¯•çš„å®Œæ•´çš„ç¥ç»ç½‘ç»œæ•°æ®å¤„ç†è¿‡ç¨‹ã€‚ Pokemon æ•°æ®é›† æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ æœ¬æ¬¡å®æˆ˜ï¼Œé‡‡ç”¨Pokemonè‡ªå®šä¹‰æ•°æ®é›†ï¼Œæ•°æ®é›†ä¸­åŒ…å«5ç§ç±»å‹çš„ç²¾çµ æ•°æ®é›†ä¸­æ‰€åŒ…å«çš„å›¾ç‰‡çš„æ•°é‡åˆ†åˆ«æ˜¯ï¼š çš®å¡ä¸˜ ï¼š234 è¶…æ¢¦ï¼š 239 æ°å°¼é¾Ÿï¼š 223 å°ç«é¾™ï¼š 238 å¦™è›™ç§å­ï¼š 234 æ•°æ®é›†åˆ’åˆ† å®æˆ˜æ­¥éª¤ æ•°æ®é›†åŠ è½½ï¼ˆLoad dataï¼‰â€» åˆ›å»ºæ¨¡å‹ï¼ˆBuild modelï¼‰ è®­ç»ƒå’Œæµ‹è¯•ï¼ˆTrain and Testï¼‰ è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰â€» æ•°æ®é›†åŠ è½½ è¿™ä¸€éƒ¨åˆ†çš„å·¥ä½œä¸»è¦å°±æ˜¯è¦ç»§æ‰¿çˆ¶ç±»ï¼ˆtorch.utils.data.Datasetï¼‰å¹¶ä¸”å®ç°è¯¥ç±»ä¸‹çš„ä¸¤ä¸ªå‡½æ•° __len__:è¿”å›æ ·æœ¬é•¿åº¦ __getitem__:å–å‡ºæ ·æœ¬ ä¸¾ä¸ªä¾‹å­ï¼š 12345678910class NumberDataset(Dataset): def __init__(self,training=True): if training: self.samples = list(range(1,1001)) else: self.samples = list(range(1001,1501)) def __len__(self): return len(self.samples) def __getitem__(self, idx): return self.samples[idx] äº†è§£äº†æ•°æ®é›†PyTorchä¸­çš„åŠ è½½æ–¹æ³•ï¼Œä¸‹é¢æ¥ä»‹ç»ä¸€ä¸‹æœ¬æ¬¡é¡¹ç›®éœ€è¦å®Œæˆçš„æ•°æ®é¢„å¤„ç†ç›¸å…³æ“ä½œã€‚ æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼ˆPreprocessingï¼‰ Image Resize 224*224 for ResNet 18 Data Argumentation Rotate Crop Normalize Mean,std ToTensor æ•°æ®é›†å­˜æ”¾æ–‡ä»¶ç»“æ„ 123456pokemanâ”œâ”€bulbasaurâ”œâ”€charmanderâ”œâ”€mewtwoâ”œâ”€pikachuâ””â”€squirtle å¯ä»¥å‘ç°æ˜¯5ç§ç²¾çµæ˜¯åˆ†äº†5ä¸ªæ–‡ä»¶å¤¹ï¼Œæˆ‘ä»¬æ‰“å¼€pikachuæ–‡ä»¶å¤¹ï¼Œå¯ä»¥çœ‹åˆ°é‡Œé¢çš„å›¾ç‰‡æ•°æ®æ˜¯è¿™æ ·çš„ã€‚ è¿™æ ·å­˜æ”¾çš„å¥½å¤„æ˜¯ï¼Œä½¿ç”¨PyTorchå¯ä»¥ç›´æ¥ä¸€è¡Œä»£ç å¯¼å…¥æ‰€æœ‰çš„æ•°æ®ã€‚åé¢æˆ‘ä»¬ä¼šè¿›è¡Œè®²è§£ã€‚ PyTorchå®ç° é¦–å…ˆæ˜¯åå­—ç±»åˆ«çš„æ˜ å°„ name2label 12345678910111213def __init__(self, root, resize, mode): super(Pokemon, self).__init__() # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–å‡½æ•° self.root = root self.resize = resize # åˆ›å»ºç±»åˆ«å’Œæ ‡ç­¾æ˜ å°„è¡¨ self.name2label=&#123;&#125; for name in sorted(os.listdir((os.path.join(root)))): if not os.path.isdir(os.path.join(root,name)): continue self.name2label[name] = len(self.name2label.keys()) # è°ƒè¯•ä»£ç  print(self.name2label) è¿™é‡Œå› ä¸ºlistdirè¿”å›çš„é¡ºåºä¸ç¨³å®šï¼Œæ‰€ä»¥è¿”å›åå¢åŠ ä¸€ä¸ªsortedå‡½æ•°å¯¹åå­—æ’åºï¼Œè¿™æ ·å°±ä¿è¯äº†è¿”å›çš„é¡ºåºç¨³å®šçš„é—®é¢˜ã€‚ ç»“æœå¦‚ä¸‹ï¼š 1&#123;&#x27;bulbasaur&#x27;: 0, &#x27;charmander&#x27;: 1, &#x27;mewtwo&#x27;: 2, &#x27;pikachu&#x27;: 3, &#x27;squirtle&#x27;: 4&#125; æ³¨æ„__getitem__é‡å†™çš„æ—¶å€™è¦å°†å›¾ç‰‡é‡Œé¢çš„ä¿¡æ¯æå–å‡ºæ¥ï¼Œè€Œä¸æ˜¯å›¾ç‰‡çš„è·¯å¾„ï¼ï¼ï¼ load_csvåŠ è½½æ–‡ä»¶ä¿¡æ¯ è¿™ä¸ªå‡½æ•°ä¹Ÿæ˜¯å†™åœ¨æˆ‘ä»¬è‡ªå·±çš„Classä¸­çš„ï¼Œç›®çš„æ˜¯æ ¹æ®ä¸€ä¸ªæ•°æ®é›†åŠ è½½ä¸€ä¸ªæ•°æ®é›†ä¿¡æ¯çš„csvæ–‡ä»¶(å¦‚æœæ²¡æœ‰å°±å…ˆåˆ›å»ºä¸€ä¸ªç„¶åå†åŠ è½½)ï¼Œæ–‡ä»¶ä¸­å­˜å‚¨æ¯ä¸€ä¸ªæ•°æ®çš„å­˜æ”¾ä½ç½®ä»¥åŠæ ‡ç­¾ä¿¡æ¯ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839def load_csv(self, filename):\t# æ²¡æœ‰csvæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶ï¼Œç”Ÿæˆä¸€ä¸ª if not os.path.exists(os.path.join(self.root, filename)): images = [] for name in self.name2label.keys(): # &#x27;pokemon\\\\mewtwo\\\\00001.png images += glob.glob(os.path.join(self.root, name, &#x27;*.png&#x27;)) images += glob.glob(os.path.join(self.root, name, &#x27;*.jpg&#x27;)) images += glob.glob(os.path.join(self.root, name, &#x27;*.jpeg&#x27;)) # 1167, &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27; print(len(images), images) random.shuffle(images) with open(os.path.join(self.root, filename), mode=&#x27;w&#x27;, newline=&#x27;&#x27;) as f: writer = csv.writer(f) for img in images: # &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27; name = img.split(os.sep)[-2] label = self.name2label[name] # &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27;, 0 writer.writerow([img, label]) print(&#x27;writen into csv file:&#x27;, filename) # å¦‚æœå­˜åœ¨csvæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶ï¼Œåˆ™è¯»å– # read from csv file images, labels = [], [] with open(os.path.join(self.root, filename)) as f: reader = csv.reader(f) for row in reader: # &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27;, 0 img, label = row label = int(label) images.append(img) labels.append(label) assert len(images) == len(labels) return images, labels globæ˜¯pythonè‡ªå·±å¸¦çš„ä¸€ä¸ªæ–‡ä»¶æ“ä½œç›¸å…³æ¨¡å—ï¼Œç”¨å®ƒå¯ä»¥æŸ¥æ‰¾ç¬¦åˆè‡ªå·±ç›®çš„çš„æ–‡ä»¶.è¯¥æ–¹æ³•è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆlistï¼‰ï¼›è¯¥æ–¹æ³•éœ€è¦ä¸€ä¸ªå‚æ•°ç”¨æ¥æŒ‡å®šåŒ¹é…çš„è·¯å¾„å­—ç¬¦ä¸²ï¼ˆå­—ç¬¦ä¸²å¯ä»¥ä¸ºç»å¯¹è·¯å¾„ä¹Ÿå¯ä»¥ä¸ºç›¸å¯¹è·¯å¾„ï¼‰ï¼Œå…¶è¿”å›çš„æ–‡ä»¶ååªåŒ…æ‹¬å½“å‰ç›®å½•é‡Œçš„æ–‡ä»¶åï¼Œä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹é‡Œçš„æ–‡ä»¶ã€‚ åˆ’åˆ†æ•°æ®é›† åœ¨__init__ä¸­load_csvåï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œæ•°æ®é›†è£å‰ªäº†ã€‚ 123456789101112# image, labelself.images, self.labels = self.load_csv(&#x27;images.csv&#x27;)if mode==&#x27;train&#x27;: # 60% self.images = self.images[:int(0.6*len(self.images))] self.labels = self.labels[:int(0.6*len(self.labels))]elif mode==&#x27;val&#x27;: # 20% = 60%-&gt;80% self.images = self.images[int(0.6*len(self.images)):int(0.8*len(self.images))] self.labels = self.labels[int(0.6*len(self.labels)):int(0.8*len(self.labels))]else: # 20% = 80%-&gt;100% self.images = self.images[int(0.8*len(self.images)):] self.labels = self.labels[int(0.8*len(self.labels)):] å…¶å®æˆ‘æ›´æ¨èçš„æ–¹æ³•æ˜¯å…ˆå°†æ•°æ®é›†å…¨éƒ¨è¯»å‡ºæ¥ï¼Œç„¶åå†å¦å†™ä¸€ä¸ªå‡½æ•°ï¼Œä½¿ç”¨PyTorchæä¾›çš„subsetæ–¹æ³•å¯¹æ•°æ®é›†è¿›è¡Œåˆ’åˆ†ã€‚è¯¦æƒ…å¯ä»¥è§PyTorchæŠ€å·§ä¸­Kfoldè¿™ä¸€ä¸ªæ¨¡å—ã€‚ æ•°æ®å¢å¼º æˆ‘ä»¬æ˜¯åœ¨å–æ•°æ®çš„æ—¶å€™å¯¹æ•°æ®è¿›è¡Œæ•°æ®å¢å¼ºæ“ä½œ 12345678910111213141516171819202122def __getitem__(self, idx): # idx~[0~len(images)] # self.images, self.labels # img: &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27; # label: 0 img, label = self.images[idx], self.labels[idx] tf = transforms.Compose([ lambda x:Image.open(x).convert(&#x27;RGB&#x27;), # string path= &gt; image data transforms.Resize((int(self.resize*1.25), int(self.resize*1.25))), transforms.RandomRotation(15), transforms.CenterCrop(self.resize), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) img = tf(img) label = torch.tensor(label) return img, label Classéƒ¨åˆ†ä»£ç æ±‡æ€» 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119class Pokemon(Dataset): def __init__(self, root, resize, mode): super(Pokemon, self).__init__() self.root = root self.resize = resize self.name2label = &#123;&#125; # &quot;sq...&quot;:0 for name in sorted(os.listdir(os.path.join(root))): if not os.path.isdir(os.path.join(root, name)): continue self.name2label[name] = len(self.name2label.keys()) # print(self.name2label) # image, label self.images, self.labels = self.load_csv(&#x27;images.csv&#x27;) if mode==&#x27;train&#x27;: # 60% self.images = self.images[:int(0.6*len(self.images))] self.labels = self.labels[:int(0.6*len(self.labels))] elif mode==&#x27;val&#x27;: # 20% = 60%-&gt;80% self.images = self.images[int(0.6*len(self.images)):int(0.8*len(self.images))] self.labels = self.labels[int(0.6*len(self.labels)):int(0.8*len(self.labels))] else: # 20% = 80%-&gt;100% self.images = self.images[int(0.8*len(self.images)):] self.labels = self.labels[int(0.8*len(self.labels)):] def load_csv(self, filename): if not os.path.exists(os.path.join(self.root, filename)): images = [] for name in self.name2label.keys(): # &#x27;pokemon\\\\mewtwo\\\\00001.png images += glob.glob(os.path.join(self.root, name, &#x27;*.png&#x27;)) images += glob.glob(os.path.join(self.root, name, &#x27;*.jpg&#x27;)) images += glob.glob(os.path.join(self.root, name, &#x27;*.jpeg&#x27;)) # 1167, &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27; print(len(images), images) random.shuffle(images) with open(os.path.join(self.root, filename), mode=&#x27;w&#x27;, newline=&#x27;&#x27;) as f: writer = csv.writer(f) for img in images: # &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27; name = img.split(os.sep)[-2] label = self.name2label[name] # &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27;, 0 writer.writerow([img, label]) print(&#x27;writen into csv file:&#x27;, filename) # read from csv file images, labels = [], [] with open(os.path.join(self.root, filename)) as f: reader = csv.reader(f) for row in reader: # &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27;, 0 img, label = row label = int(label) images.append(img) labels.append(label) assert len(images) == len(labels) return images, labels def __len__(self): return len(self.images) def denormalize(self, x_hat): mean = [0.485, 0.456, 0.406] std = [0.229, 0.224, 0.225] # x_hat = (x-mean)/std # x = x_hat*std = mean # x: [c, h, w] # mean: [3] =&gt; [3, 1, 1] mean = torch.tensor(mean).unsqueeze(1).unsqueeze(1) std = torch.tensor(std).unsqueeze(1).unsqueeze(1) # print(mean.shape, std.shape) x = x_hat * std + mean return x def __getitem__(self, idx): # idx~[0~len(images)] # self.images, self.labels # img: &#x27;pokemon\\\\bulbasaur\\\\00000000.png&#x27; # label: 0 img, label = self.images[idx], self.labels[idx] tf = transforms.Compose([ lambda x:Image.open(x).convert(&#x27;RGB&#x27;), # string path= &gt; image data transforms.Resize((int(self.resize*1.25), int(self.resize*1.25))), transforms.RandomRotation(15), transforms.CenterCrop(self.resize), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) img = tf(img) label = torch.tensor(label) return img, label å…¶ä¸­denormalizeå‡½æ•°åšçš„å·¥ä½œæ˜¯åæ­£åˆ™åŒ– VisdoméªŒè¯è‡ªå®šä¹‰æ•°æ®é›†åŠ è½½æ­£ç¡®æ€§ æˆ‘ä»¬åœ¨ä¸»å‡½æ•°ä¸­å†™ä¸‹å¦‚ä¸‹çš„ä»£ç ï¼š 12345678910111213141516171819import visdomimport timeimport torchvisionviz = visdom.Visdom()db = Pokemon(&#x27;pokemon&#x27;, 64, &#x27;train&#x27;)x,y = next(iter(db))print(&#x27;sample:&#x27;, x.shape, y.shape, y)viz.image(db.denormalize(x), win=&#x27;sample_x&#x27;, opts=dict(title=&#x27;sample_x&#x27;))loader = DataLoader(db, batch_size=32, shuffle=True, num_workers=8)for x,y in loader: viz.images(db.denormalize(x), nrow=8, win=&#x27;batch&#x27;, opts=dict(title=&#x27;batch&#x27;)) viz.text(str(y.numpy()), win=&#x27;label&#x27;, opts=dict(title=&#x27;batch-y&#x27;))time.sleep(10) ä½¿ç”¨Visdomä¹‹å‰ä¸€å®šè¦åœ¨å‘½ä»¤è¡Œå¯åŠ¨Visdomæœ¬åœ°æœåŠ¡å™¨ï¼Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤ 1python -m visdom.server è¿è¡Œæ•ˆæœæ˜¯æ¯è¿‡10sload32å¼ å›¾å‡ºæ¥ï¼Œä¸€æ’8ä¸ªï¼Œä¸€å…±4æ’ã€‚ è‡ªå®šä¹‰æ•°æ®é›†çš„éƒ¨åˆ†å°±å®Œæˆäº†ï¼Œä¸‹é¢å°±è¿›å…¥åˆ°å»ºç«‹æ¨¡å‹çš„é˜¶æ®µäº†ã€‚ å»ºç«‹æ¨¡å‹ è¿™ä¸€é˜¶æ®µåœ¨ä¹‹å‰çš„PyTorch CNNå®æˆ˜éƒ¨åˆ†å·²ç»æœ‰è¿‡è¯¦ç»†çš„è®²è§£äº†ï¼Œè¿™é‡Œå°±ä¸èµ˜è¿°äº†ã€‚ æœ¬å®éªŒä½¿ç”¨çš„ResNet18æ¨¡å‹ä»£ç ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041class ResNet18(nn.Module): def __init__(self, num_class): super(ResNet18, self).__init__() self.conv1 = nn.Sequential( nn.Conv2d(3, 16, kernel_size=3, stride=3, padding=0), nn.BatchNorm2d(16) ) # followed 4 blocks # [b, 16, h, w] =&gt; [b, 32, h ,w] self.blk1 = ResBlk(16, 32, stride=3) # [b, 32, h, w] =&gt; [b, 64, h, w] self.blk2 = ResBlk(32, 64, stride=3) # # [b, 64, h, w] =&gt; [b, 128, h, w] self.blk3 = ResBlk(64, 128, stride=2) # # [b, 128, h, w] =&gt; [b, 256, h, w] self.blk4 = ResBlk(128, 256, stride=2) # [b, 256, 7, 7] self.outlayer = nn.Linear(256*3*3, num_class) def forward(self, x): &quot;&quot;&quot; :param x: :return: &quot;&quot;&quot; x = F.relu(self.conv1(x)) # [b, 64, h, w] =&gt; [b, 1024, h, w] x = self.blk1(x) x = self.blk2(x) x = self.blk3(x) x = self.blk4(x) # print(x.shape) x = x.view(x.size(0), -1) x = self.outlayer(x) return x è®­ç»ƒï¼ŒéªŒè¯ï¼Œæµ‹è¯• ä¸¥æ ¼Trainï¼ŒValï¼ŒTestæ¨¡æ¿â€» 12345678910111213for epoch in range(epochs): train(train_db) if epoch%10==0: # Val val_acc = evaluate(val_db) if val_acc is the best: save_ckpt() # ä¿å­˜å½“å‰ç½‘ç»œå‚æ•° if out_of_patience(): breakload_ckpt # åŠ è½½ç½‘ç»œå‚æ•°test_acc = evaluate(test_db) # test ä»¥åè®­ç»ƒæŒ‰ç…§ä»¥ä¸Šæ¨¡æ¿è¿›è¡Œä¹¦å†™å³å¯ã€‚ æœ¬å®éªŒä¸­æ‰€ä½¿ç”¨çš„ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š evaluateéƒ¨åˆ† 1234567891011121314def evalute(model, loader): model.eval() correct = 0 total = len(loader.dataset) for x,y in loader: x,y = x.to(device), y.to(device) with torch.no_grad(): logits = model(x) pred = logits.argmax(dim=1) correct += torch.eq(pred, y).sum().float().item() return correct / total mainéƒ¨åˆ† 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def main(): model = ResNet18(5).to(device) optimizer = optim.Adam(model.parameters(), lr=lr) criteon = nn.CrossEntropyLoss() best_acc, best_epoch = 0, 0 # ä¿å­˜æœ€ä¼˜æ¨¡å‹å‚æ•° global_step = 0 viz.line([0], [-1], win=&#x27;loss&#x27;, opts=dict(title=&#x27;loss&#x27;)) viz.line([0], [-1], win=&#x27;val_acc&#x27;, opts=dict(title=&#x27;val_acc&#x27;)) for epoch in range(epochs): for step, (x,y) in enumerate(train_loader): # x: [b, 3, 224, 224], y: [b] x, y = x.to(device), y.to(device) model.train() logits = model(x) loss = criteon(logits, y) optimizer.zero_grad() loss.backward() optimizer.step() viz.line([loss.item()], [global_step], win=&#x27;loss&#x27;, update=&#x27;append&#x27;) global_step += 1 if epoch % 1 == 0: val_acc = evalute(model, val_loader) if val_acc&gt; best_acc: best_epoch = epoch best_acc = val_acc torch.save(model.state_dict(), &#x27;best.mdl&#x27;) # ä¿å­˜æœ€ä¼˜æ¨¡å‹å‚æ•° viz.line([val_acc], [global_step], win=&#x27;val_acc&#x27;, update=&#x27;append&#x27;)\t# ç»“æŸtrainå print(&#x27;best acc:&#x27;, best_acc, &#x27;best epoch:&#x27;, best_epoch)\t# åŠ è½½æœ€ä¼˜æ¨¡å‹ model.load_state_dict(torch.load(&#x27;best.mdl&#x27;)) print(&#x27;loaded from ckpt!&#x27;)\t# è¿›è¡Œtest test_acc = evalute(model, test_loader) print(&#x27;test acc:&#x27;, test_acc) å¦‚æœæƒ³è¦å®æ—¶æ£€æµ‹è®­ç»ƒæƒ…å†µï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨visdomå·¥å…·ï¼Œè€Œä¸æ˜¯æœ€åè¿›è¡Œmatplotlibï¼Œå®æ—¶ç›‘æ§å¯ä»¥åœ¨æ¨¡å‹å‡ºç°é—®é¢˜æ—¶åŠæ—¶åœä¸‹æ¥ï¼Œè¿›è¡Œè°ƒæ•´ã€‚(å¦‚ä¸Šé¢çš„ä»£ç æ‰€ç¤º) ç›®å‰ç»“æœ æŒ‰ç…§ä»¥ä¸Šæ­¥éª¤ä¸‹æ¥ï¼Œæˆ‘ä»¬çš„æ¨¡å‹trainä¸‹æ¥çš„lossæ˜¯éå¸¸å°çš„ï¼Œä½†æ˜¯æµ‹è¯•é›†ï¼Œå‡†ç¡®ç‡å¹¶æ²¡æœ‰è¾¾åˆ°ç†æƒ³çš„å‡†ç¡®ç‡ï¼Œè¿™è¯´æ˜æˆ‘ä»¬çš„æ¨¡å‹å‘ç”Ÿäº†è¿‡æ‹Ÿåˆ,å‘ç”Ÿè¿™æ ·çš„äº‹æƒ…éå¸¸çš„æ­£å¸¸ï¼Œå› ä¸ºæˆ‘ä»¬æ•°æ®é›†çš„è§„æ¨¡éå¸¸çš„å°ï¼Œè€Œä¸”ç§ç±»ä¹Ÿä¸å¤šï¼Œå¯¹äºResNet18è¿™ç§è¾ƒä¸ºå¤æ‚çš„ç¥ç»ç½‘ç»œæ˜¯ä¸å¤Ÿçš„ï¼Œå¾ˆå®¹æ˜“å‡ºç°è¿™æ ·çš„é—®é¢˜ï¼Œå› æ­¤ï¼Œè¿™ä¸ªæ—¶å€™å°±æœ‰å¿…è¦ä½¿ç”¨è¿ç§»å­¦ä¹ è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜äº†ã€‚ è¿ç§»å­¦ä¹ ï¼ˆTransfer Learningï¼‰ ç®€è€Œè¨€ä¹‹ï¼Œè¿ç§»å­¦ä¹ æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå°±æ˜¯æŠŠä¸ºä»»åŠ¡ A å¼€å‘çš„æ¨¡å‹ä½œä¸ºåˆå§‹ç‚¹ï¼Œé‡æ–°ä½¿ç”¨åœ¨ä¸ºä»»åŠ¡ B å¼€å‘æ¨¡å‹çš„è¿‡ç¨‹ä¸­ã€‚ åœ¨æˆ‘ä»¬è¿™é‡Œï¼Œå°±æ˜¯åœ¨è®­ç»ƒå¥½ImageNetæ•°æ®é›†çš„ç¥ç»ç½‘ç»œçš„åŸºç¡€ä¸Šï¼Œæå–å…¶ä¸­è®­ç»ƒå¥½çš„ç½‘ç»œå‚æ•°ï¼ŒåŠ è½½åˆ°è¦è®­ç»ƒå®å¯æ¢¦æ•°æ®é›†çš„ç½‘ç»œä¸­ï¼Œç„¶åå†å¯¹å®å¯æ¢¦æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚ è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨çš„æ˜¯torchvisionä¸­æä¾›å¥½çš„resnet18æ¨¡å‹ 1from torchvision.models import resnet18 æ­¤ResNet18æ˜¯å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ æˆ‘ä»¬è¦åšçš„å°±æ˜¯å°†å…¶å‰17å±‚æ‹†ä¸‹æ¥ï¼Œç„¶åæœ€åä¸€å±‚æ¥ä¸€å±‚æˆ‘ä»¬è‡ªå·±çš„å…¨è¿æ¥å±‚è¿›è¡Œåˆ†ç±»ã€‚ ä½¿ç”¨children()æ–¹æ³•æ‹†ä¸‹ç½‘ç»œçš„å‰17å±‚ç„¶åä¼ å…¥åˆ°æˆ‘ä»¬è‡ªå·±çš„modelä¸­å»ï¼Œç„¶åå†æ¥Flattenæ“ä½œï¼Œç„¶åæ¥å…¨è¿æ¥å±‚ã€‚ ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼šï¼ˆåªéœ€è¦åœ¨åˆå§‹åŒ–æ¨¡å‹é‚£é‡Œæ”¹å˜ä¸€ç‚¹å³å¯ï¼Œè¿™é‡Œå°±ä¸è´´ä»£ç æ±‡æ€»äº†ï¼‰ 12345trained_model = resnet18(pretrained=True)model = nn.Sequential(*list(trained_model.children())[:-1], #[b, 512, 1, 1] Flatten(), # [b, 512, 1, 1] =&gt; [b, 512] nn.Linear(512, 5) ).to(device) Flattenå±‚ä»£ç ï¼š 12345678class Flatten(nn.Module): def __init__(self): super(Flatten, self).__init__() def forward(self, x): shape = torch.prod(torch.tensor(x.shape[1:])).item() return x.view(-1, shape) ç»“æœ æœ€ç»ˆï¼Œtrain lossåœ¨åŒä¸€æ°´å¹³ä¸‹ï¼ŒéªŒè¯é›†çš„å‡†ç¡®ç‡æé«˜äº†10%å·¦å³ï¼Œä½¿ç”¨è¿ç§»å­¦ä¹ çš„æ•ˆæœæå‡è¿˜æ˜¯éå¸¸æ˜æ˜¾çš„ã€‚"},{"title":"PyTorchè¿‡æ‹Ÿåˆ","path":"/wiki/PyTorch/PyTorchè¿‡æ‹Ÿåˆ.html","content":"è¿‡æ‹Ÿåˆä¸æ¬ æ‹Ÿåˆ æ¬ æ‹Ÿåˆ è®­ç»ƒæ—¶çš„å‡†ç¡®ç‡ä½ï¼ˆtrain acc. is badï¼‰ æµ‹è¯•æ—¶çš„å‡†ç¡®ç‡ä¹Ÿå¾ˆä½ï¼ˆtest acc. is bad as wellï¼‰ è¿‡æ‹Ÿåˆ ç›¸æ¯”äºæ¬ æ‹Ÿåˆçš„çŠ¶æ€ï¼Œè®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°å’Œå‡†ç¡®ç‡è¦å¥½å¾—å¤šï¼ˆtrain loss and acc. is much betterï¼‰ æµ‹è¯•æ—¶çš„å‡†ç¡®ç‡è¦ä½ä¸€äº›(test acc. is worse) æ³›åŒ–èƒ½åŠ›è¾ƒå·®ï¼ˆgeneralization performance is worseï¼‰ Train-Val-Teståˆ’åˆ† ä½¿ç”¨å¦‚Train-Val-Teståˆ’åˆ†æ¥æ£€æµ‹æ˜¯å¦å­˜åœ¨è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆçš„æƒ…å†µã€‚ Trainï¼šç”¨æ¥è®­ç»ƒç½‘ç»œValï¼šç”¨æ¥æŒ‘é€‰æ¨¡å‹å‚æ•°ï¼Œç”¨äºç›‘è§†è®­ç»ƒï¼ˆå‡ è½®è®­ç»ƒåè·‘ä¸€è½®Valï¼‰ï¼Œå‘ç°è¿‡æ‹Ÿåˆæ—¶å¯ä»¥æå‰åœæ­¢è®­ç»ƒæ¨¡å‹ Testï¼šéªŒè¯æ¨¡å‹æœ€ç»ˆçš„æ€§èƒ½ï¼ˆç»™å®¢æˆ·çœ‹ï¼‰ï¼Œä¸€èˆ¬å®é™…æƒ…å†µä¸‹è¿™ä¸€éƒ¨åˆ†çš„æ•°æ®å®¢æˆ·ä¸ä¼šæä¾› PyTorchåˆ’åˆ†Train-Valæ•°æ®é›†ä»£ç å¦‚ä¸‹ï¼š 1234567891011print(&#x27;train:&#x27;,len(train_db),&#x27;test:&#x27;,len(test_db))train_db,val_db=torch.utils.data.random_split(train_db,[50000,10000])print(&#x27;db1:&#x27;,len(train_db),&#x27;db2:&#x27;,len(val_db))train_loader=torch.utils.data.DataLoader( train_db, batch_size=batch_size,shuffle=True)val_loader=torch.utils.data.DataLoader( val_db, batch_size=batch_size,shuffle=True) kæŠ˜äº¤å‰éªŒè¯ï¼ˆk-fold cross validationï¼‰ K-foldäº¤å‰éªŒè¯æ˜¯ä¸€ç§æ•°æ®æ‹†åˆ†æŠ€æœ¯ï¼Œè¢«å®šä¹‰ä¸ºä¸€ç§ç”¨äºåœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šä¼°è®¡æ¨¡å‹æ€§èƒ½çš„æ–¹æ³•ã€‚ä½ å¯ä»¥ä½¿ç”¨k&gt;1æŠ˜æ¥å®ç°ç”¨äºä¸åŒç›®çš„çš„æ ·æœ¬åˆ’åˆ†ï¼Œä¹Ÿæ˜¯ä¸€ç§ç”¨äºè¶…å‚æ•°ä¼˜åŒ–çš„æŠ€æœ¯ï¼Œä»¥ä¾¿å¯ä»¥è®­ç»ƒå…·æœ‰æœ€ä¼˜è¶…å‚æ•°å€¼çš„æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ç§æ— éœ€å¢æ·»æˆ–è€…ä¿®æ”¹æ ·æœ¬çš„é‡é‡‡æ ·æŠ€æœ¯ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯ï¼Œæ¯ä¸ªæ ·æœ¬æ¡ˆä¾‹ä»…ç”¨äºè®­ç»ƒå’ŒéªŒè¯ï¼ˆä½œä¸ºæµ‹è¯•æŠ˜çš„ä¸€éƒ¨åˆ†ï¼‰ä¸€æ¬¡ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥å¾ˆå¥½é™ä½æ¨¡å‹æ€§èƒ½çš„æ–¹å·®ã€‚ K-foldäº¤å‰éªŒè¯çš„è¿‡ç¨‹åˆ†ä¸ºä¸‹é¢å‡ æ­¥ï¼š æŠŠæ•°æ®é›†åˆ†ä¸ºè®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ã€‚ ç„¶åå°†è®­ç»ƒæ•°æ®é›†æ‹†åˆ†ä¸ºKä»½ï¼›åœ¨K-foldsæ ·æœ¬ä¸­ï¼Œï¼ˆK-1ï¼‰ä»½ç”¨äºè®­ç»ƒï¼Œ1ä»½ç”¨äºéªŒè¯ï¼ŒæŠŠæ¯æ¬¡æ¨¡å‹çš„æ€§èƒ½è®°å½•ä¸‹æ¥ã€‚ é‡å¤ç¬¬2æ­¥ï¼Œç›´åˆ°æ¯ä¸ªk-fold éƒ½ç”¨åˆ°äº†éªŒè¯ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒè¢«ç§°ä¸ºk-foldäº¤å‰éªŒè¯ï¼‰ã€‚ é€šè¿‡è·å–æ­¥éª¤2ä¸­ä¸ºæ‰€æœ‰Kä¸ªæ¨¡å‹è®¡ç®—çš„æ¨¡å‹åˆ†æ•°æ¥è®¡ç®—æ¨¡å‹æ€§èƒ½çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚ å¯¹ä¸åŒçš„è¶…å‚æ•°å€¼é‡å¤æ­¥éª¤2åˆ°æ­¥éª¤5ã€‚ æœ€åé€‰æ‹©äº§ç”Ÿæœ€ä¼˜åˆ†æ•°å‡å€¼å’Œæ ‡å‡†å€¼çš„æ¨¡å‹è¶…å‚æ•°ã€‚ åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè®¡ç®—è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚ æ±‡æ€» ä»ç„¶æ˜¯é’ˆå¯¹MINSTæ•°æ®é›†ï¼ŒåŸºäºå‰é¢ä¼˜åŒ–çš„åŸºç¡€ä¸Šä½†æ˜¯åˆ’åˆ†æˆä¸ºäº†ä¸‰ä¸ªæ•°æ®é›†çš„ä»£ç ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformsbatch_size=200learning_rate=0.01epochs=10train_db = datasets.MNIST(&#x27;../data&#x27;, train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ]))train_loader = torch.utils.data.DataLoader( train_db, batch_size=batch_size, shuffle=True)test_db = datasets.MNIST(&#x27;../data&#x27;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]))test_loader = torch.utils.data.DataLoader(test_db, batch_size=batch_size, shuffle=True)print(&#x27;train:&#x27;, len(train_db), &#x27;test:&#x27;, len(test_db))train_db, val_db = torch.utils.data.random_split(train_db, [50000, 10000])print(&#x27;db1:&#x27;, len(train_db), &#x27;db2:&#x27;, len(val_db))train_loader = torch.utils.data.DataLoader( train_db, batch_size=batch_size, shuffle=True)val_loader = torch.utils.data.DataLoader( val_db, batch_size=batch_size, shuffle=True)class MLP(nn.Module): def __init__(self): super(MLP, self).__init__() self.model = nn.Sequential( nn.Linear(784, 200), nn.LeakyReLU(inplace=True), nn.Linear(200, 200), nn.LeakyReLU(inplace=True), nn.Linear(200, 10), nn.LeakyReLU(inplace=True), ) def forward(self, x): x = self.model(x) return xdevice = torch.device(&#x27;cuda:0&#x27;)net = MLP().to(device)optimizer = optim.SGD(net.parameters(), lr=learning_rate)criteon = nn.CrossEntropyLoss().to(device)# Trainéƒ¨åˆ†for epoch in range(epochs): for batch_idx, (data, target) in enumerate(train_loader): data = data.view(-1, 28*28) data, target = data.to(device), target.cuda() logits = net(data) loss = criteon(logits, target) optimizer.zero_grad() loss.backward() # print(w1.grad.norm(), w2.grad.norm()) optimizer.step() if batch_idx % 100 == 0: print(&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#x27;.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\t# ValéªŒè¯éƒ¨åˆ† test_loss = 0 correct = 0 for data, target in val_loader: data = data.view(-1, 28 * 28) data, target = data.to(device), target.cuda() logits = net(data) test_loss += criteon(logits, target).item() pred = logits.data.max(1)[1] correct += pred.eq(target.data).sum() test_loss /= len(val_loader.dataset) print(&#x27; VAL set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) &#x27;.format( test_loss, correct, len(val_loader.dataset), 100. * correct / len(val_loader.dataset)))# testæµ‹è¯•éƒ¨åˆ†test_loss = 0correct = 0for data, target in test_loader: data = data.view(-1, 28 * 28) data, target = data.to(device), target.cuda() logits = net(data) test_loss += criteon(logits, target).item() pred = logits.data.max(1)[1] correct += pred.eq(target.data).sum()test_loss /= len(test_loader.dataset)print(&#x27; Test set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%) &#x27;.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) å‡å°‘è¿‡æ‹Ÿåˆçš„æ–¹æ³• æ›´å¤šçš„æ•°æ®ï¼ˆMore Dataï¼‰ å‡å°‘æ¨¡å‹çš„å¤æ‚ç¨‹åº¦ï¼ˆConstraint model complexityï¼‰ æ›´æµ…çš„ç½‘ç»œ æ­£åˆ™åŒ– Dropout æ•°æ®å¢å¼ºï¼ˆData aargumentationï¼‰ Early stoppingï¼ˆå‰é¢è¿›è¡Œè®²è§£è¿‡ï¼‰ æ­£åˆ™åŒ–ï¼ˆRegularizationï¼‰ ä½ å¯èƒ½ç†Ÿæ‚‰å¥¥å¡å§†å‰ƒåˆ€åŸåˆ™ï¼šç»™å‡ºä¸¤ä¸ªè§£é‡Šï¼Œæœ€å¯èƒ½æ­£ç¡®çš„è§£é‡Šæ˜¯æ›´ç®€å•çš„ä¸€ä¸ª â€“ å‡è®¾è¾ƒå°‘çš„è§£é‡Šã€‚ è¿™ä¸ªåŸåˆ™ä¹Ÿé€‚ç”¨äºç¥ç»ç½‘ç»œçš„æ¨¡å‹ï¼š ç®€å•çš„æ¨¡å‹æ¯”å¤æ‚çš„æ³›åŒ–èƒ½åŠ›å¥½ã€‚ æ­£åˆ™åŒ–ï¼Œå³åœ¨æˆæœ¬å‡½æ•°ä¸­åŠ å…¥ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹(æƒ©ç½šé¡¹)ï¼Œæƒ©ç½šæ¨¡å‹çš„å¤æ‚åº¦ï¼Œé˜²æ­¢ç½‘ç»œè¿‡æ‹Ÿåˆã€‚ ä»¥Logistic Regressionçš„äº¤å‰ç†µæŸå¤±å‡½æ•°ä¸ºä¾‹ã€‚ J(Î¸)=âˆ’1mâˆ‘i=1m[yilny^i+(1âˆ’yi)ln(1âˆ’y^i)]J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}[y_i ln\\hat{y}_i+(1-y_i)ln(1-\\hat{y}_i)] J(Î¸)=âˆ’m1â€‹i=1âˆ‘mâ€‹[yiâ€‹lny^â€‹iâ€‹+(1âˆ’yiâ€‹)ln(1âˆ’y^â€‹iâ€‹)] æˆ‘ä»¬åŠ å…¥å¯¹å‚æ•°çš„æƒ©ç½šé¡¹ J(Î¸)=âˆ’1mâˆ‘i=1m[yilny^i+(1âˆ’yi)ln(1âˆ’y^i)]+Î»âˆ‘i=1nâˆ£Î¸iâˆ£J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}[y_i ln\\hat{y}_i+(1-y_i)ln(1-\\hat{y}_i)]+\\lambda\\sum_{i=1}^n|\\theta_i| J(Î¸)=âˆ’m1â€‹i=1âˆ‘mâ€‹[yiâ€‹lny^â€‹iâ€‹+(1âˆ’yiâ€‹)ln(1âˆ’y^â€‹iâ€‹)]+Î»i=1âˆ‘nâ€‹âˆ£Î¸iâ€‹âˆ£ å½“ç„¶ä¹Ÿå¯ä»¥åŠ L2èŒƒæ•°çš„æƒ©ç½šé¡¹(åœ¨PyTorchä¸­æœ€å¸¸ç”¨) J(Î¸)=âˆ’1mâˆ‘i=1m[yilny^i+(1âˆ’yi)ln(1âˆ’y^i)]+12Î»âˆ‘i=1nâˆ£âˆ£Î¸iâˆ£âˆ£2J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}[y_i ln\\hat{y}_i+(1-y_i)ln(1-\\hat{y}_i)]+\\frac{1}{2}\\lambda\\sum_{i=1}^n||\\theta_i||^2 J(Î¸)=âˆ’m1â€‹i=1âˆ‘mâ€‹[yiâ€‹lny^â€‹iâ€‹+(1âˆ’yiâ€‹)ln(1âˆ’y^â€‹iâ€‹)]+21â€‹Î»i=1âˆ‘nâ€‹âˆ£âˆ£Î¸iâ€‹âˆ£âˆ£2 è¿™æ ·é€šè¿‡è°ƒæ•´åˆé€‚çš„Î»\\lambdaÎ»å‚æ•°å°±å¯ä»¥æœ‰æ•ˆçš„æŠ‘åˆ¶æ¨¡å‹é«˜é˜¶å‚æ•°ã€‚ æ­£åˆ™åŒ–åœ¨PyTorchä¸­åˆå«åš`WeightDecay` åœ¨PyTorchä¸­åšL2-regularization 1234device=torch.device(&#x27;cuda:0&#x27;)net=MLP().to(device)optimizer=optim.SGD(net.parameters(),lr=learning_rate,weight_decay=0.01)#è¿™é‡ŒåŠ ä¸€ä¸ªweight_decayå‚æ•°å°±å¥½äº†criteon=nn.CrossEntropyLoss().to(device) åœ¨PyTorchä¸­åšL1-regularization å› ä¸ºPyTorchä¸æä¾›ç›¸åº”çš„APIï¼Œæ‰€ä»¥L1-regularizationéœ€è¦è‡ªå·±å®ç°. 12345678910regularization_loss=0for param in model.parameters(): regularization_loss+=torch.sum(torch.abs(param))classify_loss=criteon(logits,target)loss=classify_loss+0.01*regularization_lossoptimizer.zero_grad()loss.backward()optimizer.step() ä¸€èˆ¬æ˜¯å‡ºç°äº†overfittingçš„æƒ…å†µåæ‰ä¼šè®¾ç½®weight_decay åŠ¨é‡ä¸å­¦ä¹ ç‡è¡°å‡ åŠ¨é‡ï¼ˆmomentumï¼‰ å­¦ä¹ ç‡è¡°å‡ï¼ˆlearningrate decayï¼‰ åŠ¨é‡ï¼ˆmomentumï¼‰ åŸæ¥çš„æ›´æ–°å‡½æ•° wk+1=wkâˆ’Î±âˆ‡f(wk)w^{k+1}=w^k-\\alpha abla f(w^k) wk+1=wkâˆ’Î±âˆ‡f(wk) åŠ äº†åŠ¨é‡ä»¥åçš„æ›´æ–°å‡½æ•° wk+1=wkâˆ’Î±zk+1w^{k+1}=w^k-\\alpha z^{k+1} wk+1=wkâˆ’Î±zk+1 zk+1=Î²zk+âˆ‡f(wk)z^{k+1}=\\beta z^k+ abla f(w^k) zk+1=Î²zk+âˆ‡f(wk) zkz^kzkåœ¨è¿™é‡Œä»£è¡¨ä¸Šä¸€æ¬¡æ¢¯åº¦çš„æ–¹å‘ï¼Œæ‰€ä»¥æ¯æ¬¡çš„æ›´æ–°ä¸ä»…å–å†³äºè¿™ä¸€æ¬¡æ¢¯åº¦çš„æ–¹å‘è¿˜è¦å–å†³äºä¸Šä¸€æ¬¡æ¢¯åº¦çš„æ–¹å‘ã€‚å¯ä»¥å‘ç°åŠ¨é‡å…¶å®å°±æ˜¯æŒ‡æ•°åŠ æƒå¹³å‡ã€‚ å¯ä»¥å‘ç°ç›¸æ¯”æœªæ·»åŠ åŠ¨é‡ï¼Œæœ‰åŠ¨é‡çš„è®­ç»ƒæ›´æ–°çš„æ—¶å€™æ–¹å‘å˜åŒ–æ²¡æœ‰é‚£ä¹ˆå°–é”å’Œå‰§çƒˆäº†ï¼Œæœªæ·»åŠ åŠ¨é‡çš„è®­ç»ƒæœ€ç»ˆæ— æ³•æ”¶æ•›åˆ°æœ€ä¼˜è§£ï¼Œä½†æ˜¯æ·»åŠ äº†åŠ¨é‡çš„è®­ç»ƒï¼Œæœ€ç»ˆå¯ä»¥å‡­å€Ÿæƒ¯æ€§å¾—åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚ PyTorchå¯¹momentumçš„æ”¯æŒ 123456789optimizer=torch.optim.SGD(model.parameters(),args.lr, momentum=args.momentum,# è¿™é‡Œæ·»åŠ ä¸€ä¸ªåŠ¨é‡å‚æ•°å°±å¯ä»¥äº† weight_decay=args.weight_decay)scheduler=ReduceLROnPlateau(optimizer,&#x27;min&#x27;)for epoch in xrange(args.start_epoch,args.epochs): train(train_loader,model,criterion,optimizer,epoch) reult_avg,loss_val=validate(val_loader,model,criterion,epoch) scheduler.step(loss_val) å­¦ä¹ ç‡è¡°å‡ï¼ˆlearningrate decayï¼‰ å­¦ä¹ ç‡è¡°å‡ä¸€èˆ¬æœ‰ä¸¤ç§è¡°å‡ç­–ç•¥ ä¸€ç§æ˜¯å½“æŸå¤±å‡½æ•°ç¢°åˆ°å¹³åŸçš„æ—¶å€™è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ï¼Œä½¿ç”¨PyTorchä¸­çš„å‡½æ•°æ˜¯ReduceLROnPlateau 123456789optimizer=torch.optim.SGD(model.parameters(),args.lr, momentum=args.momentum,# è¿™é‡Œæ·»åŠ ä¸€ä¸ªåŠ¨é‡å‚æ•°å°±å¯ä»¥äº† weight_decay=args.weight_decay)scheduler=ReduceLROnPlateau(optimizer,&#x27;min&#x27;)for epoch in xrange(args.start_epoch,args.epochs): train(train_loader,model,criterion,optimizer,epoch) reult_avg,loss_val=validate(val_loader,model,criterion,epoch) scheduler.step(loss_val) è¿˜æœ‰ä¸€ç§æ¯”è¾ƒç®€å•ç²—æš´ï¼Œå°±æ˜¯æ¯è¿‡å¤šå°‘æ­¥ç„¶åæŠŠlearning_rateè¿›è¡Œè¡°å‡ã€‚PyTorchä¸­ä½¿ç”¨çš„å‡½æ•°æ˜¯StepLR 123456789# Assuming optimizer uses lr = 0.05 for all groups# lr = 0.05 if epoch &lt; 30# lr = 0.005 if 30 &lt;= epoch &lt; 60# lr = 0.0005 if 60 &lt;= epoch &lt; 90schedular =StepLR(optimizer,steo_size=30,gamma=0.1)for epoch in range(100): scheduler.step() train(...) validate(...) StepLRä¸­çš„å‚æ•°è¡¨ç¤ºçš„å°±æ˜¯æ¯æ­¥è¿›30æ­¥ï¼Œlrå‡å°‘ä¸ºåŸæ¥çš„0.1ï¼Œè¯¦æƒ…å¯ä»¥è§ä¸Šé¢çš„ä»£ç æ³¨é‡Šã€‚ Early Stop&amp;Dropout Early Stop å› ä¸ºæœ‰æ—¶è®­ç»ƒè½®æ•°è¿‡å¤šä¼šå‡ºç°è¿‡æ‹Ÿåˆçš„æƒ…å†µä»è€Œè®©æ¨¡å‹æ€§èƒ½å˜åï¼Œæ‰€ä»¥åœ¨å¿…è¦çš„æ—¶å€™æˆ‘ä»¬è¦å…ˆåœæ­¢è®­ç»ƒæ¨¡å‹ï¼ˆvalå–æœ€å¤§å€¼æ—¶ï¼‰ï¼Œä¿å­˜å‚æ•°ï¼Œé¿å…ç»§ç»­è®­ç»ƒå‡ºç°è¿‡æ‹Ÿåˆçš„æƒ…å†µã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„Early Stop æ­¥éª¤ Valæ•°æ®é›†ç”¨æ¥é€‰æ‹©å‚æ•°ï¼ˆè¶…å‚æ•°ï¼‰ è§‚å¯ŸéªŒè¯é›†çš„è¡¨ç° åœ¨ValéªŒè¯é›†Accæœ€é«˜ï¼ˆæˆ–Lossæœ€ä½ï¼‰å¤„åœæ­¢è®­ç»ƒï¼ˆæ ¹æ®ç»éªŒï¼Œè¿ç»­ä¸‹æ»‘ä¸€æ®µæ—¶é—´åæˆ‘ä»¬å°±è®¤ä¸ºå‰é¢çš„æœ€é«˜ç‚¹å°±æ˜¯æœ€å¥½çš„ï¼‰ Dropout æ€æƒ³ å­¦çš„æ›´å°‘æ¥å­¦çš„æ›´å¥½ æ¯ä¸ªè¿æ¥éƒ½æœ‰pçš„æ¦‚ç‡è¢«æ–­å¼€ ä»£ç å®ç° PyTorchä¸­æ·»åŠ Dropoutè¿˜æ˜¯æ¯”è¾ƒæ–¹ä¾¿çš„ 123456789net_dropped=torch.nn.Sequential( torch.nn.Linear(784,200), torch.nn.Dropout(0.5), torch.nn.ReLU(), torch.nn.Linear(200,200), torch.nn.Dropout(0.5), torch.nn.ReLU(), torch.nn.Linear(200,10),) å±‚ä¹‹é—´æ˜¯ç›´è¿çš„ï¼Œè¿™é‡Œçš„æ„æ€æ˜¯åœ¨å±‚ä¹‹é—´æœ‰50%çš„æ¦‚ç‡å‡ºç°è¿æ¥æ–­æ‰ã€‚å’Œä¸Šé¢ç”»çš„ç¤ºæ„å›¾æœ‰ä¸€ç‚¹ä¸ä¸€æ ·ã€‚ æ³¨æ„ï¼šdropoutåªåœ¨è®­ç»ƒçš„æ—¶å€™æ‰æœ‰ï¼Œæµ‹è¯•çš„æ—¶å€™æ˜¯ä¸ä¼šdropoutçš„ã€‚ æ•°æ®å¢å¼º è§PyTorch CNN,å› ä¸ºè®²è§£äº†å·ç§¯ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«æ–¹é¢çš„åº”ç”¨åï¼Œå¯èƒ½ä¼šå¯¹è¿™ä¸€æ–¹é¢å°è±¡æ›´åŠ æ·±åˆ»ä¸€äº›ã€‚ SGD SGDå…¨ç§°Stochastic Gradient Descentï¼Œä¸­æ–‡å…¨ç§°å«éšæœºæ¢¯åº¦ä¸‹é™ã€‚ä¸ºäº†è§£å†³æ•°æ®é›†è¿‡å¤§æ— æ³•å°†æ‰€æœ‰æ ·æœ¬æ”¾å…¥è¿›è¡Œæ¢¯åº¦ä¸‹é™ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åŒ–æˆè‹¥å¹²ä¸ªBatchï¼Œä¸€ä¸ªBatchä¸­åŒ…å«è‹¥å¹²ä¸ªæ ·æœ¬ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸€ä¸ªBatchè¿›è¡Œä¸€æ¬¡æ¢¯åº¦ä¸‹é™ï¼ˆæ³¨æ„æ˜¯ä¸€ä¸ªBatchè€Œä¸æ˜¯æ¯æ¬¡å–ä¸€ä¸ªæ ·æœ¬å°±ä¸‹é™ä¸€æ¬¡ï¼‰ å…¶å®ä»¥ä¸Šè¿™ä¸ªåº”è¯¥å«åšå°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼Œè€Œå¹¶éSGDï¼ŒSGDæ˜¯Batchsize=1çš„å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ã€‚ è¿™é‡Œæ¨èä¸€ç¯‡è®²è§£ä¸åŒæ¢¯åº¦ä¸‹é™çš„åšå®¢ï¼šæœºå™¨å­¦ä¹ ï¼šé¢å¯¹æµ·é‡æ•°æ®å¦‚ä½•è¿›è¡Œæœºå™¨å­¦ä¹ "},{"title":"stringstream","path":"/wiki/C++/sstream/stringstream.html","content":"stringstream æ˜¯ C++ æ ‡å‡†åº“ä¸­çš„ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ç±»ï¼Œå®ƒå±äº &lt;sstream&gt; å¤´æ–‡ä»¶ã€‚è¿™ä¸ªç±»å…è®¸ä½ æŠŠå­—ç¬¦ä¸²å½“ä½œæµæ¥å¤„ç†ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥ä½¿ç”¨ç±»ä¼¼äºå¤„ç†æ–‡ä»¶æµï¼ˆå¦‚ ifstream å’Œ ofstreamï¼‰çš„æ–¹å¼æ¥å¤„ç†å­—ç¬¦ä¸²ã€‚ åŸºæœ¬ç”¨æ³• å®šä¹‰ï¼šä½ å¯ä»¥é€šè¿‡åŒ…å«å¤´æ–‡ä»¶ &lt;sstream&gt; æ¥ä½¿ç”¨ stringstream ç±»ã€‚std::stringstream å¯ç”¨äºè¯»å†™å­—ç¬¦ä¸²ã€‚ åˆå§‹åŒ–ï¼šä½ å¯ä»¥ç›´æ¥åˆå§‹åŒ–ä¸€ä¸ª stringstream å¯¹è±¡ï¼Œä¹Ÿå¯ä»¥ç”¨ä¸€ä¸ªå­—ç¬¦ä¸²åˆå§‹åŒ–å®ƒã€‚ è¯»å†™æ“ä½œï¼šä½¿ç”¨ &lt;&lt; æ“ä½œç¬¦å‘ stringstream å†™å…¥æ•°æ®ï¼Œä½¿ç”¨ &gt;&gt; æ“ä½œç¬¦ä»ä¸­è¯»å–æ•°æ®ã€‚ è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼šä½¿ç”¨ str() æˆå‘˜å‡½æ•°å¯ä»¥è·å–æˆ–è®¾ç½® stringstream çš„å†…å®¹ã€‚ æ¸…ç©ºï¼šä½¿ç”¨ str(&quot;&quot;) å¯ä»¥æ¸…ç©º stringstream çš„å†…å®¹ï¼Œä½¿ç”¨ clear() å¯ä»¥é‡ç½®å®ƒçš„çŠ¶æ€ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ çµæ´»æ€§ï¼šstringstream éå¸¸é€‚åˆåšç±»å‹è½¬æ¢å’Œå­—ç¬¦ä¸²æ‹¼æ¥ã€‚ æ€§èƒ½ï¼šä¸ç›´æ¥æ“ä½œå­—ç¬¦ä¸²ç›¸æ¯”ï¼Œä½¿ç”¨ stringstream å¯èƒ½ä¼šæœ‰ä¸€äº›æ€§èƒ½æŸå¤±ï¼Œå°¤å…¶æ˜¯åœ¨å¤§é‡æ•°æ®æ“ä½œæ—¶ã€‚ çŠ¶æ€ç®¡ç†ï¼šåœ¨ä» stringstream è¯»å–æ•°æ®åï¼Œåº”æ£€æŸ¥æµçš„çŠ¶æ€ï¼ˆå¦‚æ˜¯å¦åˆ°è¾¾æœ«å°¾ï¼‰ã€‚ å†…å­˜ç®¡ç†ï¼šstringstream è‡ªåŠ¨ç®¡ç†å†…éƒ¨çš„å­—ç¬¦ä¸²ç¼“å†²åŒºï¼Œæ— éœ€æ‰‹åŠ¨é‡Šæ”¾å†…å­˜ã€‚ ç¤ºä¾‹ä»£ç  12345678910111213141516171819#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;string&gt;int main() &#123; std::stringstream ss; ss &lt;&lt; &quot;Example &quot;; // å†™å…¥å­—ç¬¦ä¸² ss &lt;&lt; 2024; // å†™å…¥æ•°å­— std::string str = ss.str(); // å°† stringstream è½¬æ¢ä¸º string std::cout &lt;&lt; str &lt;&lt; std::endl; // è¾“å‡º &quot;Example 2024&quot; int num; ss.str(&quot;1234&quot;); // è®¾ç½®æ–°çš„å­—ç¬¦ä¸²å†…å®¹ ss &gt;&gt; num; // ä» stringstream è¯»å–æ•°å­— std::cout &lt;&lt; num &lt;&lt; std::endl; // è¾“å‡º 1234 return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ stringstream æ¥è¿›è¡ŒåŸºæœ¬çš„å†™å…¥ã€è¯»å–å’Œç±»å‹è½¬æ¢æ“ä½œã€‚"},{"title":"PyTorchåŸºç¡€","path":"/wiki/PyTorch/PyTorchåŸºç¡€.html","content":"Tensoræ•°æ®ç±»å‹ å¯¹æ¯” Python PyTorch Int IntTensor of size() float FloatTensor of size() Int array IntTensor of size [d1,d2,â€¦] Float array FloatTensor of size[d1,d2,â€¦] string â€“ å¯ä»¥å‘ç°PyTorchå¹¶ä¸æ”¯æŒstringè¡¨ç¤ºï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä¸¤ç§æ–¹æ³•åœ¨PyTorch ä¸­è¡¨ç¤ºstringã€‚ One-hot Embedding Word2vec glove è¿™é‡Œä¸å¯¹ä»¥ä¸Šä¸¤ç§æ–¹æ³•å±•å¼€è¿›è¡Œè®²è§£ï¼Œå¤§å®¶æ„Ÿå…´è¶£å¯ä»¥è‡ªè¡Œç™¾åº¦ã€‚ æ•°æ®ç±»å‹ æœ€å¸¸ç”¨çš„ä¸€èˆ¬æ˜¯ä»¥ä¸‹å‡ ç§ FloatTensor DoubleTensor IntTensor LongTensor ByteTensor æ•°æ®ç±»å‹æ¨æ–­ 123456In [3]: a=torch.randn(2,3)In [4]: a.type()Out[4]: &#x27;torch.FloatTensor&#x27;In [5]: type(a)Out[5]: torch.Tensor type()ï¼šæ‰“å‡ºå½“å‰tensorçš„æ•°æ®ç±»å‹ isinstance()ï¼šæ£€éªŒå½“å‰æ•°æ®æ˜¯å¦ä¸ºæ­¤ç±»å‹ type(xxx)ï¼šPythonè‡ªå¸¦çš„ç±»å‹æ£€æµ‹ï¼Œåªèƒ½æ£€æµ‹æœ€åŸºæœ¬æ•°æ®ç±»å‹ ä»¥ä¸‹ä»£ç æµ‹è¯•è¯´æ˜äº†ï¼ŒåŒä¸€æ•°æ®éƒ¨ç½²åœ¨CPUå’ŒGPUä¸Šæ•°æ®ç±»å‹æ˜¯ä¸ä¸€æ ·çš„ 12345In [7]: isinstance(a,torch.cuda.FloatTensor)Out[7]: FalseIn [8]: a=a.cuda()In [9]: isinstance(a,torch.cuda.FloatTensor)Out[9]: True æ ‡é‡çš„è¡¨ç¤º: Dim0 1234In [10]: torch.tensor(1.0)Out[10]: tensor(1.)In [11]: torch.tensor(1.3)Out[11]: tensor(1.3000) ä»¥ä¸‹ä»£ç å±•ç¤ºäº†shape,size(),dim()çš„ä½¿ç”¨æ–¹æ³•ã€‚ å…¶ä¸­è¾“å…¥19å’Œ21æ˜¯å¸¸è§çš„ç¡®å®štensorç»´åº¦çš„æ–¹æ³• 123456789In [17]: a=torch.tensor(1.3)In [18]: a.shapeOut[18]: torch.Size([])In [19]: len(a.shape)Out[19]: 0In [20]: a.size()Out[20]: torch.Size([])In [21]: a.dim()Out[21]: 0 å‘é‡Vectorï¼šDim1 ä¸€ä¸ªå…ƒç´ çš„ä¸€ç»´å‘é‡ï¼Œå…¶å®å°±æ˜¯å¤šåŠ äº†ä¸€ä¸ªä¸­æ‹¬å·ï¼Œè¯¦æƒ…è§ä¸‹é¢çš„ä»£ç ã€‚ FloatTensoræ¥æ”¶çš„å‚æ•°æ˜¯shapeï¼Œç„¶åéšæœºåˆå§‹åŒ–å‘é‡ã€‚ ç„¶åIn [9]ä»¥åä»‹ç»äº†ä¸€ç§numpyè½¬tensorçš„æ–¹æ³• 123456789101112131415161718In [3]: torch.tensor([1.1])Out[3]: tensor([1.1000])In [4]: a=torch.tensor([1.1])In [5]: a.dim()Out[5]: 1In [6]: torch.tensor([1.1,2.2])Out[6]: tensor([1.1000, 2.2000])In [7]: torch.FloatTensor(1)Out[7]: tensor([0.])In [8]: torch.FloatTensor(2)Out[8]: tensor([0., 0.])In [9]: import numpy as npIn [10]: data=np.ones(2)In [11]: dataOut[11]: array([1., 1.])In [12]: torch.from_numpy(data)Out[12]: tensor([1., 1.], dtype=torch.float64) çŸ©é˜µMatrixï¼šDim2 1234567891011121314In [3]: a=torch.randn(2,3)In [4]: aOut[4]: tensor([[-0.6969, 1.8345, -0.4894], [-0.0066, -0.0398, -0.6140]])In [5]: a.shapeOut[5]: torch.Size([2, 3])In [6]: a.size(0)Out[6]: 2In [7]: a.size(1)Out[7]: 3In [8]: a.shape[1]Out[8]: 3 åœ¨PyTorchä¸­ï¼Œrandnæ˜¯éšæœºæ­£æ€åˆ†å¸ƒï¼Œè€Œrandæ˜¯éšæœºå‡åŒ€åˆ†å¸ƒã€‚ Dim3 12345678910111213141516171819In [3]: a=torch.rand(1,2,3)In [4]: aOut[4]: tensor([[[0.7603, 0.4443, 0.4788], [0.0602, 0.6325, 0.8426]]])In [5]: a.shapeOut[5]: torch.Size([1, 2, 3])In [6]: a[0]Out[6]: tensor([[0.7603, 0.4443, 0.4788], [0.0602, 0.6325, 0.8426]])In [7]: a[0,1]Out[7]: tensor([0.0602, 0.6325, 0.8426])In [8]: a[0,1,0]Out[8]: tensor(0.0602)In [9]: list(a.shape)Out[9]: [1, 2, 3] ä¸‰ç»´çš„tensorä¸€èˆ¬ç”¨äºRNNä¸­ Dim4 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253In [3]: a=torch.rand(2,3,28,28)In [4]: a.dim()Out[4]: 4In [5]: aOut[5]: tensor([[[[0.5255, 0.9019, 0.9471, ..., 0.7050, 0.4455, 0.8681], [0.7229, 0.9215, 0.4863, ..., 0.4863, 0.5061, 0.3511], [0.0015, 0.3703, 0.0695, ..., 0.7927, 0.0028, 0.5953], ..., [0.3896, 0.5274, 0.7822, ..., 0.7864, 0.5558, 0.2190], [0.8072, 0.7983, 0.8963, ..., 0.8586, 0.2881, 0.1836], [0.7002, 0.4452, 0.8168, ..., 0.6467, 0.2885, 0.4928]], [[0.5885, 0.6984, 0.6732, ..., 0.3300, 0.3039, 0.1747], [0.2004, 0.1730, 0.4867, ..., 0.5207, 0.3391, 0.6586], [0.0279, 0.1897, 0.5924, ..., 0.7152, 0.6622, 0.1943], ..., [0.6697, 0.9150, 0.1786, ..., 0.6098, 0.8226, 0.2826], [0.2074, 0.6030, 0.0912, ..., 0.9088, 0.1924, 0.6403], [0.0557, 0.0836, 0.2382, ..., 0.4082, 0.0600, 0.5102]], [[0.3708, 0.5273, 0.0810, ..., 0.8926, 0.5854, 0.7139], [0.6355, 0.3067, 0.9933, ..., 0.7173, 0.0793, 0.3067], [0.9277, 0.6752, 0.7401, ..., 0.6875, 0.4112, 0.9575], ..., [0.2762, 0.6146, 0.9833, ..., 0.2625, 0.9879, 0.1417], [0.1789, 0.9695, 0.6872, ..., 0.2485, 0.0840, 0.4170], [0.5604, 0.1260, 0.8523, ..., 0.6334, 0.1975, 0.5056]]], [[[0.9585, 0.5642, 0.2652, ..., 0.7171, 0.5738, 0.7511], [0.0737, 0.4149, 0.1017, ..., 0.4772, 0.4125, 0.4467], [0.6502, 0.9494, 0.1355, ..., 0.0834, 0.4446, 0.5004], ..., [0.2966, 0.6502, 0.6373, ..., 0.6158, 0.9067, 0.0245], [0.1544, 0.6203, 0.7105, ..., 0.5898, 0.9481, 0.7846], [0.0048, 0.8663, 0.5166, ..., 0.7284, 0.1925, 0.2311]], [[0.0852, 0.0139, 0.8834, ..., 0.6738, 0.1022, 0.8247], [0.0161, 0.2121, 0.9729, ..., 0.2736, 0.3918, 0.5949], [0.1229, 0.8208, 0.6334, ..., 0.0238, 0.5333, 0.0843], ..., [0.9250, 0.3495, 0.2272, ..., 0.2272, 0.7861, 0.1189], [0.7124, 0.8442, 0.6705, ..., 0.7530, 0.0809, 0.4165], [0.5223, 0.0803, 0.3681, ..., 0.3973, 0.7163, 0.1920]], [[0.1807, 0.7834, 0.5945, ..., 0.5394, 0.7165, 0.4785], [0.8470, 0.0618, 0.2278, ..., 0.5901, 0.4242, 0.0087], [0.9244, 0.1387, 0.8042, ..., 0.4879, 0.6511, 0.4556], ..., [0.2453, 0.7729, 0.5773, ..., 0.7876, 0.7998, 0.5125], [0.3097, 0.0141, 0.5490, ..., 0.2160, 0.4402, 0.9370], [0.5274, 0.9141, 0.0378, ..., 0.9517, 0.8165, 0.6193]]]])In [6]: a.shapeOut[6]: torch.Size([2, 3, 28, 28])In [7]: a.numel()Out[7]: 4704 numelå‡½æ•°çš„å«ä¹‰æ˜¯numberof element,è¿”å›å¯¹åº”tensorä¸­å…ƒç´ çš„ä¸ªæ•° å››ç»´çš„tensorä¸€èˆ¬ç”¨äºCNNä¸­ åˆ›å»ºTensor ä»numpyä¸­å¯¼å…¥æ•°æ® 123456789In [4]: a=np.array([2,3.3])In [5]: torch.from_numpy(a)Out[5]: tensor([2.0000, 3.3000], dtype=torch.float64)In [6]: a=np.ones([2,3])In [7]: torch.from_numpy(a)Out[7]: tensor([[1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) ä»Liståˆ—è¡¨ä¸­å¯¼å…¥æ•°æ® 1234567891011121314151617In [3]: torch.tensor([2.,3.2])Out[3]: tensor([2.0000, 3.2000])In [4]: torch.FloatTensor([2.,3.2])Out[4]: tensor([2.0000, 3.2000])In [5]: torch.FloatTensor(2,3)Out[5]: tensor([[0., 0., 0.], [0., 0., 0.]])In [6]: torch.tensor([[2.,3.2],[1.,22.3]])Out[6]: tensor([[ 2.0000, 3.2000], [ 1.0000, 22.3000]])In [7]: torch.Tensor(2,3)Out[7]: tensor([[0., 0., 0.], [0., 0., 0.]]) æ³¨æ„åŒºåˆ†å¤§å†™Tensorå’Œå°å†™tensorï¼Œè§In[3]å’ŒIn [7]çš„åŒºåˆ«ï¼Œç„¶åIn [4]å’ŒIn [5]ä¹Ÿè¦è¿›è¡ŒåŒºåˆ†ã€‚ ç”Ÿæˆæœªç»è¿‡åˆå§‹åŒ–çš„æ•°æ®uninitalized torch.empty() torch.FloatTensor() torch.IntTensor(d1,d2,d3l) 1234567891011121314151617181920212223In [3]: torch.empty(1)Out[3]: tensor([0.])In [4]: torch.empty([2,3])Out[4]: tensor([[0., 0., 0.], [0., 0., 0.]])In [5]: torch.empty(2,3)Out[5]: tensor([[0., 0., 0.], [0., 0., 0.]])In [6]: torch.Tensor(2,3)Out[6]: tensor([[0., 0., 0.], [0., 0., 0.]])In [7]: torch.IntTensor(2,3)Out[7]: tensor([[0, 0, 0], [0, 0, 0]], dtype=torch.int32)In [8]: torch.FloatTensor(2,3)Out[8]: tensor([[0., 0., 0.], [0., 0., 0.]]) éå¸¸ä¸å»ºè®®ç›´æ¥å°†æœªåˆå§‹åŒ–çš„Tensorå¸¦å…¥è®¡ç®—ï¼Œæœ‰æå¤§æ¦‚ç‡å‡ºç°å¥‡æ€ªçš„é—®é¢˜ã€‚è¿™æ˜¯å› ä¸ºæœªç»åˆå§‹åŒ–çš„Tensorï¼Œéšæœºç”Ÿæˆçš„æ•°æ®æœ‰å¯èƒ½ä¼šç›¸å·®è¾ƒå¤§ï¼ˆæ¯”å¦‚æå¤§æˆ–è€…æå°ï¼‰ï¼Œä¸Šé¢çš„ä»£ç å¹¶æ²¡æœ‰å‡ºç°è¿™æ ·çš„é—®é¢˜ï¼Œå¯èƒ½æ˜¯å› ä¸ºè¿æ°”æ¯”è¾ƒå¥½ã€‚ empty()åŠ ä¸åŠ æ‹¬å·éƒ½å¯ä»¥ è®¾ç½®é»˜è®¤æ•°æ®ç±»å‹ PyTorché»˜è®¤çš„Tensorç±»å‹æ˜¯FloatTensorï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½¿ç”¨Tensoræˆ–tensorç”Ÿæˆçš„tensorçš„æ•°æ®ç±»å‹éƒ½æ˜¯FloatTensorç±»å‹çš„ã€‚ è®¾ç½®Tensoré»˜è®¤çš„æ•°æ®ç±»å‹é‡‡ç”¨çš„å‡½æ•°æ˜¯set_default_tensor_type 123456In [3]: torch.tensor([1.2,3]).type()Out[3]: &#x27;torch.FloatTensor&#x27;In [4]: torch.set_default_tensor_type(torch.DoubleTensor)In [5]: torch.tensor([1.2,3]).type()Out[5]: &#x27;torch.DoubleTensor&#x27; éšæœºåˆå§‹åŒ– rand():éšæœºç”Ÿæˆ(0,1)ä¹‹é—´çš„æ•°ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰ rand_likeï¼šä¼ å…¥å‚æ•°æ˜¯ä¸€ä¸ªTensorï¼Œå°±randä¸€ä¸ªå’Œä¼ å…¥tensorå½¢çŠ¶ä¸€æ ·çš„tensor randintï¼šæŒ‡å®šæœ€å°å€¼å’Œæœ€å¤§å€¼ä»¥åŠTensorçš„ç»´åº¦ä¿¡æ¯ï¼Œç„¶åè¿›è¡Œéšæœºã€‚ randint_likeï¼šåŒrandlike,è¿™é‡Œä¸å†èµ˜è¿°ï¼Œè¯¦æƒ…è§ä¸Šé¢çš„rand_likeå‡½æ•° randnï¼šéšæœºç”Ÿæˆ(0,1)ä¹‹é—´çš„æ•°ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰ fullï¼šç»™å®šç»´åº¦ä¿¡æ¯å’Œå¯¹åº”çš„æ•°ï¼Œä½¿ç”¨è¯¥æ•°åˆå§‹åŒ–ç»™å®šç»´åº¦çš„tensorã€‚ 1234567891011121314151617181920212223242526272829303132333435363738In [3]: torch.rand(3,3)Out[3]: tensor([[0.2722, 0.3876, 0.2607], [0.2612, 0.5041, 0.4084], [0.2007, 0.0119, 0.1834]])In [4]: a=torch.rand(3,3)In [5]: torch.rand_like(a)Out[5]: tensor([[0.1392, 0.9533, 0.5443], [0.9043, 0.4646, 0.0362], [0.7572, 0.5375, 0.8975]])In [6]: b=torch.randint(1,10,[2,3])In [7]: bOut[7]: tensor([[5, 6, 9], [5, 1, 1]])In [8]: c=torch.randint_like(b,1,100)In [9]: cOut[9]: tensor([[42, 20, 59], [15, 51, 1]])In [10]: torch.randn(3,3)Out[10]: tensor([[ 0.6524, -1.4728, 0.0623], [-0.6681, 0.7447, 0.9798], [ 0.0814, 1.3355, -0.7414]])In [11]: torch.full([5,2],0.1213)Out[11]: tensor([[0.1213, 0.1213], [0.1213, 0.1213], [0.1213, 0.1213], [0.1213, 0.1213], [0.1213, 0.1213]])In [12]: torch.full([],7)#ç”Ÿæˆæ ‡é‡Out[12]: tensor(7)In [13]: torch.full([1],7)#ç”Ÿæˆä¸€ç»´å‘é‡Out[13]: tensor([7]) arange ä¼ å…¥ä¸¤ä¸ªæˆ–ä¸‰ä¸ªå‚æ•°ï¼Œåˆ†åˆ«è¡¨ç¤ºèµ·å§‹å’Œç»ˆæ­¢ä½ç½®ï¼ˆå·¦é—­å³å¼€ï¼‰ï¼Œç„¶åç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯æ­¥é•¿ï¼Œä¸å†™å°±é»˜è®¤æ˜¯1ã€‚ 12345In [3]: torch.arange(0,10)Out[3]: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])In [4]: torch.arange(0,10,2)Out[4]: tensor([0, 2, 4, 6, 8]) linspace/logspace linspaceå’Œarangeéå¸¸çš„åƒï¼Œä½†æ˜¯ç¬¬ä¸‰ä¸ªå‚æ•°ä¸è¡¨ç¤ºæ­¥é•¿äº†ï¼Œè€Œæ˜¯è¡¨ç¤ºçš„æ˜¯æ•°é‡ï¼Œè¿˜æœ‰ä¸€ä¸ªéå¸¸é‡è¦çš„ä¸åŒæ˜¯ï¼Œè¿™é‡Œçš„ç»ˆæ­¢ç‚¹æ˜¯åŒ…å«åœ¨äº†åˆ†å‰²çš„åºåˆ—ä¸­çš„ã€‚ï¼ˆè§ä¸‹é¢çš„ä¾‹å­ï¼‰ logspaceå…ˆæ˜¯åŒlinspaceä¸€æ ·ï¼Œå°†èµ·å§‹ç‚¹å’Œç»ˆæ­¢ç‚¹ä¹‹é—´çš„æ•°æ®åˆ’åˆ†æˆç»™å®šæ•°é‡çš„ç­‰å·®æ•°åˆ—ï¼Œç„¶åå°†è¿™äº›å€¼ä½œä¸ºæŒ‡æ•°ï¼Œ10ä½œä¸ºåº•æ•°ï¼ˆå½“ç„¶åº•æ•°ä¹Ÿå¯ä»¥è‡ªå·±é€šè¿‡æ”¹å˜baseå‚æ•°è¿›è¡Œè®¾ç½®ï¼‰ï¼Œè®¡ç®—å‡ºæ¥çš„åºåˆ—ä½œä¸ºæœ€åå‘ˆç°çš„ç­”æ¡ˆã€‚ 1234567891011121314151617In [3]: torch.linspace(0,10,steps=5)Out[3]: tensor([ 0.0000, 2.5000, 5.0000, 7.5000, 10.0000])In [4]: torch.linspace(0,10,steps=10)Out[4]: tensor([ 0.0000, 1.1111, 2.2222, 3.3333, 4.4444, 5.5556, 6.6667, 7.7778, 8.8889, 10.0000])In [5]: torch.linspace(0,10,steps=11)Out[5]: tensor([ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9., 10.])In [6]: torch.logspace(0,-1,steps=10)Out[6]: tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292, 0.1000])In [7]: torch.logspace(0,10,steps=11,base=2)Out[7]: tensor([1.0000e+00, 2.0000e+00, 4.0000e+00, 8.0000e+00, 1.6000e+01, 3.2000e+01, 6.4000e+01, 1.2800e+02, 2.5600e+02, 5.1200e+02, 1.0240e+03]) ones/zeros/eye è¿™ä¸ªéå¸¸ç®€å•ï¼Œå¤§å®¶ç›´æ¥çœ‹ä¸‹é¢çš„ä¾‹å­å°±å¯ä»¥æ˜ç™½ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚ 12345678910111213141516171819202122232425In [3]: torch.ones(3,3)Out[3]: tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]])In [4]: torch.zeros(3,3)Out[4]: tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])In [5]: torch.eye(3,3)Out[5]: tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])In [6]: torch.eye(3,5)Out[6]: tensor([[1., 0., 0., 0., 0.], [0., 1., 0., 0., 0.], [0., 0., 1., 0., 0.]])In [7]: torch.eye(3)Out[7]: tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) likeæ–¹æ³•åœ¨è¿™é‡Œä¹Ÿå¯ä»¥ä½¿ç”¨å“¦ã€‚æ¯”å¦‚ones_like randperm éšæœºæ‰“ä¹±å‡½æ•°ï¼Œä¸€èˆ¬ç”¨äºæ‰“ä¹±ç´¢å¼•ç¼–å·ã€‚ 123In [3]: idx=torch.randperm(10)In [4]: idxOut[4]: tensor([8, 6, 9, 5, 1, 2, 4, 7, 3, 0]) Tensor åˆ‡ç‰‡ ç®€å•åˆ‡ç‰‡ 123456789In [3]: a=torch.rand(4,3,28,28)In [4]: a[0].shapeOut[4]: torch.Size([3, 28, 28])In [5]: a[0,1].shapeOut[5]: torch.Size([28, 28])In [6]: a[0,1,2,3]Out[6]: tensor(0.4744)In [7]: a[:2].shapeOut[7]: torch.Size([2, 3, 28, 28]) é€‰åŒºé—´ 123456789In [9]: a[:2,:1,:,:].shapeOut[9]: torch.Size([2, 1, 28, 28])In [10]: a[:2,1:,:,:].shapeOut[10]: torch.Size([2, 2, 28, 28])In [11]: a[:2,-1,:,:].shapeOut[11]: torch.Size([2, 28, 28])In [12]: a[:2,-1:,:,:].shapeOut[12]: torch.Size([2, 1, 28, 28]) æœ‰æ­¥é•¿çš„åˆ‡ç‰‡ 1234In [14]: a[:,:,0:28:2,0:28:2].shapeOut[14]: torch.Size([4, 3, 14, 14])In [15]: a[:,:,::2,::2].shapeOut[15]: torch.Size([4, 3, 14, 14]) ç‰¹å®šç´¢å¼•åˆ‡ç‰‡ ä½¿ç”¨index_selectè¿™ä¸ªå‡½æ•° ä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ä¸€ä¸ªæ ‡é‡è¡¨ç¤ºå¯¹ç¬¬å‡ ä¸ªç»´åº¦è¿›è¡Œç´¢å¼•æ“ä½œï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯ä¸€ä¸ªtensoræ•°ç»„ï¼Œè¡¨ç¤ºæˆ‘ä»¬æƒ³å–å‡ºæ¥çš„ç´¢å¼•å·ã€‚ 123456789101112131415In [21]: a=torch.eye(3)In [22]: aOut[22]: tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])In [23]: a.index_select(0,torch.tensor([0,2]))Out[23]: tensor([[1., 0., 0.], [0., 0., 1.]])In [24]: a.index_select(0,torch.arange(2))Out[24]: tensor([[1., 0., 0.], [0., 1., 0.]]) â€¦ 12345678910111213In [3]: a=torch.rand(4,3,28,28)In [4]: a.shapeOut[4]: torch.Size([4, 3, 28, 28])In [5]: a[...].shapeOut[5]: torch.Size([4, 3, 28, 28])In [6]: a[0,...].shapeOut[6]: torch.Size([3, 28, 28])In [7]: a[:,1,...].shapeOut[7]: torch.Size([4, 28, 28])In [8]: a[...,:2].shapeOut[8]: torch.Size([4, 3, 28, 2]) é€šè¿‡é®ç½©å–æ•° ä½¿ç”¨åˆ°çš„å‡½æ•°æ˜¯masked_selectedï¼Œè¿™ä¸ªå‡½æ•°å¹¶ä¸æ˜¯éå¸¸çš„å¸¸ç”¨ã€‚ 123456789101112131415In [3]: z=torch.randn(3,4)In [4]: zOut[4]: tensor([[-0.9371, 1.0520, 0.2948, 0.3691], [ 0.9820, 0.9555, -0.9335, -1.5135], [-0.2594, -0.7860, -0.5336, 0.2682]])In [5]: mask=z.ge(0.5)In [6]: maskOut[6]: tensor([[False, True, False, False], [ True, True, False, False], [False, False, False, False]])In [7]: torch.masked_select(z,mask)Out[7]: tensor([1.0520, 0.9820, 0.9555]) é€šè¿‡takeæ¥è¿›è¡Œå–æ•° takeå–æ•°ä¼šå°†tensoræ‰“å¹³ç„¶åå†æ ¹æ®æ–°çš„ç´¢å¼•è¿›è¡Œå–æ•°æ“ä½œï¼Œè¯¦æƒ…è§ä¸‹é¢çš„ä¾‹å­ã€‚ 123In [3]: src=torch.tensor([[4,3,5],[6,7,8]])In [4]: torch.take(src,torch.tensor([0,2,5]))Out[4]: tensor([4, 5, 8]) Tensor ç»´åº¦å˜æ¢ view/reshape squeeze/unsqueeze transpose/t/permute expand/repeat reshape/view reshapeå’Œviewæ˜¯å®Œå…¨ç­‰ä»·çš„ï¼Œè¯¦æƒ…è§ä¸‹é¢çš„ä¾‹å­ã€‚ 12345678In [3]: a=torch.rand(4,1,28,28)In [4]: a.shapeOut[4]: torch.Size([4, 1, 28, 28])In [5]: a.view(4,28*28).shapeOut[5]: torch.Size([4, 784])In [6]: a.reshape(4,28*28).shapeOut[6]: torch.Size([4, 784]) squeeze/unsqueeze unsqueeze å¯¹äºä¸€ä¸ªç»´åº¦ä¸ºnçš„tensorï¼Œæƒ³è¦æ‰©å±•ç»´åº¦æ‰€èƒ½å¤Ÿä¼ å…¥å‚æ•°çš„èŒƒå›´æ˜¯**$[-n-1,n+1)$**å¦‚æœè¾“å…¥çš„æ˜¯æ­£çš„ç´¢å¼•ï¼ˆæˆ–0ï¼‰åˆ™æ˜¯åœ¨ä¹‹å‰æ’å…¥ï¼Œè´Ÿçš„ç´¢å¼•åˆ™æ˜¯åœ¨ä¹‹åæ’å…¥ 123456789101112131415In [3]: a=torch.randn(4,1,28,28)In [4]: a.shapeOut[4]: torch.Size([4, 1, 28, 28])In [5]: a.unsqueeze(0).shapeOut[5]: torch.Size([1, 4, 1, 28, 28])In [6]: a.unsqueeze(-1).shapeOut[6]: torch.Size([4, 1, 28, 28, 1])In [7]: a.unsqueeze(4).shapeOut[7]: torch.Size([4, 1, 28, 28, 1])In [8]: a.unsqueeze(-4).shapeOut[8]: torch.Size([4, 1, 1, 28, 28])In [9]: a.unsqueeze(-5).shapeOut[9]: torch.Size([1, 4, 1, 28, 28])In [10]: a.unsqueeze(5).shapeOut[10]: RuntimeError: Dimension out of range squeeze 1234567891011121314In [3]: b=torch.rand(1,32,1,1)In [4]: b.shapeOut[4]: torch.Size([1, 32, 1, 1])In [5]: b.squeeze().shapeOut[5]: torch.Size([32])In [6]: b.squeeze(0).shapeOut[6]: torch.Size([32, 1, 1])In [7]: b.squeeze(-1).shapeOut[7]: torch.Size([1, 32, 1])In [8]: b.squeeze(1).shape # can&#x27;t squeeze this dimensionOut[8]: torch.Size([1, 32, 1, 1])In [9]: b.squeeze(-4).shapeOut[9]: torch.Size([32, 1, 1]) expand/repeat expand è¿™æ˜¯ç»´åº¦æ‰©å±•å‡½æ•°å’Œç»´åº¦å¢åŠ å‡½æ•°è¿˜æ˜¯æœ‰è¾ƒå¤§ä¸åŒçš„ï¼Œæ³¨æ„åŒºåˆ†ï¼ç»´åº¦å¢åŠ æ˜¯å¢åŠ äº†ä¸€ä¸ªæ–°çš„ç»´åº¦ï¼Œè€Œç»´åº¦æ‰©å±•æ˜¯å°†å½“å‰å·²æœ‰ç»´åº¦æ”¹å˜å…¶shapeçš„å¤§å°ã€‚ ä¸¤ä¸ªAPIæ‰€å®ç°çš„åŠŸèƒ½æ˜¯å®Œå…¨ä¸€æ ·çš„ï¼Œä½†æ˜¯æˆ‘ä»¬æ›´åŠ æ¨èä½¿ç”¨ç¬¬ä¸€ä¸ªAPIï¼Œå› ä¸ºç¬¬ä¸€ä¸ªAPIæ˜¯åœ¨æ•°æ®éœ€è¦ä½¿ç”¨æ—¶æ‰è¿›è¡Œå¤åˆ¶ï¼Œå› æ­¤expandçš„æ‰§è¡Œé€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”æ›´åŠ èŠ‚çº¦å†…å­˜ã€‚ åªæœ‰åŸæ¥ç»´åº¦ä¸º1ï¼Œæ‰èƒ½å¤Ÿè¢«æ‰©å±•ï¼ï¼ï¼ å¦‚æœexpandä¸­å¡«å†™çš„å‚æ•°ä¸º-1ï¼Œè¡¨ç¤ºçš„æ˜¯ç»´åº¦å¤§å°ä¿æŒä¸å˜ã€‚ 123456789101112131415161718In [3]: a=torch.rand(1,3)In [4]: aOut[4]: tensor([[0.2768, 0.6714, 0.6259]])In [5]: a.shapeOut[5]: torch.Size([1, 3])In [6]: a.expand(4,3)Out[6]: tensor([[0.2768, 0.6714, 0.6259], [0.2768, 0.6714, 0.6259], [0.2768, 0.6714, 0.6259], [0.2768, 0.6714, 0.6259]])In [7]: a.expand(4,-1)Out[7]: tensor([[0.2768, 0.6714, 0.6259], [0.2768, 0.6714, 0.6259], [0.2768, 0.6714, 0.6259], [0.2768, 0.6714, 0.6259]]) repeat ä¼ å…¥çš„å‚æ•°å’Œexpandå‡½æ•°æœ‰ä¸€äº›ä¸åŒï¼Œè¿™é‡Œæ‰€ä¼ å…¥çš„å‚æ•°ä»£è¡¨æ‹·è´çš„æ¬¡æ•°ï¼Œæ¯”å¦‚å¦‚æœåŸæ¥ç»´åº¦å¤§å°æ˜¯32ï¼Œä¸‹é¢å¯¹åº”å‚æ•°å¡«å†™ä¸º2ï¼Œæœ€åç”Ÿæˆçš„å¤§å°å°±æ˜¯64ã€‚ 12345678910In [3]: a=torch.rand(1,32,1,1)In [4]: a.repeat(4,32,1,1).shapeOut[4]: torch.Size([4, 1024, 1, 1])In [5]: a.repeat(4,1,1,1).shapeOut[5]: torch.Size([4, 32, 1, 1])In [6]: a.repeat(4,1,32,32).shapeOut[6]: torch.Size([4, 32, 32, 32])In [7]: a.repeat(4,1,32,0).shapeOut[7]: torch.Size([4, 32, 32, 0]) transpose/t/permute t çŸ©é˜µè½¬ç½®æ“ä½œ è¿™ä¸ªå‡½æ•°åªé€‚ç”¨äºäºŒç»´tensorï¼Œå…¶ä»–ç»´åº¦çš„tensorä½¿ç”¨ä¼šæŠ¥é”™ 12345678910111213In [3]: a=torch.rand(3,4)In [4]: aOut[4]: tensor([[0.0723, 0.9169, 0.2574, 0.9654], [0.5009, 0.9152, 0.6344, 0.7596], [0.5432, 0.3906, 0.9426, 0.9421]])In [5]: a.t()Out[5]: tensor([[0.0723, 0.5009, 0.5432], [0.9169, 0.9152, 0.3906], [0.2574, 0.6344, 0.9426], [0.9654, 0.7596, 0.9421]]) transpose çŸ©é˜µç»´åº¦äº¤æ¢å‡½æ•°ï¼Œç›´æ¥è¾“å…¥ä¸¤ä¸ªéœ€è¦è¿›è¡Œäº¤æ¢çš„ç»´åº¦ï¼Œå°±å¯ä»¥ç›´æ¥å°†è¿™ä¸¤ä¸ªç»´åº¦è¿›è¡Œäº¤æ¢ï¼ŒåŒæ—¶è¿™ä¸¤ä¸ªç»´åº¦å­˜å‚¨çš„ä¿¡æ¯ä¹Ÿä¼šè¿›è¡Œäº¤æ¢ã€‚ 12345678910In [3]: a=torch.rand(4,3,32,32)In [4]: a1=a.transpose(1,3).contiguous().view(4,3*32*32).view(4,3,32,32)In [5]: a2=a.transpose(1,3).contiguous().view(4,3*32*32).view(4,32,32,3).transpose(1,3)In [6]: a1.shape,a2.shapeOut[6]: (torch.Size([4, 3, 32, 32]), torch.Size([4, 3, 32, 32]))In [7]: torch.all(torch.eq(a,a1))Out[7]: tensor(False)In [8]: torch.all(torch.eq(a,a2))Out[8]: tensor(True) contiguouså‡½æ•°æ˜¯ä½¿å†…å­˜é¡ºåºå˜å¾—è¿ç»­ï¼Œä¸ç„¶ä¼šå¦‚æœæœ‰ä»¥ä¸‹å†™æ³•ä¼šå‡ºç°æŠ¥é”™ã€‚ï¼ˆå› ä¸ºviewä¼šå¿½è§†ç»´åº¦ä¿¡æ¯ï¼‰ permute å’Œtransposeæ¯”è¾ƒç±»ä¼¼ï¼Œä½†æ˜¯å¾ˆå¥½çš„è§£å†³äº†transposeæ¯æ¬¡åªèƒ½äº¤æ¢ä¸¤ä¸ªç»´åº¦çš„é—®é¢˜ï¼Œæˆ‘ä»¬è¾“å…¥çš„å‚æ•°ï¼Œæ˜¯ç»´åº¦çš„æ’åˆ—é¡ºåºï¼Œè¿™æ ·å°±å¯ä»¥åŒæ—¶äº¤æ¢å¤šä¸ªç»´åº¦ã€‚ 12345In [3]: a=torch.rand(1,2,3,4)In [4]: a.shapeOut[4]: torch.Size([1, 2, 3, 4])In [5]: a.permute(3,0,2,1).shapeOut[5]: torch.Size([4, 1, 3, 2])"},{"title":"PyTorchè¿›é˜¶","path":"/wiki/PyTorch/PyTorchè¿›é˜¶.html","content":"Broadcastè‡ªåŠ¨æ‰©å±• ç»´åº¦æ‰©å±• æ‰©å±•æ— éœ€å¤åˆ¶æ•°æ® å¯¹äºä¸€ä¸ªshapeä¸º`torch.size([x1,x2,x3,...,xn])`çš„`tensor`,é è¿‘x1é‚£ä¸€ç«¯ä¸ºå¤§ç»´åº¦ï¼Œé è¿‘xné‚£ä¸€ç«¯ä¸ºå°ç»´åº¦ã€‚é‚£ä¹ˆå¯¹äºbroadcastæœ‰ï¼š å°ç»´åº¦æŒ‡å®šï¼Œå¤§ç»´åº¦éšæ„è¿™ä¸€è§„å¾‹ï¼ˆå› ä¸ºåœ¨å¤§ç»´åº¦ä¸Šè¿›è¡Œå¹¿æ’­ï¼‰ æ‹¼æ¥ä¸æ‹†åˆ† cat stack split chunk cat ä¸»è¦çš„åŠŸèƒ½æ˜¯å°†tensoræ‹¼æ¥èµ·æ¥ 1234In [3]: a=torch.rand(4,32,8)In [4]: b=torch.rand(5,32,8)In [5]: torch.cat([a,b],dim=0).shapeOut[5]: torch.Size([9, 32, 8]) `dim`å‚æ•°è¡¨ç¤ºçš„æ˜¯åœ¨å“ªä¸ªç»´åº¦ä¸Šè¿›è¡Œåˆå¹¶ã€‚å¦‚æœæ˜¯`n`ç»´tensoråˆ™å–å€¼èŒƒå›´æ˜¯[0,n) stack stackçš„åŠŸèƒ½å’Œcatæœ‰äº›åƒï¼Œä½†æ˜¯ä»–è¦æ±‚çš„æ˜¯æ‰€æ‹¼æ¥çš„ä¸¤ä¸ªtensorçš„shapeå¿…é¡»å®Œå…¨ä¸€æ ·ã€‚å¹¶ä¸”æ‹¼æ¥åä¼šåœ¨æ‹¼æ¥ç»´åº¦ä¹‹å‰å¢åŠ ä¸€ä¸ªç»´åº¦ã€‚ æ³¨æ„ï¼šshapeå¿…é¡»å®Œå…¨ä¸€æ ·ï¼ ç„¶ååœ¨æ‰€æ‹¼æ¥ç»´åº¦ä¹‹å‰ä¼šæ–°å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œç”¨äºåŒºåˆ†æ˜¯æ‹¼æ¥çš„å“ªä¸€å—ï¼ˆå‰ä¸€å—æˆ–åä¸€å—ï¼‰ 1234In [3]: a1=torch.rand(5,3,16,32)In [4]: a2=torch.rand(5,3,16,32)In [5]: torch.stack([a1,a2],dim=1).shapeOut[5]: torch.Size([5, 2, 3, 16, 32]) split splitæ˜¯æŒ‰ç…§é•¿åº¦å¯¹tensorè¿›è¡Œæ‹†åˆ†çš„å‡½æ•°ï¼Œä¸€èˆ¬ä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä»£è¡¨çš„æ˜¯æ‰€æ‹†ç»´åº¦çš„é•¿åº¦ï¼ˆé•¿åº¦ä¸ä»…å¯ä»¥ç”¨æ ‡é‡è¡¨ç¤ºå›ºå®šçš„é•¿åº¦ï¼Œä¹Ÿå¯ä»¥ç”¨listæ¥è¡¨ç¤ºä¸å›ºå®šçš„é•¿åº¦ï¼Œè¯¦æƒ…è§ä¸‹é¢çš„ä¾‹å­ï¼‰ï¼Œç¬¬äºŒä¸ªå‚æ•°ä»£è¡¨çš„æ˜¯æ‰€æ‹†çš„ç»´åº¦æ˜¯ç¬¬å‡ ç»´åº¦ã€‚ 12345678In [3]: c=torch.rand(3,32,8)In [4]: aa,bb,cc=c.split(1,dim=0)In [5]: aa.shape,bb.shape,cc.shapeOut[5]: (torch.Size([1, 32, 8]), torch.Size([1, 32, 8]), torch.Size([1, 32, 8]))In [6]: aa,bb=c.split([2,1],dim=0)In [7]: aa.shape,bb.shapeOut[7]: (torch.Size([2, 32, 8]), torch.Size([1, 32, 8])) chunck chunckæ˜¯æŒ‰ç…§æ•°é‡å¯¹tensorè¿›è¡Œæ‹†åˆ†çš„å‡½æ•°ï¼Œä¸€èˆ¬ä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä»£è¡¨çš„æ˜¯æ‰€æ‹†ç»´åº¦è¦æ‹†å‡ºæ¥çš„æ•°é‡ï¼Œç¬¬äºŒä¸ªå‚æ•°ä»£è¡¨çš„æ˜¯æ‰€æ‹†çš„ç»´åº¦æ˜¯ç¬¬å‡ ç»´åº¦ã€‚ 12345In [3]: d=torch.rand(6,32,8)In [4]: c=torch.rand(3,32,8)In [5]: aa,bb,cc=d.chunk(3,dim=0)In [6]: aa.shape,bb.shape,cc.shapeOut[6]: (torch.Size([2, 32, 8]), torch.Size([2, 32, 8]), torch.Size([2, 32, 8])) æ•°å­¦è¿ç®— åŸºæœ¬å››åˆ™è¿ç®—(add/minus/multiply/divide) çŸ©é˜µä¹˜æ³•(Matmul) ä¹˜æ–¹è¿ç®—(Pow) å¼€æ–¹è¿ç®—(Sqrt/rsqrt) è¿‘ä¼¼è¿ç®—(Round) åŸºæœ¬å››åˆ™è¿ç®— 1234567891011121314151617181920212223In [3]: a=torch.tensor([[2,4,6],[8,10,12]])In [4]: b=torch.ones(2,3)*2In [5]: a+bOut[5]: tensor([[ 4., 6., 8.], [10., 12., 14.]])In [6]: a-bOut[6]: tensor([[ 0., 2., 4.], [ 6., 8., 10.]])In [7]: a*bOut[7]: tensor([[ 4., 8., 12.], [16., 20., 24.]])In [8]: a/bOut[8]: tensor([[1., 2., 3.], [4., 5., 6.]])In [9]: a/(a/b)Out[9]: tensor([[2., 2., 2.], [2., 2., 2.]]) pytorchä¸­è¿˜ä¸“é—¨æœ‰å®šä¹‰å¥½çš„å››åˆ™è¿ç®—çš„å‡½æ•°å’Œä»¥ä¸Šè¿™äº›è¿ç®—ç¬¦å·æ‰€è¿ç®—å‡ºæ¥çš„æ•ˆæœç›¸åŒï¼Œä»–ä»¬åˆ†åˆ«æ˜¯ã€‚ torch.add torch.minus torch.mul torch.div 123456789In [10]: torch.all(torch.eq(a+b,torch.add(a,b)))Out[10]: tensor(True)In [11]: torch.all(torch.eq(a-b,torch.sub(a,b)))Out[11]: tensor(True)In [12]: torch.all(torch.eq(a*b,torch.mul(a,b)))Out[12]: tensor(True)In [13]: torch.all(torch.eq(a/b,torch.div(a,b)))Out[13]: tensor(True) æ³¨æ„ï¼šè¿™é‡Œçš„ä¹˜æ³•å’Œé™¤æ³•ï¼Œä¸åŒäºçŸ©é˜µä¹˜æ³•å’Œé™¤æ³•ï¼Œåªæ˜¯å°†ä¸¤ä¸ªçŸ©é˜µå¯¹åº”ä½ç½®çš„æ•°è¿›è¡Œç›¸ä¹˜æˆ–ç›¸é™¤æ“ä½œã€‚ è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªæ•´é™¤è¿ç®—ç¬¦å·//æ²¡æœ‰è®²åˆ°ï¼Œå¥½åƒå¹¶æ²¡æœ‰æ‰¾åˆ°ä¸ä»–å¯¹åº”çš„å‡½æ•° çŸ©é˜µä¹˜æ³• torch.mm(åªé€‚ç”¨äºäºŒç»´tensor,ä¸æ¨è) torch.matmul(é€‚ç”¨äºä»»æ„ç»´åº¦çš„çŸ©é˜µ) @(åŒä¸Štorch.matmul) 123456789101112131415In [3]: a=torch.tensor([[2,4],[8,12]])In [4]: b=torch.tensor([[1,2],[3,4]])In [5]: torch.mm(a,b)Out[5]: tensor([[14, 20], [44, 64]])In [6]: torch.matmul(a,b)Out[6]: tensor([[14, 20], [44, 64]])In [7]: a@bOut[7]: tensor([[14, 20], [44, 64]]) BPå…¨è¿æ¥ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªä¾‹å­ x@w.t()+bx@w.t()+b x@w.t()+b 1234In [4]: x=torch.rand(4,784)In [5]: w=torch.rand(512,784)In [6]: (x@w.t()).shapeOut[6]: torch.Size([4, 512]) é«˜äº2ç»´çŸ©é˜µä¹˜æ³•çš„åŸç† å–æœ€å°ä¸¤ä¸ªç»´åº¦çš„å†…å®¹è¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œä¿ç•™é«˜ç»´åº¦çš„çš„å¤§å°ã€‚å…¶å®ç›¸å½“äºæ˜¯æ”¯æŒäº†å¤šä¸ªçŸ©é˜µå¹¶è¡Œç›¸ä¹˜ã€‚ é«˜ç»´åº¦å¤§å°ä¸ä¸€å®šè¦å®Œå…¨ä¸€æ ·ï¼Œä½†æ˜¯è¦ç¬¦åˆbroadcastingåŸåˆ™ï¼Œå…·ä½“è§ä¸‹é¢çš„ä¾‹å­ 12345678910In [3]: a=torch.rand(4,3,28,64)In [4]: b=torch.rand(4,3,64,32)In [5]: torch.matmul(a,b).shapeOut[5]: torch.Size([4, 3, 28, 32])In [6]: b=torch.rand(4,1,64,32)In [7]: torch.matmul(a,b).shapeOut[7]: torch.Size([4, 3, 28, 32])In [8]: b=torch.rand(4,2,64,32)In [9]: torch.matmul(a,b).shapeTraceback ä¹˜æ–¹è¿ç®— .pow()ï¼šæ‹¬å·ä¸­å†™æ¬¡æ–¹æ•° **ï¼šåŒä¸Šé¢çš„powå‡½æ•°ï¼Œä¹˜æ–¹è¿ç®—ç¬¦ sqrt()ï¼šå¼€å¹³æ–¹è¿ç®— rsqrt()ï¼šå¼€å¹³æ–¹åæ±‚å€’æ•°ã€‚ 1234567891011121314151617181920212223242526272829In [3]: a=torch.full([2,2],3)In [4]: aOut[4]: tensor([[3, 3], [3, 3]])In [5]: a.pow(2)Out[5]: tensor([[9, 9], [9, 9]])In [6]: a**2Out[6]: tensor([[9, 9], [9, 9]])In [7]: torch.all(torch.eq(a**2,a.pow(2)))Out[7]: tensor(True)In [8]: aa=a**2In [9]: aa.sqrt()Out[9]: tensor([[3., 3.], [3., 3.]])In [10]: aa.rsqrt()Out[10]: tensor([[0.3333, 0.3333], [0.3333, 0.3333]])In [11]: aa**(0.5)Out[11]: tensor([[3., 3.], [3., 3.]]) expå’Œlogå’Œlog2å’Œlog10 çœ‹åå­—åº”è¯¥å°±å¤§æ¦‚æ˜ç™½åŠŸèƒ½äº†ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ï¼Œç›´æ¥ä¸Šä¸€ä¸ªä¾‹å­å§ 12345678910In [14]: a=torch.exp(torch.ones(2,2))In [15]: aOut[15]: tensor([[2.7183, 2.7183], [2.7183, 2.7183]])In [16]: torch.log(a)Out[16]: tensor([[1., 1.], [1., 1.]]) 1234567891011In [18]: a=torch.ones(2,2)*2In [19]: torch.log2(a)Out[19]: tensor([[1., 1.], [1., 1.]])In [20]: a=torch.ones(2,2)*100In [21]: torch.log10(a)Out[21]: tensor([[2., 2.], [2., 2.]]) è¿‘ä¼¼è¿ç®— .floor()ï¼šå‘ä¸‹å–æ•´ .ceil()ï¼šå‘ä¸Šå–æ•´ .round()ï¼šå››èˆäº”å…¥ .trunc()ï¼šè£å‰ªâ€”â€”åªä¿ç•™æ•´æ•°éƒ¨åˆ† /frac()ï¼šè£å‰ªâ€”â€”åªä¿ç•™å°æ•°éƒ¨åˆ† 12345678910In [3]: a=torch.tensor(3.14)In [4]: a.floor(),a.ceil(),a.trunc(),a.frac()Out[4]: (tensor(3.), tensor(4.), tensor(3.), tensor(0.1400))In [5]: a=torch.tensor(3.499999)In [6]: a.round()Out[6]: tensor(3.)In [7]: a=torch.tensor(3.5)In [8]: a.round()Out[8]: tensor(4.) æ¢¯åº¦è£å‰ªâ€» æˆ‘ä»¬åœ¨åšå’Œæœºå™¨å­¦ä¹ ç›¸å…³çš„é¡¹ç›®ä¸­æ—¶ï¼Œæœ‰å¯èƒ½ä¼šç¢°åˆ°è¿™ç§æƒ…å†µï¼Œå°±æ˜¯æ¢¯åº¦å¤ªå¤§æˆ–å¤ªå°ï¼ˆæ¥è¿‘0ï¼‰ä»è€Œå¯¼è‡´æˆ‘ä»¬çš„è®­ç»ƒç»“æœå¹¶ä¸æ˜¯éå¸¸çš„ç†æƒ³ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é‡‡ç”¨æ¢¯åº¦è£å‰ªçš„æ–¹æ³•ï¼Œå°†æ¢¯åº¦ç°æœ‰æ¢¯åº¦æ§åˆ¶åœ¨ä¸€ä¸ªèŒƒå›´å†…ï¼Œæœ‰æ•ˆé¿å…è¿™ç±»é—®é¢˜ã€‚ æ‰€ä½¿ç”¨çš„å‡½æ•°æ˜¯clampï¼Œä¸€èˆ¬ä¼ å…¥ä¸€ä¸ªæˆ–ä¸¤ä¸ªå‚æ•°ã€‚ å¦‚æœä¹‹ä¼ å…¥ä¸€ä¸ªå‚æ•°ï¼Œè¯¥å‚æ•°è¡¨ç¤ºæ¢¯åº¦çš„æœ€å°å€¼ï¼Œå› æ­¤æ¯”è¯¥å€¼å°çš„æ¢¯åº¦éƒ½ä¼šè¢«å¼ºè¡Œå¢å¤§åˆ°è¯¥å€¼ã€‚ å¦‚æœä¼ å…¥ä¸¤ä¸ªå‚æ•°ï¼Œåˆ™ä¸¤ä¸ªå‚æ•°åˆ†åˆ«è¡¨ç¤ºæœ€å°å€¼å’Œæœ€å¤§å€¼ï¼Œæ¯”æœ€å°å€¼å°çš„å€¼ä¼šå¼ºè¡Œå˜ä¸ºè®¾å®šçš„æœ€å°å€¼ï¼Œæ¯”æœ€å¤§å€¼å¤§çš„å€¼ä¼šå¼ºè¡Œå˜ä¸ºè®¾å®šçš„æœ€å¤§å€¼ã€‚ 123456789101112131415161718192021222324In [3]: grad=torch.rand(2,3)*30-15In [4]: grad.max()Out[4]: tensor(6.2306)In [5]: grad.min()Out[5]: tensor(-11.8838)In [6]: grad.median()Out[6]: tensor(-0.5767)In [7]: grad.clamp(5)Out[7]: tensor([[5.0000, 5.0000, 5.0000], [5.0000, 5.0000, 6.2306]])In [8]: gradOut[8]: tensor([[ 3.8570, -0.2229, -11.8838], [ -8.5261, -0.5767, 6.2306]])In [9]: grad.clamp(0)Out[9]: tensor([[3.8570, 0.0000, 0.0000], [0.0000, 0.0000, 6.2306]])In [10]: grad.clamp(0,5)Out[10]: tensor([[3.8570, 0.0000, 0.0000], [0.0000, 0.0000, 5.0000]]) ç»Ÿè®¡å±æ€§ normï¼šèŒƒæ•° mean,sumï¼šå¹³å‡å€¼ï¼Œå’Œ prodï¼šç´¯ä¹˜ max,min,argmin,argmaxï¼šæœ€å¤§å€¼ï¼Œæœ€å°å€¼ï¼Œæœ€å°å€¼æ‰€åœ¨ä½ç½®ï¼Œæœ€å¤§å€¼æ‰€åœ¨ä½ç½® kthvalue,topkï¼šæ±‚ç¬¬kä¸ªå€¼ï¼Œæ±‚å‰kä¸ªå€¼ norm ä¸€èˆ¬æ˜¯1èŒƒæ•°å’Œ2èŒƒæ•°ä½¿ç”¨çš„è¾ƒå¤šï¼Œä½†ä¸‹é¢è¿˜æ˜¯ä¼šå°†å„ä¸ªèŒƒæ•°çš„å«ä¹‰è¿›è¡Œç®€è¦çš„ä»‹ç»ã€‚ 0èŒƒæ•°ï¼šçŸ©é˜µä¸­éé›¶å…ƒç´ çš„ä¸ªæ•° 1èŒƒæ•°ï¼šçŸ©é˜µä¸­å„ä¸ªå…ƒç´ çš„ç»å¯¹å€¼ä¹‹å’Œ 2èŒƒæ•°ï¼šçŸ©é˜µä¸­å„ä¸ªå…ƒç´ å¹³æ–¹å’Œçš„1/2æ¬¡æ–¹ï¼Œåˆè¢«ç§°ä¸ºEuclideanèŒƒæ•°æˆ–è€…Frobenius èŒƒæ•°ã€‚ pèŒƒæ•°ï¼šä¸ºxå‘é‡ï¼ˆæˆ–çŸ©é˜µï¼‰å„ä¸ªå…ƒç´ ç»å¯¹å€¼pæ¬¡æ–¹å’Œçš„1/pæ¬¡æ–¹ã€‚ normå‡½æ•°ä¸€èˆ¬éœ€è¦ä¸€ä¸ªæˆ–è€…ä¸¤ä¸ªå‚æ•°ï¼Œå¦‚æœåªæ˜¯æä¾›ä¸€ä¸ªå‚æ•°ï¼Œåˆ™è¯¥å‚æ•°è¡¨ç¤ºçš„æ˜¯ç¬¬å‡ èŒƒæ•°ï¼Œå¦‚æœæä¾›2ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°æ„ä¹‰åŒä¸Šï¼Œç¬¬äºŒä¸ªå‚æ•°çš„æ„ä¹‰æ˜¯åœ¨å“ªä¸ªç»´åº¦ä¸Šè¿›è¡ŒèŒƒæ•°è¿ç®—ã€‚ 123456789101112131415161718192021222324252627282930313233343536In [3]: a=torch.tensor([1.,2.,3.,4.,5.,6.,7.,8.])In [4]: b=a.view(2,4)In [5]: c=a.view(2,2,2)In [6]: bOut[6]: tensor([[1., 2., 3., 4.], [5., 6., 7., 8.]])In [7]: cOut[7]: tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])In [8]: a.norm(1),b.norm(1),c.norm(1)Out[8]: (tensor(36.), tensor(36.), tensor(36.))In [9]: a.norm(2),b.norm(2),c.norm(2)Out[9]: (tensor(14.2829), tensor(14.2829), tensor(14.2829))In [10]: b.norm(1,dim=1)Out[10]: tensor([10., 26.])In [11]: b.norm(1,dim=0)Out[11]: tensor([ 6., 8., 10., 12.])In [12]: b.norm(2,dim=1)Out[12]: tensor([ 5.4772, 13.1909])In [13]: c.norm(1,dim=0)Out[13]: tensor([[ 6., 8.], [10., 12.]])In [14]: c.norm(1,dim=1)Out[14]: tensor([[ 4., 6.], [12., 14.]])In [15]: c.norm(1,dim=2)Out[15]: tensor([[ 3., 7.], [11., 15.]]) mean,max,min,sum,prod 123456789101112In [3]: a=torch.arange(8).view(2,4).float()In [4]: aOut[4]: tensor([[0., 1., 2., 3.], [4., 5., 6., 7.]])In [5]: a.min(),a.max(),a.mean(),a.prod()Out[5]: (tensor(0.), tensor(7.), tensor(3.5000), tensor(0.))In [6]: a.sum()Out[6]: tensor(28.)In [7]: a.argmax(),a.argmin()Out[7]: (tensor(7), tensor(0)) å¯ä»¥å‘ç°argmaxå’Œargminåœ¨å¯»æ‰¾æœ€å¤§æœ€å°å€¼çš„æ—¶å€™ï¼Œæ˜¯å°†æ•´ä¸ªtensorå˜ä¸ºäº†ä¸€ä¸ªä¸€ç»´å‘é‡çš„ï¼å¦‚æœæˆ‘ä»¬æƒ³æ±‚æ¯ä¸€è¡Œçš„ä¸€ä¸ªæœ€å¤§å€¼æˆ–æœ€å°å€¼çš„ä½ç½®ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨ä»¥ä¸‹çš„è¿™ç§åšæ³•ã€‚ 123In [3]: a=torch.randn(4,10)In [4]: a.argmax(dim=1)Out[4]: tensor([3, 0, 6, 9]) dim&amp;keepdim è¿™ä¸¤ä¸ªéƒ½æ˜¯å‡½æ•°ä¸­çš„å‚æ•°ï¼Œdimçš„ä½œç”¨åœ¨ä¸Šé¢æˆ‘ä»¬å·²ç»æ¼”ç¤ºè¿‡äº†ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚keepdimè®¾ç½®çš„æ˜¯è¿”å›çš„ç­”æ¡ˆæ˜¯å¦è¦å’ŒåŸæ¥çš„çŸ©é˜µä¿æŒç›¸åŒçš„ç»´åº¦ä¿¡æ¯ã€‚ 12345678910111213141516171819202122232425262728In [3]: a=torch.randn(4,10)In [4]: a.argmax(dim=1)Out[4]: tensor([3, 0, 6, 9])In [5]: a.max(dim=1)Out[5]: torch.return_types.max(values=tensor([2.2597, 1.0554, 0.9288, 1.1149]),indices=tensor([3, 0, 6, 9]))In [6]: a.argmax(dim=1)Out[6]: tensor([3, 0, 6, 9])In [7]: a.max(dim=1,keepdim=True)Out[7]: torch.return_types.max(values=tensor([[2.2597], [1.0554], [0.9288], [1.1149]]),indices=tensor([[3], [0], [6], [9]]))In [8]: a.argmax(dim=1,keepdim=True)Out[8]: tensor([[3], [0], [6], [9]]) topk,kthvalue 123456789101112131415161718192021222324252627282930313233343536373839In [3]: a=torch.randn(4,10)In [4]: a.topk(3,dim=1)Out[4]: torch.return_types.topk(values=tensor([[2.0085, 0.5275, 0.4304], [1.5748, 0.8510, 0.6699], [1.1440, 0.8921, 0.7946], [0.9630, 0.8487, 0.8158]]),indices=tensor([[4, 0, 8], [9, 3, 5], [5, 9, 0], [6, 9, 4]]))In [5]: a.topk(3,dim=1,largest=False)Out[5]: torch.return_types.topk(values=tensor([[-1.8353, -1.5600, -0.7452], [-1.1623, -1.0671, -0.2221], [-1.1269, -0.3777, -0.2676], [-2.1377, -0.2639, -0.0832]]),indices=tensor([[2, 3, 9], [1, 8, 4], [7, 8, 6], [8, 1, 5]]))In [6]: a.kthvalue(1,dim=1)Out[6]: torch.return_types.kthvalue(values=tensor([-1.8353, -1.1623, -1.1269, -2.1377]),indices=tensor([2, 1, 7, 8]))In [7]: a.kthvalue(1)Out[7]: torch.return_types.kthvalue(values=tensor([-1.8353, -1.1623, -1.1269, -2.1377]),indices=tensor([2, 1, 7, 8]))In [8]: a.kthvalue(9)Out[8]: torch.return_types.kthvalue(values=tensor([0.5275, 0.8510, 0.8921, 0.8487]),indices=tensor([0, 3, 9, 9])) å¯¹äºtopkå‡½æ•°é»˜è®¤æ˜¯ä»å¤§åˆ°å°ï¼Œå¦‚æœæŠŠlargestæ”¹ä¸ºFalseåˆ™æ˜¯ä»å°åˆ°å¤§ã€‚kthvalueå‡½æ•°é»˜è®¤æ˜¯ä»å°åˆ°å¤§ æ¯”è¾ƒ &gt;,&gt;=,&lt;=,!=,== torch.eq(a,b) ä»¥ä¸Šä¸¤ç§éƒ½æ˜¯æ¯”è¾ƒçŸ©é˜µå¯¹åº”ä½ç½®çš„æ•°ï¼Œå› æ­¤è¿”å›çš„å€¼æ˜¯ä¸€ä¸ªåŒå¤§å°çš„çŸ©é˜µã€‚ torch.equal(a,b)ï¼šåˆ¤æ–­ä¸¤ä¸ªçŸ©é˜µæ˜¯å¦å®Œå…¨ç›¸ç­‰ 12345678910111213141516171819202122232425262728293031323334In [3]: a=torch.randn(4,10)In [4]: a&gt;0Out[4]: tensor([[ True, True, True, True, True, True, False, False, True, True], [ True, True, True, True, True, True, False, True, False, False], [False, True, False, True, False, True, False, True, True, False], [False, True, False, True, False, False, False, False, True, True]])In [5]: torch.gt(a,0)Out[5]: tensor([[ True, True, True, True, True, True, False, False, True, True], [ True, True, True, True, True, True, False, True, False, False], [False, True, False, True, False, True, False, True, True, False], [False, True, False, True, False, False, False, False, True, True]])In [6]: a!=0Out[6]: tensor([[True, True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True, True]])In [7]: a=torch.ones(2,3)In [8]: b=torch.randn(2,3)In [9]: torch.eq(a,b)Out[9]: tensor([[False, False, False], [False, False, False]])In [10]: torch.eq(a,a)Out[10]: tensor([[True, True, True], [True, True, True]])In [11]: torch.equal(a,a)Out[11]: TrueIn [12]: torch.equal(a,b)Out[12]: False é«˜é˜¶æ“ä½œ where gather where torch.where(condition,x,y) whereå‡½æ•°è¿”å›ä¸€ä¸ªtensorï¼Œè¿™ä¸ªtensorä¸­çš„å…ƒç´ ä¸æ˜¯ä»xä¸­é€‰å‡ºæ¥çš„å°±æ˜¯ä»yä¸­é€‰å‡ºæ¥çš„ï¼Œé€‰æ‹©åˆ¤æ–­æ¡ä»¶å¦‚ä¸‹æ‰€ç¤ºï¼š outi={xiifÂ conditioniyiotherwiseout_i=\\begin{cases} x_i \\quad if\\ condition_i\\\\ y_i\\quad otherwise \\end{cases} outiâ€‹={xiâ€‹ifÂ conditioniâ€‹yiâ€‹otherwiseâ€‹ conditionä¹Ÿæ˜¯ä¸€ä¸ªtensorï¼Œå’Œx,yçš„å¤§å°ä¸€æ ·ã€‚å¦‚æœå¯¹åº”ä½ç½®çš„conditonå€¼ä¸º1ï¼Œåˆ™å–xå¯¹åº”ä½ç½®çš„æ•°æ®ï¼Œå¦åˆ™å–yå¯¹åº”ä½ç½®çš„æ•°æ® 1234567891011121314151617181920In [3]: cond=torch.rand(2,2)In [4]: a=torch.zeros(2,2)In [5]: b=torch.ones(2,2)In [6]: condOut[6]: tensor([[0.5486, 0.6658], [0.9244, 0.3691]])In [7]: aOut[7]: tensor([[0., 0.], [0., 0.]])In [8]: bOut[8]: tensor([[1., 1.], [1., 1.]])In [9]: torch.where(cond&gt;0.6,a,b)Out[9]: tensor([[1., 0.], [0., 1.]]) è™½ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨Pythonè‡ªå¸¦çš„forå¾ªç¯å’Œifè¯­å¥æ¥å®ç°åŒæ ·çš„åŠŸèƒ½ï¼Œä½†æ˜¯è¿™æ ·çš„è¯ç”±äºè¿™äº›è¯­å¥è¿è¡Œåœ¨CPUä¸Šï¼Œæˆ‘ä»¬ä¸èƒ½äº«å—åˆ°PyTorchåº“ä¸­å¸¦æ¥çš„GPUåŠ é€Ÿçš„ä¼˜åŠ¿ï¼Œå› æ­¤ä¼šè¿è¡Œçš„æ›´æ…¢ä¸€äº›ã€‚ gather torch.gather(input,dim,index,out=None) gatherå‡½æ•°å®ç°çš„åŠŸèƒ½ç±»ä¼¼äºæŸ¥è¡¨å‡½æ•°ï¼Œç»™å®šä¸€ä¸ªåˆå§‹è¡¨ï¼Œå†ç»™å®šä¸€ä¸ªç´¢å¼•è¡¨ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸€å¼ æŒ‰ç…§ç´¢å¼•è¡¨æŸ¥å®Œåˆå§‹è¡¨çš„è¡¨ã€‚ 12345678910111213141516171819In [3]: prob=torch.randn(4,10)In [4]: idx=prob.topk(dim=1,k=3)In [5]: idx=idx[1]In [6]: idxOut[6]: tensor([[9, 6, 7], [0, 3, 2], [1, 4, 2], [1, 5, 6]])In [7]: label=torch.arange(10)+100In [8]: labelOut[8]: tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])In [9]: torch.gather(label.expand(4,10),dim=1,index=idx.long())Out[9]: tensor([[109, 106, 107], [100, 103, 102], [101, 104, 102], [101, 105, 106]]) æ€»ç»“ ä»¥ä¸Šä¾¿æ˜¯PyTorchä¸­å¸¸ç”¨çš„æ“ä½œäº†ï¼Œåç»­å°±æ˜¯å®æˆ˜ç¯èŠ‚äº†ã€‚"},{"title":"accumulate","path":"/wiki/C++/numeric/accumulate.html","content":"accumulate å‡½æ•°æ˜¯ C++ æ ‡å‡†åº“ä¸­ &lt;numeric&gt; å¤´æ–‡ä»¶çš„ä¸€éƒ¨åˆ†ï¼Œä¸»è¦ç”¨äºè®¡ç®—ç»™å®šèŒƒå›´å†…å…ƒç´ çš„ç´¯ç§¯å’Œæˆ–å…¶ä»–ç´¯ç§¯æ“ä½œã€‚ åŸºæœ¬ç”¨æ³• accumulate å‡½æ•°çš„åŸå‹å¦‚ä¸‹ï¼š 12345template &lt;class InputIterator, class T&gt;T accumulate (InputIterator first, InputIterator last, T init);template &lt;class InputIterator, class T, class BinaryOperation&gt;T accumulate (InputIterator first, InputIterator last, T init, BinaryOperation binary_op); first å’Œ lastï¼šç¡®å®šè¦å¤„ç†çš„å…ƒç´ èŒƒå›´çš„è¿­ä»£å™¨ã€‚ initï¼šç´¯ç§¯çš„åˆå§‹å€¼ã€‚ binary_opï¼ˆå¯é€‰ï¼‰ï¼šä¸€ä¸ªäºŒå…ƒæ“ä½œï¼Œç”¨äºæ›¿ä»£é»˜è®¤çš„åŠ æ³•æ“ä½œã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ é»˜è®¤è¡Œä¸ºï¼šåœ¨ä¸æä¾› binary_op çš„æƒ…å†µä¸‹ï¼Œé»˜è®¤æ‰§è¡ŒåŠ æ³•æ“ä½œã€‚ è‡ªå®šä¹‰æ“ä½œï¼šé€šè¿‡æä¾› binary_opï¼Œå¯ä»¥æ‰§è¡Œä»»ä½•äºŒå…ƒæ“ä½œï¼Œå¦‚ä¹˜æ³•ã€æœ€å¤§å€¼ç­‰ã€‚ ç±»å‹åŒ¹é…ï¼šinit çš„ç±»å‹åº”ä¸å®¹å™¨å…ƒç´ ç±»å‹å…¼å®¹ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´æ„å¤–çš„ç»“æœæˆ–ç¼–è¯‘é”™è¯¯ã€‚ æ€§èƒ½ï¼šè¿™æ˜¯ä¸€ä¸ªçº¿æ€§æ—¶é—´å¤æ‚åº¦çš„æ“ä½œï¼Œå› ä¸ºå®ƒéå†æ•´ä¸ªèŒƒå›´ã€‚ ç¤ºä¾‹ä»£ç  ä»¥ä¸‹æ˜¯ä½¿ç”¨ accumulate çš„ä¸€ä¸ªç¤ºä¾‹ï¼Œå±•ç¤ºäº†åŸºæœ¬çš„ç´¯åŠ æ“ä½œå’Œè‡ªå®šä¹‰æ“ä½œï¼š 1234567891011121314151617#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;numeric&gt;int main() &#123; std::vector&lt;int&gt; nums = &#123;1, 2, 3, 4, 5&#125;; // é»˜è®¤ç´¯åŠ  int sum = std::accumulate(nums.begin(), nums.end(), 0); std::cout &lt;&lt; &quot;Sum: &quot; &lt;&lt; sum &lt;&lt; std::endl; // ä½¿ç”¨è‡ªå®šä¹‰æ“ä½œï¼ˆä¹˜æ³•ï¼‰ int product = std::accumulate(nums.begin(), nums.end(), 1, std::multiplies&lt;int&gt;()); std::cout &lt;&lt; &quot;Product: &quot; &lt;&lt; product &lt;&lt; std::endl; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç¬¬ä¸€ä¸ª accumulate è°ƒç”¨è®¡ç®—äº† nums çš„æ€»å’Œï¼Œè€Œç¬¬äºŒä¸ªè°ƒç”¨ä½¿ç”¨äº†ä¹˜æ³•æ“ä½œæ¥è®¡ç®—æ‰€æœ‰å…ƒç´ çš„ä¹˜ç§¯ã€‚"},{"title":"max_element","path":"/wiki/C++/algorithm/max_element.html","content":"åœ¨ C++ ä¸­ï¼Œmax_element æ˜¯ä¸€ä¸ªæ¥è‡ª &lt;algorithm&gt; å¤´æ–‡ä»¶çš„å‡½æ•°ï¼Œç”¨äºæŸ¥æ‰¾ç»™å®šèŒƒå›´å†…çš„æœ€å¤§å…ƒç´ ã€‚ä»¥ä¸‹æ˜¯å…³äº max_element çš„è¯¦ç»†è§£é‡Šï¼š åŸºæœ¬ç”¨æ³• å‡½æ•°åŸå‹: max_element å‡½æ•°çš„åŸºæœ¬åŸå‹ä¸º max_element(Iterator first, Iterator last)ï¼Œå…¶ä¸­ Iterator æ˜¯æŒ‡å‘å®¹å™¨å…ƒç´ çš„è¿­ä»£å™¨ã€‚ è¿”å›å€¼: å®ƒè¿”å›ä¸€ä¸ªæŒ‡å‘ç»™å®šèŒƒå›´ä¸­æœ€å¤§å…ƒç´ çš„è¿­ä»£å™¨ã€‚å¦‚æœæœ‰å¤šä¸ªç›¸åŒçš„æœ€å¤§å…ƒç´ ï¼Œè¿”å›ç¬¬ä¸€ä¸ªè¿™æ ·çš„å…ƒç´ çš„è¿­ä»£å™¨ã€‚ èŒƒå›´: ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯èŒƒå›´çš„å¼€å§‹ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯èŒƒå›´çš„ç»“æŸï¼ˆä¸åŒ…æ‹¬ï¼‰ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ å®¹å™¨ç±»å‹: max_element å¯ä»¥ç”¨äºä»»ä½•æä¾›éšæœºè®¿é—®è¿­ä»£å™¨çš„å®¹å™¨ï¼Œå¦‚ vectorã€dequeã€æ•°ç»„ç­‰ã€‚ æ¯”è¾ƒå‡½æ•°: å¯ä»¥æä¾›è‡ªå®šä¹‰çš„æ¯”è¾ƒå‡½æ•°æ¥å®šä¹‰â€œæœ€å¤§â€å…ƒç´ çš„æ¡ä»¶ã€‚ ç©ºèŒƒå›´: å¦‚æœèŒƒå›´ä¸ºç©ºï¼ˆå³ first ç­‰äº lastï¼‰ï¼Œåˆ™è¿”å› lastã€‚ æ€§èƒ½: æ—¶é—´å¤æ‚åº¦é€šå¸¸æ˜¯çº¿æ€§çš„ï¼Œå³ O(n)ï¼Œå…¶ä¸­ n æ˜¯èŒƒå›´å†…å…ƒç´ çš„æ•°é‡ã€‚ ç¤ºä¾‹ä»£ç  123456789101112131415#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;int main() &#123; std::vector&lt;int&gt; v = &#123;1, 3, 2, 8, 5&#125;; auto max_it = std::max_element(v.begin(), v.end()); if (max_it != v.end()) &#123; std::cout &lt;&lt; &quot;æœ€å¤§å…ƒç´ : &quot; &lt;&lt; *max_it &lt;&lt; std::endl; &#125; else &#123; std::cout &lt;&lt; &quot;å‘é‡ä¸ºç©º&quot; &lt;&lt; std::endl; &#125; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œmax_element ç”¨äºæŸ¥æ‰¾ vector ä¸­çš„æœ€å¤§å…ƒç´ ã€‚å¦‚æœæ‰¾åˆ°ï¼Œå®ƒæ‰“å°å‡ºè¯¥å…ƒç´ çš„å€¼ã€‚"},{"title":"lower_bound","path":"/wiki/C++/algorithm/lower_bound.html","content":"åœ¨ C++ ä¸­ï¼Œ&lt;algorithm&gt; å¤´æ–‡ä»¶ä¸­çš„lower_bound å‡½æ•°æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„ç®—æ³•ï¼Œå®ƒç”¨äºåœ¨å·²æ’åºçš„èŒƒå›´å†…æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸å°äºç»™å®šå€¼çš„å…ƒç´ ã€‚ä¸‹é¢æˆ‘å°†è¯¦ç»†è§£é‡Šè¿™ä¸ªå‡½æ•°çš„åŸºæœ¬ç”¨æ³•ã€ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ï¼Œä»¥åŠæä¾›ç¤ºä¾‹ä»£ç ã€‚ åŸºæœ¬ç”¨æ³• å‡½æ•°åŸå‹ï¼šlower_bound(ForwardIterator first, ForwardIterator last, const T&amp; val) å‚æ•°ï¼š first å’Œ last æ˜¯å®šä¹‰è¦æœç´¢çš„èŒƒå›´çš„è¿­ä»£å™¨ã€‚ val æ˜¯æˆ‘ä»¬è¦æŸ¥æ‰¾çš„å€¼ã€‚ è¿”å›å€¼ï¼šæŒ‡å‘èŒƒå›´ä¸­ç¬¬ä¸€ä¸ªä¸å°äº val çš„å…ƒç´ çš„è¿­ä»£å™¨ã€‚å¦‚æœæ‰€æœ‰å…ƒç´ éƒ½å°äº valï¼Œåˆ™è¿”å› lastã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ lower_bound éœ€è¦é¢„æ’åºçš„èŒƒå›´ã€‚å¦‚æœèŒƒå›´æ²¡æœ‰æ’åºï¼Œç»“æœæ˜¯æœªå®šä¹‰çš„ã€‚ å®ƒä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ç®—æ³•ï¼Œå› æ­¤æ—¶é—´å¤æ‚åº¦ä¸º O(log n)ï¼Œå…¶ä¸­ n æ˜¯èŒƒå›´å†…å…ƒç´ çš„æ•°é‡ã€‚ å¦‚æœèŒƒå›´ä¸­å­˜åœ¨å¤šä¸ªç­‰äº val çš„å…ƒç´ ï¼Œlower_bound ä¼šè¿”å›æŒ‡å‘è¿™äº›å…ƒç´ ä¸­ç¬¬ä¸€ä¸ªçš„è¿­ä»£å™¨ã€‚ å¯¹äºè‡ªå®šä¹‰ç±»å‹ï¼Œä½ å¯èƒ½éœ€è¦æä¾›æ¯”è¾ƒå‡½æ•°æˆ–é‡è½½æ¯”è¾ƒæ“ä½œç¬¦ã€‚ ç¤ºä¾‹ä»£ç  123456789101112131415161718#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;int main() &#123; std::vector&lt;int&gt; vec = &#123;1, 2, 4, 4, 5, 6, 7&#125;; // æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸å°äº4çš„å…ƒç´  auto it = std::lower_bound(vec.begin(), vec.end(), 4); if (it != vec.end()) &#123; std::cout &lt;&lt; &quot;ç¬¬ä¸€ä¸ªä¸å°äº4çš„å…ƒç´ æ˜¯: &quot; &lt;&lt; *it &lt;&lt; std::endl; &#125; else &#123; std::cout &lt;&lt; &quot;æ²¡æœ‰æ‰¾åˆ°ä¸å°äº4çš„å…ƒç´ &quot; &lt;&lt; std::endl; &#125; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åœ¨ä¸€ä¸ªå·²æ’åºçš„ vector ä¸­æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸å°äº4çš„å…ƒç´ ã€‚ç”±äºé›†åˆä¸­æœ‰ä¸¤ä¸ª4ï¼Œlower_bound è¿”å›æŒ‡å‘ç¬¬ä¸€ä¸ª4çš„è¿­ä»£å™¨ã€‚"},{"title":"tuple åŸºç¡€","path":"/wiki/C++/tuple/tuple åŸºç¡€.html","content":"åœ¨C++ä¸­ï¼Œtupleæ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å·¥å…·ï¼Œå®ƒå…è®¸ä½ å°†ä¸åŒç±»å‹çš„å…ƒç´ ç»„åˆæˆå•ä¸€çš„å¤åˆç±»å‹ã€‚è¿™é‡Œï¼Œæˆ‘å°†æ ¹æ®ä½ çš„è¦æ±‚ï¼Œä¾æ¬¡ä»‹ç»tupleçš„åŸºæœ¬ç”¨æ³•ã€ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ï¼Œä»¥åŠæä¾›ä¸€äº›ç¤ºä¾‹ä»£ç ã€‚ åŸºæœ¬ç”¨æ³• tupleæ˜¯æ ‡å‡†æ¨¡æ¿åº“ï¼ˆSTLï¼‰çš„ä¸€éƒ¨åˆ†ï¼Œä½äº&lt;tuple&gt;å¤´æ–‡ä»¶ä¸­ã€‚å®ƒå¯ä»¥å­˜å‚¨ä»»æ„æ•°é‡å’Œç±»å‹çš„å…ƒç´ ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æœ‰å…¶å¯¹åº”çš„ç±»å‹å’Œä½ç½®ã€‚tupleçš„å…ƒç´ å¯ä»¥é€šè¿‡std::getå‡½æ•°è®¿é—®ï¼Œå…¶ç´¢å¼•æ˜¯ä»0å¼€å§‹çš„ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ ç±»å‹å®‰å…¨ï¼šä¸æ•°ç»„æˆ–ç»“æ„ä½“ç›¸æ¯”ï¼Œtupleæä¾›äº†æ›´å¼ºçš„ç±»å‹å®‰å…¨æ€§ï¼Œå› ä¸ºå®ƒå¯ä»¥å­˜å‚¨ä¸åŒç±»å‹çš„å…ƒç´ ã€‚ ä¸å®šé•¿ï¼štupleå¯ä»¥åŒ…å«ä»»æ„æ•°é‡çš„å…ƒç´ ï¼Œä½¿å¾—å®ƒéå¸¸çµæ´»ã€‚ å…ƒç´ è®¿é—®ï¼šé€šè¿‡std::get&lt;ç´¢å¼•&gt;(tupleå¯¹è±¡)æ¥è®¿é—®å…ƒç´ ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç´¢å¼•æ˜¯åœ¨ç¼–è¯‘æ—¶ç¡®å®šçš„ï¼Œå› æ­¤ä¸èƒ½åŠ¨æ€åœ°åœ¨è¿è¡Œæ—¶å†³å®šè¦è®¿é—®çš„å…ƒç´ ç´¢å¼•ã€‚ ä¸ç»“æ„ä½“çš„æ¯”è¾ƒï¼šå¯¹äºç®€å•çš„æ•°æ®èšåˆï¼Œç»“æ„ä½“å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒä»¬æä¾›äº†æ›´æ¸…æ™°çš„è¯­ä¹‰ã€‚ç„¶è€Œï¼Œå¯¹äºéœ€è¦å­˜å‚¨ä¸åŒç±»å‹æ•°æ®æˆ–æ•°æ®ç»“æ„åœ¨è¿è¡Œæ—¶æ‰èƒ½ç¡®å®šçš„æƒ…å†µï¼Œtupleåˆ™æ›´åŠ é€‚ç”¨ã€‚ æ€§èƒ½è€ƒè™‘ï¼šå°½ç®¡tupleæä¾›äº†å¾ˆå¤§çš„çµæ´»æ€§ï¼Œä½†ä½¿ç”¨ä¸å½“å¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ç‰¹åˆ«æ˜¯é¢‘ç¹è®¿é—®tupleå…ƒç´ æ—¶ï¼Œåº”è€ƒè™‘æ˜¯å¦æœ‰æ›´åˆé€‚çš„æ•°æ®ç»“æ„ã€‚ ç¤ºä¾‹ä»£ç  åˆ›å»ºä¸€ä¸ªtupleå¹¶è®¿é—®å…¶å…ƒç´ ï¼š 123456789101112131415#include &lt;tuple&gt;#include &lt;iostream&gt;#include &lt;string&gt;int main() &#123; // åˆ›å»ºä¸€ä¸ªåŒ…å«æ•´æ•°ã€å­—ç¬¦ä¸²å’Œæµ®ç‚¹æ•°çš„tuple std::tuple&lt;int, std::string, double&gt; myTuple = std::make_tuple(10, &quot;Test&quot;, 3.14); // è®¿é—®å¹¶æ‰“å°tupleçš„å…ƒç´  std::cout &lt;&lt; &quot;æ•´æ•°: &quot; &lt;&lt; std::get&lt;0&gt;(myTuple) &lt;&lt; std::endl; std::cout &lt;&lt; &quot;å­—ç¬¦ä¸²: &quot; &lt;&lt; std::get&lt;1&gt;(myTuple) &lt;&lt; std::endl; std::cout &lt;&lt; &quot;æµ®ç‚¹æ•°: &quot; &lt;&lt; std::get&lt;2&gt;(myTuple) &lt;&lt; std::endl; return 0;&#125; è¿™æ®µä»£ç é¦–å…ˆåŒ…å«äº†å¿…è¦çš„å¤´æ–‡ä»¶ï¼Œç„¶ååˆ›å»ºäº†ä¸€ä¸ªtupleå¯¹è±¡myTupleï¼Œå®ƒåŒ…å«äº†ä¸€ä¸ªintç±»å‹ã€ä¸€ä¸ªstd::stringç±»å‹å’Œä¸€ä¸ªdoubleç±»å‹çš„å…ƒç´ ã€‚éšåé€šè¿‡std::getå‡½æ•°è®¿é—®å¹¶æ‰“å°äº†æ¯ä¸ªå…ƒç´ çš„å€¼ã€‚ tupleæ˜¯C++ä¸­ä¸€ä¸ªéå¸¸å¼ºå¤§ä¸”çµæ´»çš„å·¥å…·ï¼Œèƒ½å¤Ÿå¸®åŠ©ä½ å¤„ç†å¤æ‚çš„æ•°æ®ç»“æ„ã€‚ç„¶è€Œï¼Œåˆç†é€‰æ‹©æ•°æ®ç»“æ„å¯¹äºæé«˜ç¨‹åºæ€§èƒ½å’Œå¯è¯»æ€§éƒ½æ˜¯éå¸¸é‡è¦çš„ã€‚"},{"title":"unordered_map åŸºç¡€","path":"/wiki/C++/unordered_map/unordered_map åŸºç¡€.html","content":"unordered_map æ˜¯ C++ æ ‡å‡†æ¨¡æ¿åº“ï¼ˆSTLï¼‰ä¸­çš„ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å®¹å™¨ã€‚å®ƒè¢«ç”¨æ¥å­˜å‚¨é”®å€¼å¯¹ï¼Œå…¶ä¸­æ¯ä¸ªé”®éƒ½æ˜¯å”¯ä¸€çš„ã€‚è¿™ä¸ªå®¹å™¨ä½¿ç”¨å“ˆå¸Œè¡¨æ¥å®ç°ï¼Œå› æ­¤å…¶åœ¨å¹³å‡æƒ…å†µä¸‹ä¸ºé”®çš„æŸ¥æ‰¾ã€æ’å…¥å’Œåˆ é™¤æ“ä½œæä¾›äº†å¸¸æ•°æ—¶é—´å¤æ‚åº¦ï¼ˆO(1)ï¼‰ã€‚ä¸‹é¢æ˜¯å…³äº unordered_map çš„è¯¦ç»†ä»‹ç»ï¼š åŸºæœ¬ç”¨æ³• åˆå§‹åŒ–ï¼šå¯ä»¥é€šè¿‡ç›´æ¥å£°æ˜æˆ–ä½¿ç”¨åˆå§‹åŒ–åˆ—è¡¨æ¥åˆ›å»º unordered_mapã€‚ æ’å…¥å…ƒç´ ï¼šä½¿ç”¨ insert æ–¹æ³•æˆ– [] æ“ä½œç¬¦æ¥æ’å…¥æ–°å…ƒç´ ã€‚ è®¿é—®å…ƒç´ ï¼šä½¿ç”¨ [] æ“ä½œç¬¦æˆ– at æ–¹æ³•æ¥è®¿é—®å…ƒç´ ã€‚ åˆ é™¤å…ƒç´ ï¼šä½¿ç”¨ erase æ–¹æ³•æ¥åˆ é™¤å…ƒç´ ã€‚ æŸ¥æ‰¾å…ƒç´ ï¼šä½¿ç”¨ find æ–¹æ³•æ¥æŸ¥æ‰¾ç‰¹å®šé”®çš„å…ƒç´ ã€‚ å¤§å°å’Œå®¹é‡ï¼šä½¿ç”¨ size æ–¹æ³•è·å–å…ƒç´ ä¸ªæ•°ï¼Œempty æ£€æŸ¥æ˜¯å¦ä¸ºç©ºã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ æ€§èƒ½ï¼šåœ¨å¹³å‡æƒ…å†µä¸‹ï¼Œæ’å…¥ã€åˆ é™¤å’ŒæŸ¥æ‰¾æ“ä½œçš„æ—¶é—´å¤æ‚åº¦éƒ½æ˜¯ O(1)ã€‚ä½†åœ¨æœ€åæƒ…å†µä¸‹ï¼Œè¿™äº›æ“ä½œçš„æ—¶é—´å¤æ‚åº¦å¯èƒ½é€€åŒ–ä¸º O(n)ã€‚ å“ˆå¸Œå‡½æ•°ï¼šunordered_map ä½¿ç”¨å“ˆå¸Œå‡½æ•°å°†é”®æ˜ å°„åˆ°å“ˆå¸Œè¡¨ä¸­çš„æ¡¶ã€‚å¯¹äºè‡ªå®šä¹‰ç±»å‹ï¼Œå¯èƒ½éœ€è¦å®šä¹‰è‡ªå·±çš„å“ˆå¸Œå‡½æ•°ã€‚ ç¢°æ’å¤„ç†ï¼šå½“ä¸¤ä¸ªé”®æ˜ å°„åˆ°åŒä¸€ä¸ªæ¡¶æ—¶ï¼Œunordered_map é€šè¿‡é“¾è¡¨æ¥å¤„ç†ç¢°æ’ã€‚ æ— åºæ€§ï¼šå¦‚å…¶åæ‰€ç¤ºï¼Œunordered_map ä¸­çš„å…ƒç´ æ˜¯æ— åºå­˜å‚¨çš„ï¼Œä¸ä¿è¯å…ƒç´ çš„é¡ºåºã€‚ å”¯ä¸€é”®ï¼šæ¯ä¸ªé”®åœ¨ unordered_map ä¸­å¿…é¡»æ˜¯å”¯ä¸€çš„ã€‚ ç¤ºä¾‹ä»£ç  12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;unordered_map&gt;int main() &#123; std::unordered_map&lt;std::string, int&gt; umap; // æ’å…¥å…ƒç´  umap[&quot;apple&quot;] = 5; umap[&quot;banana&quot;] = 8; // è®¿é—®å…ƒç´  std::cout &lt;&lt; &quot;apple count: &quot; &lt;&lt; umap[&quot;apple&quot;] &lt;&lt; std::endl; // æŸ¥æ‰¾å…ƒç´  if (umap.find(&quot;banana&quot;) != umap.end()) &#123; std::cout &lt;&lt; &quot;banana found&quot; &lt;&lt; std::endl; &#125; // åˆ é™¤å…ƒç´  umap.erase(&quot;apple&quot;); // éå†å…ƒç´  for (auto&amp; item : umap) &#123; std::cout &lt;&lt; item.first &lt;&lt; &quot; =&gt; &quot; &lt;&lt; item.second &lt;&lt; std::endl; &#125; return 0;&#125; è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº† unordered_map çš„åŸºæœ¬ç”¨æ³•ï¼ŒåŒ…æ‹¬å¦‚ä½•æ’å…¥ã€è®¿é—®ã€æŸ¥æ‰¾å’Œåˆ é™¤å…ƒç´ ã€‚ä½¿ç”¨ unordered_map å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†å¤§é‡çš„æ•°æ®ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¿«é€ŸæŸ¥æ‰¾å’Œæ›´æ–°æ•°æ®çš„åœºåˆã€‚"},{"title":"getline","path":"/wiki/C++/string/getline.html","content":"getline æ˜¯ C++ ä¸­ç”¨äºä»è¾“å…¥æµä¸­è¯»å–å­—ç¬¦ä¸²çš„å‡½æ•°ï¼Œé€šå¸¸ä¸æ–‡ä»¶æµï¼ˆå¦‚ ifstreamï¼‰æˆ–æ ‡å‡†è¾“å…¥ï¼ˆå¦‚ cinï¼‰ä¸€èµ·ä½¿ç”¨ã€‚å®ƒå±äº &lt;string&gt; å¤´æ–‡ä»¶ã€‚ åŸºæœ¬ç”¨æ³• å®šä¹‰ï¼šgetline å‡½æ•°å®šä¹‰åœ¨ &lt;string&gt; å¤´æ–‡ä»¶ä¸­ï¼Œé€šå¸¸ä¸ &lt;iostream&gt; ä¸€èµ·ä½¿ç”¨ã€‚ å‡½æ•°åŸå‹ï¼šstd::getline(std::istream&amp; stream, std::string&amp; str, char delim)ã€‚ streamï¼šè¦è¯»å–çš„è¾“å…¥æµï¼Œå¦‚ cin æˆ–æ–‡ä»¶æµå¯¹è±¡ã€‚ strï¼šç”¨äºå­˜å‚¨è¯»å–åˆ°çš„å­—ç¬¦ä¸²çš„ std::string å¯¹è±¡ã€‚ delimï¼ˆå¯é€‰ï¼‰ï¼šä½œä¸ºè¡Œç»“æŸç¬¦çš„åˆ†éš”ç¬¦ï¼Œé»˜è®¤ä¸ºæ¢è¡Œç¬¦ ã€‚ è¯»å–è¡Œï¼šgetline ä¼šè¯»å–è¾“å…¥ç›´åˆ°é‡åˆ°åˆ†éš”ç¬¦ï¼ˆé»˜è®¤ä¸ºæ¢è¡Œç¬¦ï¼‰ï¼Œå¹¶å°†è¯»å–çš„å†…å®¹ï¼ˆä¸åŒ…æ‹¬åˆ†éš”ç¬¦ï¼‰å­˜å‚¨åœ¨ str ä¸­ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ å®‰å…¨æ€§ï¼šä¸ä½¿ç”¨ cin &gt;&gt; ç›´æ¥è¯»å–å­—ç¬¦ä¸²ç›¸æ¯”ï¼Œgetline å¯ä»¥é¿å…å› å­—ç¬¦ä¸²ä¸­çš„ç©ºæ ¼è€Œå¯¼è‡´çš„è¯»å–ä¸­æ–­ã€‚ çµæ´»æ€§ï¼šä½ å¯ä»¥è‡ªå®šä¹‰åˆ†éš”ç¬¦ï¼Œä¾¿äºå¤„ç†ä¸åŒæ ¼å¼çš„è¾“å…¥ã€‚ è¾“å…¥ç»“æŸï¼šå¦‚æœåœ¨è¾¾åˆ°åˆ†éš”ç¬¦ä¹‹å‰åˆ°è¾¾æ–‡ä»¶æœ«å°¾æˆ–å‘ç”Ÿé”™è¯¯ï¼Œgetline å°†è®¾ç½®è¾“å…¥æµçš„çŠ¶æ€æ ‡å¿—ã€‚ ç©ºè¡Œå¤„ç†ï¼šgetline ä¹Ÿèƒ½è¯»å–ç©ºè¡Œï¼Œæ­¤æ—¶è¿”å›çš„å­—ç¬¦ä¸²å°†ä¸ºç©ºã€‚ ç¤ºä¾‹ä»£ç  12345678910111213#include &lt;iostream&gt;#include &lt;string&gt;int main() &#123; std::string line; std::cout &lt;&lt; &quot;è¯·è¾“å…¥ä¸€äº›æ–‡æœ¬ï¼ˆåŒ…å«ç©ºæ ¼ï¼‰: &quot;; std::getline(std::cin, line); std::cout &lt;&lt; &quot;ä½ è¾“å…¥çš„æ–‡æœ¬æ˜¯: &quot; &lt;&lt; line &lt;&lt; std::endl; return 0;&#125; è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ std::getline ä»æ ‡å‡†è¾“å…¥è¯»å–ä¸€è¡Œæ–‡æœ¬ã€‚è¿™ç§æ–¹å¼å¯ä»¥æ­£ç¡®å¤„ç†å«æœ‰ç©ºæ ¼çš„å­—ç¬¦ä¸²è¾“å…¥ã€‚"},{"title":"sort","path":"/wiki/C++/algorithm/sort.html","content":"åŸºæœ¬ç”¨æ³• sort å‡½æ•°æ˜¯ C++ æ ‡å‡†åº“ä¸­çš„ä¸€ä¸ªå¼ºå¤§çš„æ’åºç®—æ³•ï¼Œé€šå¸¸å®ç°ä¸ºå¿«é€Ÿæ’åºã€‚è¿™ä¸ªå‡½æ•°å®šä¹‰åœ¨ &lt;algorithm&gt; å¤´æ–‡ä»¶ä¸­ã€‚sort å¯ä»¥å¯¹ä¸€ä¸ªåºåˆ—è¿›è¡Œæ’åºï¼Œä½¿ä¹‹æŒ‰ç…§å‡åºæ’åˆ—ã€‚åŸºæœ¬è¯­æ³•å¦‚ä¸‹ï¼š 12sort(RandomAccessIterator first, RandomAccessIterator last);sort(RandomAccessIterator first, RandomAccessIterator last, Compare comp); first å’Œ last æ˜¯å®šä¹‰å¾…æ’åºåºåˆ—çš„éšæœºè®¿é—®è¿­ä»£å™¨ã€‚ comp æ˜¯ä¸€ä¸ªå¯é€‰çš„æ¯”è¾ƒå‡½æ•°æˆ–è€…å‡½æ•°å¯¹è±¡ï¼Œç”¨äºè‡ªå®šä¹‰æ’åºé¡ºåºã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ æ—¶é—´å¤æ‚åº¦: sort çš„å¹³å‡æ—¶é—´å¤æ‚åº¦æ˜¯ O(n log n)ï¼Œå…¶ä¸­ n æ˜¯[first, last)èŒƒå›´å†…å…ƒç´ çš„æ•°é‡ã€‚ éšæœºè®¿é—®è¿­ä»£å™¨: sort éœ€è¦éšæœºè®¿é—®è¿­ä»£å™¨ï¼Œå› æ­¤é€‚ç”¨äº std::vectorã€std::dequeã€æ•°ç»„ç­‰ï¼Œä½†ä¸é€‚ç”¨äº std::listã€‚ ç¨³å®šæ€§: æ ‡å‡†åº“ä¸­çš„ sort ä¸ä¿è¯æ’åºçš„ç¨³å®šæ€§ã€‚å¦‚æœéœ€è¦ç¨³å®šæ’åºï¼Œå¯ä»¥ä½¿ç”¨ stable_sortã€‚ è‡ªå®šä¹‰æ’åº: é€šè¿‡æä¾›æ¯”è¾ƒå‡½æ•°ï¼Œå¯ä»¥å®ç°è‡ªå®šä¹‰æ’åºé€»è¾‘ã€‚ ç¤ºä¾‹ä»£ç  1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;int main() &#123; std::vector&lt;int&gt; v = &#123;4, 2, 5, 1, 3&#125;; // æŒ‰å‡åºæ’åº std::sort(v.begin(), v.end()); std::cout &lt;&lt; &quot;Sorted array: &quot;; for (int i : v) &#123; std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; &#125; std::cout &lt;&lt; std::endl; // ä½¿ç”¨è‡ªå®šä¹‰æ¯”è¾ƒå‡½æ•°è¿›è¡Œé™åºæ’åº std::sort(v.begin(), v.end(), [](int a, int b) &#123; return a &gt; b; &#125;); std::cout &lt;&lt; &quot;Sorted in descending order: &quot;; for (int i : v) &#123; std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; &#125; std::cout &lt;&lt; std::endl; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œé¦–å…ˆä½¿ç”¨ sort å°†å‘é‡ v æŒ‰å‡åºæ’åºï¼Œç„¶åä½¿ç”¨è‡ªå®šä¹‰æ¯”è¾ƒå‡½æ•°å°†å…¶æŒ‰é™åºæ’åºã€‚ è¿™é‡Œå±•ç¤ºçš„å°±æ˜¯ä½¿ç”¨è‡ªå®šä¹‰åŒ¿åå‡½æ•°é‡æ–°è§„å®šæ’åºè§„åˆ™"},{"title":"move","path":"/wiki/C++/utility/move.html","content":"åœ¨ C++ ä¸­ï¼Œâ€œmoveâ€æ“ä½œæ˜¯ä¸€ç§ä¼˜åŒ–æŠ€æœ¯ï¼Œä¸»è¦ç”¨äºå‡å°‘ä¸å¿…è¦çš„å¯¹è±¡å¤åˆ¶ï¼Œä»è€Œæé«˜ç¨‹åºæ€§èƒ½ã€‚å®ƒæ˜¯ C++11 æ ‡å‡†ä¸­å¼•å…¥çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§ã€‚ä¸‹é¢ï¼Œæˆ‘å°†åˆ†åˆ«ä»åŸºæœ¬ç”¨æ³•ã€ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ã€ä»¥åŠç¤ºä¾‹ä»£ç ä¸‰ä¸ªæ–¹é¢æ¥è®²è§£ move æ“ä½œã€‚ åŸºæœ¬ç”¨æ³• std::move æ˜¯ä¸€ä¸ªå‡½æ•°æ¨¡æ¿ï¼Œå®šä¹‰åœ¨å¤´æ–‡ä»¶ &lt;utility&gt; ä¸­ã€‚å®ƒå¯ä»¥å°†ä¸€ä¸ªå¯¹è±¡è½¬æ¢ä¸ºå³å€¼å¼•ç”¨ï¼Œä»è€Œä½¿å¾—è¯¥å¯¹è±¡çš„èµ„æºå¯ä»¥è¢«â€œç§»åŠ¨â€è€Œéå¤åˆ¶ã€‚ ä½¿ç”¨ move æ“ä½œæ—¶ï¼ŒåŸå¯¹è±¡ä¼šè½¬å…¥ä¸€ä¸ªä¸ç¡®å®šä½†æœ‰æ•ˆçš„çŠ¶æ€ã€‚è¿™æ„å‘³ç€ï¼ŒåŸå¯¹è±¡ä»ç„¶å¯ä»¥ææ„æˆ–èµ‹äºˆæ–°å€¼ï¼Œä½†å…¶å…·ä½“å†…å®¹ä¸å†ç¡®å®šã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ æ€§èƒ½æå‡ï¼šé€šè¿‡ç§»åŠ¨å¯¹è±¡è€Œéå¤åˆ¶å¯¹è±¡ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘å†…å­˜çš„åˆ†é…å’Œé‡Šæ”¾ï¼Œæé«˜ç¨‹åºçš„è¿è¡Œæ•ˆç‡ã€‚ æ‰€æœ‰æƒè½¬ç§»ï¼šæ‰§è¡Œ move æ“ä½œåï¼Œèµ„æºçš„æ‰€æœ‰æƒä»ä¸€ä¸ªå¯¹è±¡è½¬ç§»åˆ°å¦ä¸€ä¸ªå¯¹è±¡ï¼ŒåŸå¯¹è±¡ä¸å†æ‹¥æœ‰è¿™äº›èµ„æºã€‚ å®‰å…¨ä½¿ç”¨ï¼šä½¿ç”¨ move åï¼ŒåŸå§‹å¯¹è±¡å¤„äºä¸€ä¸ªä¸ç¡®å®šçš„çŠ¶æ€ã€‚å› æ­¤ï¼Œé™¤éé‡æ–°èµ‹å€¼ï¼Œå¦åˆ™ä¸åº”å†æ¬¡ä½¿ç”¨è¿™äº›è¢«ç§»åŠ¨çš„å¯¹è±¡ã€‚ å…¼å®¹æ€§ï¼šmove æ“ä½œåªé€‚ç”¨äºæ”¯æŒç§»åŠ¨è¯­ä¹‰çš„å¯¹è±¡ã€‚å¯¹äºä¸æ”¯æŒç§»åŠ¨è¯­ä¹‰çš„å¯¹è±¡ï¼Œmove æ“ä½œä¼šé€€åŒ–ä¸ºå¤åˆ¶æ“ä½œã€‚ ç¤ºä¾‹ä»£ç  ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ std::move çš„ç¤ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç§»åŠ¨æ„é€ å‡½æ•°å’Œç§»åŠ¨èµ‹å€¼æ“ä½œç¬¦æ¥å®ç°ä¸¤ä¸ªå¯¹è±¡ä¹‹é—´çš„èµ„æºè½¬ç§»ã€‚ 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;utility&gt;#include &lt;vector&gt;class MovableClass &#123;public: std::vector&lt;int&gt; data; // ç§»åŠ¨æ„é€ å‡½æ•° MovableClass(MovableClass&amp;&amp; other) noexcept : data(std::move(other.data)) &#123; std::cout &lt;&lt; &quot;Moved!&quot; &lt;&lt; std::endl; &#125; // ç§»åŠ¨èµ‹å€¼æ“ä½œç¬¦ MovableClass&amp; operator=(MovableClass&amp;&amp; other) noexcept &#123; if (this != &amp;other) &#123; data = std::move(other.data); std::cout &lt;&lt; &quot;Moved assignment!&quot; &lt;&lt; std::endl; &#125; return *this; &#125;&#125;;int main() &#123; MovableClass obj1; obj1.data = &#123;1, 2, 3&#125;; // ä½¿ç”¨ç§»åŠ¨æ„é€ å‡½æ•° MovableClass obj2 = std::move(obj1); // ä½¿ç”¨ç§»åŠ¨èµ‹å€¼æ“ä½œç¬¦ MovableClass obj3; obj3 = std::move(obj2); return 0;&#125; åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ç§»åŠ¨æ„é€ å‡½æ•°å’Œç§»åŠ¨èµ‹å€¼æ“ä½œç¬¦å®ç°äº† MovableClass å¯¹è±¡ä¹‹é—´çš„èµ„æºè½¬ç§»ã€‚æ³¨æ„ï¼Œåœ¨ç§»åŠ¨æ“ä½œä¹‹åï¼ŒåŸå¯¹è±¡ï¼ˆä¾‹å¦‚ obj1 å’Œ obj2ï¼‰è¿›å…¥äº†ä¸ç¡®å®šçš„çŠ¶æ€ï¼Œä½†å®ƒä»¬ä»ç„¶å¤„äºä¸€ä¸ªæœ‰æ•ˆçš„çŠ¶æ€ï¼Œå¯ä»¥è¢«ææ„æˆ–é‡æ–°èµ‹å€¼ã€‚"},{"title":"unordered_set åŸºç¡€","path":"/wiki/C++/unordered_set/unordered_set åŸºç¡€.html","content":"unordered_set æ˜¯ C++ ä¸­çš„æ ‡å‡†åº“å®¹å™¨ï¼Œå®ƒæ˜¯ä¸€ä¸ªå­˜å‚¨å”¯ä¸€å…ƒç´ çš„é›†åˆï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ çš„ä½ç½®ä¸ç”±å…ƒç´ çš„å€¼å†³å®šã€‚unordered_set åŸºäºå“ˆå¸Œè¡¨å®ç°ï¼Œå› æ­¤å®ƒèƒ½å¤Ÿæä¾›å¹³å‡å¸¸æ•°æ—¶é—´å¤æ‚åº¦çš„æ’å…¥ã€åˆ é™¤å’ŒæŸ¥æ‰¾æ“ä½œã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†ä»åŸºæœ¬ç”¨æ³•ã€ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ã€ä»¥åŠç¤ºä¾‹ä»£ç ä¸‰ä¸ªæ–¹é¢æ¥è®²è§£ unordered_setã€‚ åŸºæœ¬ç”¨æ³• å¤´æ–‡ä»¶ï¼šä½¿ç”¨ unordered_set å‰ï¼Œéœ€è¦åŒ…å«å¤´æ–‡ä»¶ &lt;unordered_set&gt;ã€‚ å£°æ˜ï¼šå¯ä»¥é€šè¿‡ std::unordered_set&lt;T&gt; å£°æ˜ä¸€ä¸ªé›†åˆï¼Œå…¶ä¸­ T æ˜¯å­˜å‚¨å…ƒç´ çš„ç±»å‹ã€‚ æ“ä½œï¼š .insert(value)ï¼šå‘é›†åˆä¸­æ’å…¥å…ƒç´  valueã€‚ .erase(value)ï¼šä»é›†åˆä¸­ç§»é™¤å…ƒç´  valueã€‚ .find(value)ï¼šæŸ¥æ‰¾å…ƒç´  valueï¼Œå¦‚æœæ‰¾åˆ°åˆ™è¿”å›ä¸€ä¸ªæŒ‡å‘è¯¥å…ƒç´ çš„è¿­ä»£å™¨ï¼Œå¦åˆ™è¿”å› end()ã€‚ .size()ï¼šè¿”å›é›†åˆä¸­å…ƒç´ çš„æ•°é‡ã€‚ .clear()ï¼šæ¸…ç©ºé›†åˆä¸­çš„æ‰€æœ‰å…ƒç´ ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ å”¯ä¸€æ€§ï¼šunordered_set ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½å¿…é¡»æ˜¯å”¯ä¸€çš„ï¼Œå³ä¸å…è®¸é‡å¤çš„å…ƒç´ ã€‚ æ— åºæ€§ï¼šå…ƒç´ åœ¨ unordered_set ä¸­çš„å­˜å‚¨æ˜¯æ— åºçš„ï¼Œä¸ä¿è¯ä»»ä½•ç‰¹å®šçš„å…ƒç´ é¡ºåºã€‚ æ€§èƒ½è€ƒè™‘ï¼šè™½ç„¶ unordered_set æä¾›äº†å¹³å‡å¸¸æ•°æ—¶é—´å¤æ‚åº¦çš„æ“ä½œæ€§èƒ½ï¼Œä½†æ˜¯å“ˆå¸Œå†²çªå’Œé‡å“ˆå¸Œæ“ä½œå¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ è‡ªå®šä¹‰ç±»å‹ï¼šå¦‚æœè¦åœ¨ unordered_set ä¸­å­˜å‚¨è‡ªå®šä¹‰ç±»å‹çš„å¯¹è±¡ï¼Œéœ€è¦å®šä¹‰ç›¸åº”çš„å“ˆå¸Œå‡½æ•°å’Œç›¸ç­‰åˆ¤æ–­å‡½æ•°ã€‚ ç¤ºä¾‹ä»£ç  ä¸‹é¢çš„ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ unordered_set æ¥å­˜å‚¨å’Œæ“ä½œä¸€ç»„æ•´æ•°ï¼š 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;unordered_set&gt;int main() &#123; std::unordered_set&lt;int&gt; mySet; // æ’å…¥å…ƒç´  mySet.insert(1); mySet.insert(2); mySet.insert(3); mySet.insert(4); mySet.insert(1); // é‡å¤æ’å…¥ï¼Œä¸ä¼šå¢åŠ æ–°å…ƒç´  std::cout &lt;&lt; &quot;The set contains: &quot;; for (int num : mySet) &#123; std::cout &lt;&lt; num &lt;&lt; &quot; &quot;; &#125; std::cout &lt;&lt; std::endl; // æŸ¥æ‰¾å…ƒç´  if (mySet.find(2) != mySet.end()) &#123; std::cout &lt;&lt; &quot;Element found&quot; &lt;&lt; std::endl; &#125; else &#123; std::cout &lt;&lt; &quot;Element not found&quot; &lt;&lt; std::endl; &#125; // åˆ é™¤å…ƒç´  mySet.erase(2); std::cout &lt;&lt; &quot;Element 2 removed&quot; &lt;&lt; std::endl; // æ˜¾ç¤ºé›†åˆå¤§å° std::cout &lt;&lt; &quot;The set size is: &quot; &lt;&lt; mySet.size() &lt;&lt; std::endl; return 0;&#125; è¿™æ®µä»£ç é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª unordered_set çš„å®ä¾‹ mySet å¹¶æ’å…¥äº†å‡ ä¸ªæ•´æ•°ã€‚æ³¨æ„åˆ°å°è¯•æ’å…¥é‡å¤çš„å…ƒç´ ï¼ˆå¦‚æ•°å­— 1ï¼‰ä¸ä¼šå¢åŠ æ–°å…ƒç´ ã€‚æ¥ç€ï¼Œä»£ç æ¼”ç¤ºäº†å¦‚ä½•æŸ¥æ‰¾ã€åˆ é™¤å…ƒç´ å’Œè·å–é›†åˆçš„å¤§å°ã€‚"},{"title":"upper_bound","path":"/wiki/C++/algorithm/upper_bound.html","content":"åŸºæœ¬ç”¨æ³• upper_bound å‡½æ•°åœ¨ C++ ä¸­ç”¨äºåœ¨æœ‰åºèŒƒå›´å†…æŸ¥æ‰¾å¤§äºç»™å®šå€¼çš„ç¬¬ä¸€ä¸ªå…ƒç´ ã€‚è¿™ä¸ªå‡½æ•°å±äº &lt;algorithm&gt; å¤´æ–‡ä»¶ã€‚å®ƒä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾ç®—æ³•ï¼Œå› æ­¤æ•ˆç‡è¾ƒé«˜ã€‚åŸºæœ¬è¯­æ³•å¦‚ä¸‹ï¼š 1upper_bound(ForwardIterator first, ForwardIterator last, const T&amp; val); first å’Œ last æ˜¯å®šä¹‰å¾…æœç´¢åŒºé—´çš„è¿­ä»£å™¨ã€‚ val æ˜¯æˆ‘ä»¬è¦æŸ¥æ‰¾çš„å€¼ã€‚ å‡½æ•°è¿”å›ä¸€ä¸ªæŒ‡å‘æ‰¾åˆ°çš„å…ƒç´ çš„è¿­ä»£å™¨ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œåˆ™è¿”å› lastã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ æ—¶é—´å¤æ‚åº¦: upper_bound çš„æ—¶é—´å¤æ‚åº¦æ˜¯ O(log n)ï¼Œå…¶ä¸­ n æ˜¯[first,last)[first, last)[first,last) èŒƒå›´å†…å…ƒç´ çš„æ•°é‡ã€‚ è¦æ±‚æœ‰åº: ä½¿ç”¨ upper_bound å‰ï¼Œç¡®ä¿èŒƒå›´ [first,last)[first, last)[first,last) å·²æ’åºã€‚ è¿”å›å€¼: å¦‚æœèŒƒå›´å†…æ‰€æœ‰å…ƒç´ éƒ½å°äºæˆ–ç­‰äº valï¼Œåˆ™è¿”å› lastã€‚ è‡ªå®šä¹‰æ¯”è¾ƒ: å¯ä»¥æä¾›è‡ªå®šä¹‰æ¯”è¾ƒå‡½æ•°ã€‚ ç¤ºä¾‹ä»£ç  123456789101112131415161718#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;int main() &#123; std::vector&lt;int&gt; v = &#123;1, 2, 4, 4, 5, 6, 7&#125;; // æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¤§äº 4 çš„å…ƒç´  auto it = std::upper_bound(v.begin(), v.end(), 4); if (it != v.end()) &#123; std::cout &lt;&lt; &quot;The first element greater than 4 is: &quot; &lt;&lt; *it &lt;&lt; std::endl; &#125; else &#123; std::cout &lt;&lt; &quot;No element greater than 4 found.&quot; &lt;&lt; std::endl; &#125; return 0;&#125; åœ¨æ­¤ä¾‹ä¸­ï¼Œupper_bound ä¼šè¿”å›æŒ‡å‘å€¼ 5 çš„è¿­ä»£å™¨ï¼Œå› ä¸º 5 æ˜¯æ•°ç»„ä¸­ç¬¬ä¸€ä¸ªå¤§äº 4 çš„å…ƒç´ ã€‚ å½“ç„¶upper_boundå’Œsortä¸€æ ·è¿˜å¯ä»¥è‡ªå®šä¹‰æ¯”è¾ƒçš„å†…å®¹ï¼Œä¸‹é¢æ˜¯å¦å¤–ä¸€ä¸ªä¾‹å­ï¼š å–è‡ª2023-12-08 Leetcode æ¯æ—¥ä¸€é¢˜è§£æ³• 123456789101112131415161718class Solution &#123;public: long long maxTaxiEarnings(int n, vector&lt;vector&lt;int&gt;&gt;&amp; rides) &#123; sort(rides.begin(),rides.end(), [](const vector&lt;int&gt; &amp;a, const vector&lt;int&gt; &amp;b)&#123; if(a[1]==b[1])return a[0] &lt; b[0]; return a[1] &lt; b[1]; &#125;); int p_num = rides.size(); vector&lt;long long&gt; dp(p_num+1); for(int i=0;i&lt;p_num;++i)&#123; int j = upper_bound(rides.begin(), rides.begin() + i, rides[i][0], [](int x, const vector&lt;int&gt; &amp;r)&#123; return x &lt; r[1]; &#125;) - rides.begin(); dp[i+1] = max(dp[i], dp[j]+rides[i][1]-rides[i][0]+rides[i][2]); &#125; return dp[p_num]; &#125;&#125;; è¯¥å†…åµŒè‡ªå®šä¹‰åŒ¿åå‡½æ•°ä¸»è¦å®ç°äº†å‘ŠçŸ¥upper_boundå‡½æ•°å¦‚ä½•å°†ä¼ å…¥çš„æ•´æ•°å’Œvectorä¸­çš„vectorç±»å‹æ¯”è¾ƒå¤§å°ã€‚"},{"title":"åŠ¨æ€è§„åˆ’ï¼ˆåŸºç¡€ç‰ˆï¼‰","path":"/wiki/LeetCode/ä¸“é¡¹è®­ç»ƒ/åŠ¨æ€è§„åˆ’ï¼ˆåŸºç¡€ç‰ˆï¼‰.html","content":"æ–æ³¢é‚£å¥‘ç±»å‹ Q1 é¢˜ç›®ä¼ é€é—¨ï¼š70. çˆ¬æ¥¼æ¢¯ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è®°å¿†åŒ–æœç´¢ç‰ˆï¼š 12345678910111213class Solution &#123;public: int climbStairs(int n) &#123; vector&lt;int&gt; dp(n+1,-1); dp[0] = 1;dp[1] = 1; function&lt;int(int)&gt; dfs = [&amp;](int now)&#123; if (dp[now]!=-1) return dp[now]; dp[now-1] = dfs(now-1); dp[now-2] = dfs(now-2); return dp[now-1] + dp[now-2]; &#125;; return dfs(n); &#125;&#125;; é€’æ¨ç‰ˆï¼š 1234567891011class Solution &#123;public: int climbStairs(int n) &#123; vector&lt;int&gt; dp(n+1,0); dp[0] = 1;dp[1] = 1; for(int i=2;i&lt;=n;++i)&#123; dp[i] = dp[i-1]+dp[i-2]; &#125; return dp[n]; &#125;&#125;; Q2 é¢˜ç›®ä¼ é€é—¨ï¼š509. æ–æ³¢é‚£å¥‘æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å’Œä¸Šä¸€é¢˜ä¸€æ¨¡ä¸€æ · è®°å¿†åŒ–æœç´¢ç‰ˆï¼š 1234567891011121314class Solution &#123;public: int fib(int n) &#123; vector&lt;int&gt; dp(n+2,-1); dp[0] = 0; dp[1] = 1; function&lt;int(int)&gt; dfs = [&amp;](int i)&#123; if (dp[i]!=-1) return dp[i]; dp[i-1] = dfs(i-1);dp[i-2] = dfs(i-2); return dp[i-1] + dp[i-2]; &#125;; int ans = dfs(n); return ans; &#125;&#125;; é€’æ¨ç‰ˆï¼š 1234567891011class Solution &#123;public: int fib(int n) &#123; vector&lt;int&gt; dp(n+2,0); dp[0] = 0;dp[1] = 1; for(int i=2;i&lt;=n;++i)&#123; dp[i] = dp[i-1]+dp[i-2]; &#125; return dp[n]; &#125;&#125;; çŸ©é˜µ åŠ¨æ€è§„åˆ’åœ¨å­—ç¬¦ä¸²çš„åº”ç”¨ æœ€é•¿é€’å¢å­åºåˆ— æœ€é•¿å…¬å…±å­åºåˆ— ä¹°å–è‚¡ç¥¨çš„æœ€ä½³æ—¶é—´/çŠ¶æ€æœº åŠ¨æ€è§„åˆ’åœ¨æ ‘çš„åº”ç”¨"},{"title":"å•è°ƒæ ˆ","path":"/wiki/LeetCode/ä¸“é¡¹è®­ç»ƒ/å•è°ƒæ ˆ.html","content":"åŸºç¡€ æœ¬æ¿å—æ•´ç†è‡ªçµèŒ¶å±±è‰¾åºœbç«™è§†é¢‘å•è°ƒæ ˆã€åŸºç¡€ç®—æ³•ç²¾è®² 26ã€‘_å“”å“©å“”å“©_bilibili é€šè¿‡ä¸€é“ä¾‹é¢˜è¿›è¡Œè®²è§£ï¼š é¢˜ç›®ä¼ é€é—¨ï¼š[739.æ¯æ—¥æ¸©åº¦ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰](https://leetcode.cn/problems/daily-temperatures/) æœ´ç´ ç®—æ³•å°±æ˜¯ï¼Œæˆ‘ä»¬ç›´æ¥è€ƒè™‘å¯¹äºæ¯ä¸ªå…ƒç´ éå†ï¼Œæ‰¾åˆ°ä»–å³è¾¹ç¬¬ä¸€ä¸ªæ¯”ä»–å¤§çš„æ•°ï¼Œä½†æ˜¯è¿™æ ·æ˜æ˜¾æ˜¯ä¸€ä¸ªO(n2)O(n^2)O(n2)å¤æ‚åº¦çš„ç®—æ³•ï¼Œå¦‚ä½•ä¼˜åŒ–å‘¢ï¼Ÿ é¦–å…ˆä¸éš¾æƒ³åˆ°çš„æ˜¯æˆ‘ä»¬å€’ç€è¿›è¡Œéå†ï¼Œå¦‚æœæˆ‘ä»¬çš„æ¸©åº¦åºåˆ—æ˜¯ 1,6,3,5,5,2,1,61,6,3,5,5,2,1,61,6,3,5,5,2,1,6,å¹¶ä¸”æˆ‘ä»¬å·²ç»éå†å®Œäº†æœ€åçš„4ä¸ªæ•°,é‚£ä¹ˆæˆ‘ä»¬ä¸éš¾æ¨å‡ºï¼Œå†åç»­çš„éå†ä¸­æ¯”å½“å‰å€¼å¤§çš„æ•°ä¸å¯èƒ½æ˜¯2ï¼Œ1ï¼ˆå› ä¸ºå‰é¢æœ‰ä¸€ä¸ª5æ›´å¤§ï¼‰ã€‚ æ€»ç»“ä¸€ä¸‹å½“å‰æƒ…å†µæ˜¯ï¼Œç”±äº5çš„å‡ºç°ï¼Œå³ä¾§2ï¼Œ1ä¸€å®šä¸ä¼šæˆä¸ºå·¦ä¾§æŸä¸ªæ•°ä¸‹ä¸€ä¸ªæ›´å¤§çš„æ•°äº†ã€‚æ‰€ä»¥å†åç»­çš„éå†ä¸­æˆ‘ä»¬å°±å¯ä»¥æŠŠè¿™ä¸¤ä¸ªæ•°å»æ‰ï¼Œä¸å»éå†ä»–ä»¬ä¸¤ä¸ªäº†ã€‚ ä»¥ä¸Šå°±æ˜¯å•è°ƒæ ˆç®—æ³•çš„æ ¸å¿ƒæ€æƒ³äº† ä¸‹é¢ä»‹ç»ä¸¤ç§å¸¸è§çš„å•è°ƒæ ˆå†™æ³•ï¼š ä»å³åˆ°å·¦ï¼ˆå°†ä¸‹ä¸€ä¸ªæœ€å¤§æ•°å­˜å…¥æ ˆä¸­ï¼‰ æ­¤æ—¶ç»´æŠ¤çš„æ ˆæ˜¯ä¸€ä¸ªé¡¶å°åº•å¤§çš„æ ˆï¼š 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; temperatures) &#123; int n = temperatures.size(); vector&lt;int&gt; ans(n); stack&lt;int&gt; st; for(int i=n-1;i&gt;=0;--i)&#123; int t = temperatures[i]; while (!st.empty()&amp;&amp;t &gt;= temperatures[st.top()]) st.pop(); if (!st.empty()) &#123; ans[i] = st.top() - i; &#125; st.push(i); &#125; return ans; &#125;&#125;; ä»å·¦åˆ°å³ï¼ˆå°†è¿˜æ²¡æœ‰æ‰¾åˆ°ä¸‹ä¸€ä¸ªæœ€å¤§çš„æ•°å­˜å…¥æ ˆä¸­ï¼‰ æ­¤æ—¶ç»´æŠ¤çš„æ ˆä»æ˜¯ä¸€ä¸ªé¡¶å°åº•å¤§çš„æ ˆï¼š 12345678910111213141516class Solution &#123;public: vector&lt;int&gt; dailyTemperatures(vector&lt;int&gt;&amp; temperatures) &#123; int n = temperatures.size(); vector&lt;int&gt; ans(n); stack&lt;int&gt; st; for(int i=0;i&lt;n;++i)&#123; int t = temperatures[i]; while (!st.empty() &amp;&amp; t &gt; temperatures[st.top()]) &#123; ans[st.top()] = i-st.top(); st.pop(); &#125; st.push(i); &#125; return ans; &#125;&#125;; å•è°ƒæ ˆé¢˜å• å•è°ƒæ ˆ æ¯æ—¥æ¸©åº¦ï¼ˆå•è°ƒæ ˆæ¨¡æ¿é¢˜ï¼‰ å•†å“æŠ˜æ‰£åçš„æœ€ç»ˆä»·æ ¼ ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´  I ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´  II é“¾è¡¨ä¸­çš„ä¸‹ä¸€ä¸ªæ›´å¤§èŠ‚ç‚¹ 1571 è‚¡ç¥¨ä»·æ ¼è·¨åº¦ 1709 è¡¨ç°è‰¯å¥½çš„æœ€é•¿æ—¶é—´æ®µ 1908 132 æ¨¡å¼ ~2000 ç¾ä¸½å¡” II 2072 ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´  IV 2175 ä½¿æ•°ç»„æŒ‰éé€’å‡é¡ºåºæ’åˆ— 2482 æ¯ä¸ªå…ƒç´ ä¸ºæœ€å¤§å€¼çš„æœ€å¤§èŒƒå›´ï¼ˆä¼šå‘˜é¢˜ï¼‰ çŸ©å½¢ç³»åˆ— æŸ±çŠ¶å›¾ä¸­æœ€å¤§çš„çŸ©å½¢ æœ€å¤§çŸ©å½¢ ç»Ÿè®¡å…¨ 1 å­çŸ©å½¢ 1845 å­—å…¸åºæœ€å° å»é™¤é‡å¤å­—æ¯ æ‰©å±•ï¼šé‡å¤ä¸ªæ•°ä¸è¶…è¿‡ limit ç§»æ‰ K ä½æ•°å­— ~1800 æ‰¾å‡ºæœ€å…·ç«äº‰åŠ›çš„å­åºåˆ— 1802 æ‹¼æ¥æœ€å¤§æ•° è´¡çŒ®æ³•ï¼ˆè®¡ç®—æ‰€æœ‰å­æ•°ç»„çš„â€¦â€¦çš„å’Œï¼‰ å­æ•°ç»„çš„æœ€å°å€¼ä¹‹å’Œ 1976 å­æ•°ç»„èŒƒå›´å’Œï¼ˆæœ€å¤§å€¼-æœ€å°å€¼ï¼‰ O(n)\\mathcal{O}(n)O(n) åšæ³• ~2000 å­æ•°ç»„æœ€å°ä¹˜ç§¯çš„æœ€å¤§å€¼ 2051 æ“ä½œä½¿å¾—åˆ†æœ€å¤§ 2397 å·«å¸ˆçš„æ€»åŠ›é‡å’Œï¼ˆæœ€å°å€¼*å’Œï¼‰ 2621"},{"title":"äºŒåˆ†æŸ¥æ‰¾","path":"/wiki/LeetCode/ä¸“é¡¹è®­ç»ƒ/äºŒåˆ†æŸ¥æ‰¾.html","content":"åŸºç¡€åŸç† æœ¬æ¿å—æ•´ç†è‡ªçµèŒ¶å±±è‰¾åºœbç«™è§†é¢‘äºŒåˆ†æŸ¥æ‰¾ çº¢è“æŸ“è‰²æ³•_å“”å“©å“”å“©_bilibili é€šè¿‡ä¸€é“ä¾‹é¢˜è¿›è¡Œè®²è§£ï¼š ä¾‹é¢˜è¿”å›æ•°ç»„ä¸­ç¬¬ä¸€ä¸ªâ‰¥8\\geq 8â‰¥8 æ•°å­—çš„ä½ç½®ï¼Œå¦‚æœæ‰€æœ‰æ•°éƒ½&lt;8&lt; 8&lt;8 åˆ™è¿”å›é•¿åº¦å€¼ éå¸¸æ˜æ˜¾è¿™é“é¢˜æˆ‘ä»¬å¯ä»¥é‡‡ç”¨äºŒåˆ†æŸ¥æ‰¾çš„æ–¹æ³•æ¥è§£å†³ï¼Œé¦–å…ˆæˆ‘ä»¬å…ˆè®²è§£ä¸€ä¸‹é—­åŒºé—´äºŒåˆ†è§£å†³è¿™é“é¢˜çš„å†™æ³•ï¼š é—­åŒºé—´äºŒåˆ†å†™æ³• å‡è®¾é˜Ÿåˆ—é•¿åº¦ä¸ºmï¼Œé¦–å…ˆè®¾å·¦æŒ‡é’ˆLæŒ‡å‘0ï¼Œå³æŒ‡é’ˆæŒ‡å‘m-1ã€‚æ¯æ¬¡å–ä¸­é—´çš„å…ƒç´ è¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœä¸­é—´çš„å…ƒç´ â‰¥8\\geq 8â‰¥8 åˆ™ R= mid-1å¦åˆ™L = mid+1ï¼ŒæŒç»­æ›´æ–°ç›´åˆ°L&gt;R 1234567891011121314#include&lt;bits/stdc++.h&gt;using namespace std;vector&lt;int&gt; arr = &#123;5,7,7,8,8,10&#125;;int main()&#123; int len = arr.size(); int l = 0, r = len-1; while(l&lt;=r)&#123; int mid = l+(r-l)/2; if (arr[mid]&gt;=8) r = mid-1; else l = mid+1; &#125; cout&lt;&lt;l; return 0;&#125; æ³¨æ„ï¼šäºŒåˆ†ä¸­æ±‚midçš„å†™æ³•ï¼Œåƒä¸Šé¢è¿™æ ·å†™èƒ½æœ‰æ•ˆçš„é¿å… è¿™é‡Œå…¶å®å°±å¯ä»¥æ„Ÿè§‰åˆ°ï¼Œåœ¨æ›´æ–°çš„è¿‡ç¨‹ä¸­ï¼Œæ— è®ºä½•æ—¶L-1æŒ‡å‘çš„ä¸€å®šæ˜¯&lt;8çš„æ•°R+1æŒ‡å‘çš„ä¸€å®šæ˜¯&gt;=8çš„æ•° å·¦é—­å³å¼€äºŒåˆ†å†™æ³• è¿™ä¸ªæ˜¯ç»å¸¸çœ‹åˆ°çš„äºŒåˆ†çš„å†™æ³• åŒæ ·å‡è®¾é˜Ÿåˆ—é•¿åº¦ä¸ºmï¼Œå·¦æŒ‡é’ˆLæŒ‡å‘0ï¼Œå³æŒ‡é’ˆæŒ‡å‘mï¼Œæ¯æ¬¡å–ä¸­é—´å…ƒç´ è¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœä¸­é—´å…ƒç´ â‰¥8\\geq 8â‰¥8åˆ™R = midï¼Œå¦åˆ™L = mid+1ï¼ŒæŒç»­æ›´æ–°ç›´åˆ° Lâ‰¥RL\\geq RLâ‰¥R 1234567891011121314#include&lt;bits/stdc++.h&gt;using namespace std;vector&lt;int&gt; arr = &#123;5,7,7,8,8,10&#125;;int main() &#123; int len = arr.size(); int l = 0, r = len; while(l&lt;r)&#123; int mid = l+(r-l)/2; if(arr[mid] &gt;= 8) r = mid; else l = mid+1; &#125; cout&lt;&lt; l; return 0;&#125; å¼€åŒºé—´äºŒåˆ†å†™æ³• åŒæ ·å‡è®¾é˜Ÿåˆ—é•¿åº¦ä¸ºmï¼Œå·¦æŒ‡é’ˆæŒ‡å‘-1ï¼Œå³æŒ‡é’ˆæŒ‡å‘mï¼Œæ¯æ¬¡å–ä¸­é—´å…ƒç´ è¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœä¸­é—´å…ƒç´ â‰¥8\\geq 8â‰¥8åˆ™R = mid, å¦åˆ™L = midï¼ŒæŒç»­æ›´æ–°ç›´åˆ°L+1â‰¥RL+1 \\geq RL+1â‰¥R 1234567891011121314#include&lt;bits/stdc++.h&gt;using namespace std;vector&lt;int&gt; arr = &#123;5,7,7,8,8,10&#125;;int main() &#123; int len = arr.size(); int l = -1, r = len; while(l+1&lt;r)&#123; int mid = l + (r-l)/2; if (mid&gt;=8) r = mid; else l = mid; &#125; cout &lt;&lt; r; return 0;&#125; ä¸€é“ä¾‹é¢˜ é¢˜ç›®ä¼ é€é—¨ï¼š34. åœ¨æ’åºæ•°ç»„ä¸­æŸ¥æ‰¾å…ƒç´ çš„ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªä½ç½® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å…¶ä¸­æ‰¾å½“å‰æ•°å‡ºç°çš„æœ€åä¸€ä¸ªï¼Œå°±æ˜¯æ‰¾æ¯”ä»–å¤§1çš„æ•°çš„ç¬¬ä¸€ä¸ªä½ç½®ï¼Œç„¶åæŠŠè¿™ä¸ªä½ç½®-1ã€‚ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; int len = nums.size(); int l = 0, r = len; while(l&lt;r)&#123; int mid = l+(r-l)/2; if (nums[mid]&gt;=target) r=mid; else l = mid+1; &#125; if (l == len || nums[l]!=target)&#123; vector&lt;int&gt; nw = &#123;-1,-1&#125;; return nw; &#125; vector&lt;int&gt; ans; ans.emplace_back(l); l = 0; r = len; while(l&lt;r)&#123; int mid= l+(r-l)/2; if(nums[mid]&gt;=target+1) r=mid; else l = mid+1; &#125; ans.emplace_back(l-1); return ans; &#125;&#125;; å½“ç„¶è¿™é“é¢˜ä½¿ç”¨lower_boundå’Œupper_boundä¹Ÿæ˜¯å¯ä»¥çš„ï¼Œå…·ä½“ä½¿ç”¨æ–¹æ³•è§C++éƒ¨åˆ†ã€‚ 123456789class Solution &#123;public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) &#123; auto it = lower_bound(nums.begin(),nums.end(),target); if (it == nums.end() || *it != target) return vector&lt;int&gt;&#123;-1,-1&#125;; auto it2 = upper_bound(nums.begin(), nums.end(), target); return vector&lt;int&gt;&#123;int(it-nums.begin()),int(it2-nums.begin())-1&#125;; &#125;&#125;; æ€»ç»“ å¯èƒ½çœ‹å®Œä¸Šé¢çš„å‡ ç§å†™æ³•ï¼Œè¿˜æ˜¯æ²¡æœ‰ç†è§£äºŒåˆ†çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Œè¿™é‡Œå°±æ¥æ€»ç»“ä¸€ä¸‹ã€‚å…¶å®é€šè¿‡è§‚å¯Ÿä¸Šé¢å¸¸è§çš„ä¸‰ç§å†™æ³•æˆ‘ä»¬ä¸éš¾å‘ç°ï¼ŒäºŒåˆ†çš„ç›®çš„æ˜¯åˆ¤æ–­æ•´ä¸ªåŒºé—´å’Œä¸€ä¸ªç›®æ ‡å€¼çš„å¤§å°å…³ç³»ï¼Œä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®çš„ï¼Œæˆ‘ä»¬éœ€è¦ç‰¢è®°åŒºé—´çš„å®šä¹‰ï¼åŒºé—´å†…çš„æ•°ï¼ˆä¸‹æ ‡ï¼‰éƒ½æ˜¯è¿˜æœªç¡®å®šä¸ target çš„å¤§å°å…³ç³»çš„ï¼Œæœ‰çš„æ˜¯ &lt; targetï¼Œæœ‰çš„æ˜¯ â‰¥ targetï¼›åŒºé—´å¤–çš„æ•°ï¼ˆä¸‹æ ‡ï¼‰éƒ½æ˜¯ç¡®å®šä¸ target çš„å¤§å°å…³ç³»çš„ã€‚ ç†è§£äº†ä¸Šè¿°å®šä¹‰ï¼Œåˆ™äºŒåˆ†æŸ¥æ‰¾ç®—æ³•ä¹Ÿå°±ç†è§£äº†ã€‚ äºŒåˆ†é¢˜å•ï¼ˆå³è¾¹æ•°å­—ä¸ºéš¾åº¦åˆ†ï¼‰ äºŒåˆ†ç­”æ¡ˆ H æŒ‡æ•° II ä½¿ç»“æœä¸è¶…è¿‡é˜ˆå€¼çš„æœ€å°é™¤æ•° 1542 å®Œæˆæ—…é€”çš„æœ€å°‘æ—¶é—´ 1641 æ¯ä¸ªå°å­©æœ€å¤šèƒ½åˆ†åˆ°å¤šå°‘ç³–æœ 1646 å‡†æ—¶åˆ°è¾¾çš„åˆ—è½¦æœ€å°æ—¶é€Ÿ 1676 åœ¨ D å¤©å†…é€è¾¾åŒ…è£¹çš„èƒ½åŠ› 1725 çˆ±åƒé¦™è•‰çš„ç‚ç‚ 1766 å¯ç§»é™¤å­—ç¬¦çš„æœ€å¤§æ•°ç›® 1913 åˆ¶ä½œ m æŸèŠ±æ‰€éœ€çš„æœ€å°‘å¤©æ•° 1946 å¯ä»¥åˆ°è¾¾çš„æœ€è¿œå»ºç­‘ 1962 æœ€å¤§åˆé‡‘æ•° 1981 é€ƒç¦»ç«ç¾ 2347 275. HæŒ‡æ•° é¢˜ç›®ä¼ é€é—¨ï¼š275. H æŒ‡æ•° II - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ äºŒåˆ†åˆ¤å®šæ¡ä»¶å°±æ˜¯å¦‚æœå½“å‰citationæ•°é‡ä»ç„¶å¤§äºç­‰äºåé¢çš„æ–‡ç« æ•°é‡å°±è¿˜å¯ä»¥å¾€å‰äºŒåˆ†ã€‚éœ€è¦æ³¨æ„çš„æ˜¯è¦åˆ¤æ–­ä¸€ä¸‹æ•°ç»„æœ‰æ²¡æœ‰è¶Šç•Œã€‚ å·¦é—­å³å¼€äºŒåˆ†å¦‚ä¸‹ï¼š 1234567891011121314151617class Solution &#123;public: int hIndex(vector&lt;int&gt;&amp; citations) &#123; int len = citations.size(); int l = 0,r = len; function&lt;bool(int)&gt; judge = [&amp;](int x)&#123; if (citations[x]&gt;=len-x) return true; else return false; &#125;; while(l &lt; r)&#123; int mid = l+(r-l)/2; if (judge(mid)) r = mid; else l = mid+1; &#125; return l==len?0:min(len-l,citations[l]); &#125;&#125;; 1283. ä½¿ç»“æœä¸è¶…è¿‡é˜ˆå€¼çš„æœ€å°é™¤æ•° é¢˜ç›®ä¼ é€é—¨ï¼š1283. ä½¿ç»“æœä¸è¶…è¿‡é˜ˆå€¼çš„æœ€å°é™¤æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸æ˜æ˜¾çš„äºŒåˆ†é¢˜ç›®ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯æ˜¯ä¸Šå–æ•´ï¼Œè¿™ç‚¹æœ‰ç‚¹å‘ã€‚ å¼€åŒºé—´äºŒåˆ†å¦‚ä¸‹ï¼š 1234567891011121314151617181920class Solution &#123;public: int smallestDivisor(vector&lt;int&gt;&amp; nums, int threshold) &#123; function&lt;bool(int)&gt; judge = [&amp;](int x)&#123; int ans = 0; for (auto &amp;num:nums) &#123; if (num%x) ans = ans+num/x+1; else ans += num/x; &#125; return ans&lt;=threshold; &#125;; int l=0,r=1000001; while (l+1&lt;r) &#123; int mid = l+(r-l)/2; if (judge(mid)) r=mid; else l=mid; &#125; return r; &#125;&#125;; 2187. å®Œæˆæ—…é€”çš„æœ€å°‘æ—¶é—´ é¢˜ç›®ä¼ é€é—¨ï¼š2187. å®Œæˆæ—…é€”çš„æœ€å°‘æ—¶é—´ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ é—­åŒºé—´äºŒåˆ†å¦‚ä¸‹ï¼š 1234567891011121314151617181920class Solution &#123;public: long long minimumTime(vector&lt;int&gt;&amp; time, int totalTrips) &#123; long long r = 100000000000003; long long l = 0; function&lt;bool(long long)&gt; judge=[&amp;](long long x)&#123; long long ans = 0; for (auto tim:time) &#123; ans += x / tim; &#125; return ans&gt;=(long long)totalTrips?true:false; &#125;; while (l &lt;= r) &#123; long long mid = l + (r - l)/2; if (judge(mid)) r = mid-1; else l = mid+1; &#125; return l; &#125;&#125;; 2226. æ¯ä¸ªå°å­©æœ€å¤šèƒ½åˆ†åˆ°å¤šå°‘ç³–æœ é¢˜ç›®ä¼ é€é—¨ï¼š2226. æ¯ä¸ªå°å­©æœ€å¤šèƒ½åˆ†åˆ°å¤šå°‘ç³–æœ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ é—­åŒºé—´äºŒåˆ†å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223class Solution &#123;public: int maximumCandies(vector&lt;int&gt;&amp; candies, long long k) &#123; auto maxit = max_element(candies.begin(),candies.end()); int max_ele = *maxit; function&lt;bool(long long)&gt; judge = [&amp;](int x) &#123; long long ans = 0; if (x==0) return true; for (auto candy:candies) &#123; ans += candy/x; &#125; return ans&gt;=k?true:false; &#125;; int l=0,r=max_ele; while (l&lt;=r) &#123; int mid = l + (r-l)/2; if(judge(mid)) l=mid+1; else r=mid-1; &#125; return r; &#125;&#125;; 1870. å‡†æ—¶åˆ°è¾¾çš„åˆ—è½¦æœ€å°æ—¶é€Ÿ é¢˜ç›®ä¼ é€é—¨ï¼š1870. å‡†æ—¶åˆ°è¾¾çš„åˆ—è½¦æœ€å°æ—¶é€Ÿ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å·¦é—­å³å¼€åŒºé—´äºŒåˆ†å¦‚ä¸‹ï¼š 12345678910111213141516171819202122class Solution &#123;public: int minSpeedOnTime(vector&lt;int&gt;&amp; dist, double hour) &#123; int len = dist.size(); function&lt;bool(int)&gt; judge = [&amp;](int v) &#123; int time=0; for(int i=0;i&lt;len-1;++i) &#123; time += dist[i]/v; if (dist[i]%v) time += 1; &#125; double fin_time = (double)time + (double) dist[len-1]/(double)v; return fin_time &lt;= hour?true:false; &#125;; int l = 1,r = 10000001; while (l&lt;r) &#123; int mid = l + (r-l)/2; if(judge(mid)) r = mid; else l = mid+1; &#125; return judge(l)?l:-1; &#125;&#125;; æ³¨æ„ï¼šæœ€åè¿”å›çš„æ—¶å€™è¦åˆ¤æ–­ä¸€ä¸‹å½“å‰é€Ÿåº¦èƒ½ä¸èƒ½æŒ‰è§„å®šåˆ°è¾¾ç›®çš„åœ° 1011. åœ¨ D å¤©å†…é€è¾¾åŒ…è£¹çš„èƒ½åŠ› é¢˜ç›®ä¼ é€é—¨ï¼š1011. åœ¨ D å¤©å†…é€è¾¾åŒ…è£¹çš„èƒ½åŠ› - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å·¦é—­å³å¼€åŒºé—´äºŒåˆ†ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 12345678910111213141516171819202122232425class Solution &#123;public: int shipWithinDays(vector&lt;int&gt;&amp; weights, int days) &#123; function&lt;bool(int)&gt; judge = [&amp;](int x)&#123; int cur=0,cur_day=1; for (auto weight:weights) &#123; if(cur+weight &lt;= x)&#123; cur = cur+weight; &#125; else &#123; cur_day++; cur = weight; &#125; &#125; return cur_day&lt;=days?true:false; &#125;; int l = *max_element(weights.begin(), weights.end()); int r = accumulate(weights.begin(),weights.end(),0)+1; while (l&lt;r) &#123; int mid = l + (r-l)/2; if (judge(mid)) r = mid; else l = mid+1; &#125; return l; &#125;&#125;; å¯ä»¥ç•™æ„ä¸€ä¸‹é‡Œé¢accumulateæ±‚å’Œå‡½æ•°çš„ç”¨æ³• 875. çˆ±åƒé¦™è•‰çš„ç‚ç‚ 875. çˆ±åƒé¦™è•‰çš„ç‚ç‚ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å¼€åŒºé—´äºŒåˆ†ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920class Solution &#123;public: int minEatingSpeed(vector&lt;int&gt;&amp; piles, int h) &#123; function&lt;bool(int)&gt; judge = [&amp;](int v)&#123; long long cos = 0; for(auto pile:piles)&#123; cos += pile/v; if(pile%v) cos += 1; &#125; return cos&lt;=(long long)h?true:false; &#125;; int l = 0,r = INT_MAX; while (l+1&lt;r) &#123; int mid = l + (r-l)/2; if(judge(mid)) r = mid; else l = mid; &#125; return r; &#125;&#125;; 1898. å¯ç§»é™¤å­—ç¬¦çš„æœ€å¤§æ•°ç›® é¢˜ç›®ä¼ é€é—¨ï¼š1898. å¯ç§»é™¤å­—ç¬¦çš„æœ€å¤§æ•°ç›® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åŒæ ·é¦–å…ˆè§‚å¯Ÿæ•°æ®èŒƒå›´ï¼Œ1e5çš„æ•°æ®èŒƒå›´ï¼Œé¢„æ„Ÿè¿™é“é¢˜åº”è¯¥ä½¿ç”¨äºŒåˆ†ã€‚ è¿™é“é¢˜æ¯”ä¹‹å‰çš„é¢˜ç›®è¦ç¨å¾®éš¾ä¸€ç‚¹ï¼Œéš¾ç‚¹ä¸»è¦é›†ä¸­åœ¨judgeå‡½æ•°çš„ä¹¦å†™ä¸Šï¼Œå…¶å®åªè¦åœ¨æ¯æ¬¡åˆ¤æ–­æ—¶ä½¿ç”¨ä¸€ä¸ªå“ˆå¸Œæ•°ç»„è®°å½•ä¸€ä¸‹å½“å‰å­—ç¬¦æœ‰æ²¡æœ‰è¢«åˆ é™¤ï¼Œå°±å¯ä»¥è¾ƒä¸ºç®€å•çš„è§£å†³è¿™é“é¢˜ã€‚ä»¥ä¸‹æä¾›ä¸¤ç§å¼€åŒºé—´äºŒåˆ†å†™æ³•ï¼Œæ³¨æ„åŒºåˆ†å…¶ä¸­ç»†èŠ‚ï¼Œå¦‚æœèƒ½å¤ŸåŒºåˆ†å‡ºæ¥å·®åˆ«ï¼Œé‚£æ­å–œï¼Œè¯´æ˜ä½ å¾ˆå¥½çš„æŒæ¡äº†çš„äºŒåˆ†æŸ¥æ‰¾ğŸ‡ã€‚ äºŒåˆ†ä¸‹æ ‡ï¼ˆåˆ¤æ–­åˆ°å½“å‰ä¸‹æ ‡ä¹‹å‰ï¼ˆåŒ…å«å½“å‰ä¸‹æ ‡ï¼‰èƒ½å¦è¢«removeï¼‰ 12345678910111213141516171819202122232425class Solution &#123;public: int maximumRemovals(string s, string p, vector&lt;int&gt;&amp; removable) &#123; int len = s.size(); function&lt;bool(int)&gt; judge=[&amp;](int x)&#123; vector&lt;bool&gt; vis(len,true); for (int i=0;i&lt;=x;++i) vis[removable[i]] = false; int pp = 0; for(int i=0;i&lt;len;++i)&#123; if (s[i]==p[pp]&amp;&amp;vis[i])&#123; pp++; if (pp == p.size()) return true; &#125; &#125; return false; &#125;; int l = -1, r = removable.size(); while (l+1&lt;r) &#123; int mid = l + (r-l)/2; if (judge(mid)) l = mid; else r = mid; &#125; return l+1; &#125;&#125;; äºŒåˆ†å‰nä¸ªremoveçš„è¿™ä¸ªnï¼š 12345678910111213141516171819202122232425class Solution &#123;public: int maximumRemovals(string s, string p, vector&lt;int&gt;&amp; removable) &#123; int len = s.size(); function&lt;bool(int)&gt; judge=[&amp;](int x)&#123; vector&lt;bool&gt; vis(len,true); for (int i=0;i&lt;x;++i) vis[removable[i]] = false; int pp = 0; for(int i=0;i&lt;len;++i)&#123; if (s[i]==p[pp]&amp;&amp;vis[i])&#123; pp++; if (pp == p.size()) return true; &#125; &#125; return false; &#125;; int l = -1, r = removable.size()+1; while (l+1&lt;r) &#123; int mid = l + (r-l)/2; if (judge(mid)) l = mid; else r = mid; &#125; return l; &#125;&#125;; 1482. åˆ¶ä½œ m æŸèŠ±æ‰€éœ€çš„æœ€å°‘å¤©æ•° é¢˜ç›®ä¼ é€é—¨ï¼š1482. åˆ¶ä½œ m æŸèŠ±æ‰€éœ€çš„æœ€å°‘å¤©æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åŒæ ·é¦–å…ˆè§‚å¯Ÿæ•°æ®èŒƒå›´ï¼Œ1e5çš„æ•°æ®èŒƒå›´ï¼Œé¢„æ„Ÿè¿™é“é¢˜åº”è¯¥ä½¿ç”¨äºŒåˆ†ã€‚ åŒä¸Šï¼Œå°±æ˜¯éœ€è¦è®¾è®¡ä¸€ä¸‹judgeå‡½æ•° 123456789101112131415161718192021222324252627class Solution &#123;public: int minDays(vector&lt;int&gt;&amp; bloomDay, int m, int k) &#123; auto judge = [&amp;](int x) &#123; int cnt=0,cur=0; for (auto bloom:bloomDay) &#123; if (bloom &lt;= x) &#123; cur++; if (cur == k) &#123; cur = 0; cnt ++; if (cnt == m) return true; &#125; &#125; else cur = 0; &#125; return false; &#125;; int l = 1, r = *max_element(bloomDay.begin(),bloomDay.end()); while (l &lt;= r) &#123; int mid = l + (r-l)/2; if (judge(mid)) r=mid-1; else l=mid+1; &#125; return judge(l)?l:-1; &#125;&#125;; 1642. å¯ä»¥åˆ°è¾¾çš„æœ€è¿œå»ºç­‘ é¢˜ç›®ä¼ é€é—¨ï¼š1642. å¯ä»¥åˆ°è¾¾çš„æœ€è¿œå»ºç­‘ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åŒæ ·é¦–å…ˆè§‚å¯Ÿæ•°æ®èŒƒå›´ï¼Œ1e5çš„æ•°æ®èŒƒå›´ï¼Œé¢„æ„Ÿè¿™é“é¢˜åº”è¯¥ä½¿ç”¨äºŒåˆ†ã€‚ å·¦é—­å³å¼€åŒºé—´äºŒåˆ†å†™æ³•å¦‚ä¸‹æ‰€ç¤ºï¼š 12345678910111213141516171819202122class Solution &#123;public: int furthestBuilding(vector&lt;int&gt;&amp; heights, int bricks, int ladders) &#123; auto judge = [&amp;](int x) &#123; vector&lt;int&gt; h_diffs; for(int i=1;i&lt;=x;++i)&#123; if (heights[i] &gt; heights[i-1]) h_diffs.emplace_back(heights[i]-heights[i-1]); &#125; if (ladders&gt;=h_diffs.size()) return true; sort(h_diffs.begin(),h_diffs.end()); int sum_diff = accumulate(h_diffs.begin(),h_diffs.end()-ladders,0); return sum_diff &lt;= bricks?true:false; &#125;; int l=0,r=heights.size(); while(l&lt;r)&#123; int mid = l + (r-l)/2; if (judge(mid)) l = mid+1; else r=mid; &#125; return l-1; &#125;&#125;; æ³¨æ„ï¼šè¯¥é¢˜åˆæ³•åŒºé—´åœ¨å·¦è¾¹ï¼Œæ‰€ä»¥æœ€ç»ˆå·¦é—­å³å¼€åŒºé—´äºŒåˆ†è¿”å›å€¼åº”è¯¥æ˜¯l-1 2861. æœ€å¤§åˆé‡‘æ•° é¢˜ç›®ä¼ é€é—¨ï¼š2861. æœ€å¤§åˆé‡‘æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ é¢˜ç›®ä¸­è§„å®šåªèƒ½ä½¿ç”¨ä¸€ä¸ªæœºå™¨ç”Ÿäº§æ‰€æœ‰åˆé‡‘ï¼Œæ‰€ä»¥å°±éå¸¸ç®€å•äº†ï¼Œå’Œä¹‹å‰çš„äºŒåˆ†å·®ä¸å¤šï¼Œåªä¸è¿‡ä¸­é—´è®¡ç®—å¼€é”€çš„æ—¶å€™ä¼šçˆ†intæ‰€ä»¥è®¾ç½®æˆlong longã€‚ å·¦å¼€å³é—­äºŒåˆ†ä¹¦å†™å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223class Solution &#123;public: int maxNumberOfAlloys(int n, int k, int budget, vector&lt;vector&lt;int&gt;&gt;&amp; composition, vector&lt;int&gt;&amp; stock, vector&lt;int&gt;&amp; cost) &#123; auto judge = [&amp;](int x) &#123; for(int i=0; i&lt;k; ++i) &#123; long long cost_all = 0; for(int j=0; j&lt;n; ++j) &#123; cost_all += max((long long)0, ((long long)x*composition[i][j]-stock[j]))*cost[j]; if(cost_all &gt; budget) break; &#125; if (cost_all &lt;= budget) return true; &#125; return false; &#125;; int l = 0, r = INT_MAX; while (l&lt;r) &#123; int mid = l + (r-l)/2; if(judge(mid)) l = mid+1; else r = mid; &#125; return l-1; &#125;&#125;; 2258. é€ƒç¦»ç«ç¾ è¿™é“é¢˜è¿˜æ˜¯éå¸¸æœ‰æ„æ€çš„ï¼Œæ˜¯ä¸€é“bfså’ŒäºŒåˆ†çš„ç»“åˆï¼Œé¦–å…ˆæˆ‘ä»¬å…ˆä½¿ç”¨bfsé¢„å¤„ç†ä¸€éå°†æ¯ä¸ªæ ¼å­ç€ç«çš„æ—¶é—´éƒ½å…ˆå¤„ç†å‡ºæ¥ã€‚ç„¶åæˆ‘ä»¬ä½¿ç”¨äºŒåˆ†ï¼ŒäºŒåˆ†ç­‰å¾…æ—¶é—´ï¼ŒäºŒåˆ†åˆ¤æ–­å‡½æ•°å°±æ˜¯ç¬¬äºŒæ¬¡bfsï¼Œåˆ¤æ–­åœ¨å½“å‰ç­‰å¾…æ—¶é—´ä¸‹èƒ½å¦è¿›å…¥å®‰å…¨å±‹ã€‚æ‰€ä»¥ä¸€å…±éœ€è¦æä¾›ä¸¤ä¸ªbfså‡½æ•°ã€‚ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class Solution &#123;public: int maximumMinutes(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; vector&lt;vector&lt;int&gt;&gt; dirs = &#123;&#123;1,0&#125;,&#123;-1,0&#125;,&#123;0,1&#125;,&#123;0,-1&#125;&#125;; int n = grid.size(),m = grid[0].size(); vector&lt;vector&lt;int&gt;&gt; tim_burn(n,vector&lt;int&gt;(m,INT_MAX)); auto judge = [&amp;](int x,int y) &#123; if (x&lt;0||y&lt;0||x&gt;=n||y&gt;=m) return false; if (grid[x][y] == 2) return false; return true; &#125;; auto bfs1 = [&amp;](int x, int y)&#123; &#125;; auto bfs2 = [&amp;](int stay_time)&#123; vector&lt;vector&lt;int&gt;&gt; reach(n,vector&lt;int&gt;(m,INT_MAX)); if (stay_time &gt; tim_burn[0][0]) return false; queue&lt;vector&lt;int&gt;&gt; que; que.push(vector&lt;int&gt;&#123;0,0&#125;); reach[0][0] = stay_time; while (!que.empty()) &#123; vector&lt;int&gt; nw = que.front();que.pop(); for(auto dir:dirs) &#123; if (judge(nw[0]+dir[0],nw[1]+dir[1])) &#123; int nx = nw[0]+dir[0], ny = nw[1]+dir[1]; if (nx == n-1 &amp;&amp; ny == m-1 &amp;&amp; tim_burn[nx][ny] &gt;= reach[nw[0]][nw[1]]+1) return true; if (tim_burn[nx][ny] &gt; reach[nw[0]][nw[1]]+1) &#123; if (reach[nx][ny] &gt; reach[nw[0]][nw[1]]+1)&#123; reach[nx][ny] = reach[nw[0]][nw[1]]+1; que.push(vector&lt;int&gt;&#123;nx,ny&#125;); &#125; &#125; &#125; &#125; &#125; return false; &#125;; queue&lt;vector&lt;int&gt;&gt; que1; for(int i=0;i&lt;n;++i)&#123; for(int j=0;j&lt;m;++j)&#123; if (grid[i][j]==1) &#123; tim_burn[i][j] = 0; que1.push(vector&lt;int&gt;&#123;i,j&#125;); &#125; &#125; &#125; while (!que1.empty()) &#123; vector&lt;int&gt; nw = que1.front();que1.pop(); for(auto dir:dirs) &#123; if (judge(nw[0]+dir[0],nw[1]+dir[1])) &#123; int nx = nw[0]+dir[0], ny = nw[1]+dir[1]; if (tim_burn[nx][ny] &gt; tim_burn[nw[0]][nw[1]]+1) &#123; tim_burn[nx][ny] = tim_burn[nw[0]][nw[1]]+1; que1.push(vector&lt;int&gt;&#123;nx,ny&#125;); &#125; &#125; &#125; &#125; // close interval int l = 0, r = 1000000000; while(l &lt;= r) &#123; int mid = l + (r-l)/2; if(bfs2(mid)) l = mid+1; else r = mid-1; &#125; return bfs2(1000000000)?1000000000:l-1; &#125;&#125;; æ³¨æ„ç¬¬ä¸€æ¬¡é¢„å¤„ç†çš„æ—¶å€™å°±å°†æ‰€æœ‰çš„ç«æºéƒ½å‹å…¥bfsé˜Ÿåˆ—ä¸­é¢„å¤„ç†ä¸€æ¬¡å°±è¡Œäº†ï¼Œä¸è¦æ¯æ¬¡å‘ç°ä¸€ä¸ªç«æºå°±bfsä¸€æ¬¡ï¼Œéå¸¸çš„æµªè´¹æ—¶é—´ã€‚ æœ€å°åŒ–æœ€å¤§å€¼ åˆ†é…ç»™å•†åº—çš„æœ€å¤šå•†å“çš„æœ€å°å€¼ 1886 è¢‹å­é‡Œæœ€å°‘æ•°ç›®çš„çƒ 1940 æœ€å°åŒ–æ•°ç»„ä¸­çš„æœ€å¤§å€¼ 1965 æ‰“å®¶åŠ«èˆ IV 2081 æ°´ä½ä¸Šå‡çš„æ³³æ± ä¸­æ¸¸æ³³ 2097 æœ€å°åŒ–æ•°å¯¹çš„æœ€å¤§å·®å€¼ 2155 æœ€å°åŒ–ä¸¤ä¸ªæ•°ç»„ä¸­çš„æœ€å¤§å€¼ 2302 æœ€å¤§åŒ–æœ€å°å€¼ ä¸¤çƒä¹‹é—´çš„ç£åŠ› 1920 æœ€å¤§åˆé‡‘æ•° 1981 ç¤¼ç›’çš„æœ€å¤§ç”œèœœåº¦ 2021 æ‰¾å‡ºæœ€å®‰å…¨è·¯å¾„ 2154 æœ€å¤§åŒ–åŸå¸‚çš„æœ€å°ä¾›ç”µç«™æ•°ç›® 2236"},{"title":"assign","path":"/wiki/C++/vector/assign.html","content":"åœ¨C++ä¸­ï¼Œstd::vector ç±»çš„ assign æ–¹æ³•ç”¨äºåœ¨å‘é‡ä¸­è®¾ç½®æ–°å†…å®¹ï¼Œæ›¿æ¢å…¶å½“å‰å†…å®¹ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†çš„è§£é‡Šï¼š åŸºæœ¬ç”¨æ³• assign æ–¹æ³•æœ‰å‡ ç§é‡è½½å½¢å¼ï¼Œå…è®¸ä½ ç”¨ä¸åŒçš„æ–¹å¼è®¾ç½® vector çš„å†…å®¹ï¼š assign(size_type n, const T&amp; val)ï¼šå°†å‘é‡çš„å†…å®¹æ›¿æ¢ä¸º n ä¸ª val çš„å‰¯æœ¬ã€‚ assign(InputIterator first, InputIterator last)ï¼šä½¿ç”¨ä¸¤ä¸ªè¿­ä»£å™¨ first å’Œ last æŒ‡å®šçš„èŒƒå›´æ¥æ›¿æ¢å‘é‡çš„å†…å®¹ã€‚ assign(initializer_list&lt;T&gt; il)ï¼šä½¿ç”¨åˆå§‹åŒ–åˆ—è¡¨ il ä¸­çš„å…ƒç´ æ¥æ›¿æ¢å‘é‡çš„å†…å®¹ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ assign æ–¹æ³•æ”¹å˜å‘é‡çš„å¤§å°å’Œå†…å®¹ã€‚ å¦‚æœæ–°å¤§å°å¤§äºå½“å‰å¤§å°ï¼Œä¼šåˆ›å»ºæ–°å…ƒç´ ã€‚å¦‚æœæ–°å¤§å°å°äºå½“å‰å¤§å°ï¼Œåˆ™å¤šä½™çš„å…ƒç´ ä¼šè¢«é”€æ¯ã€‚ ä½¿ç”¨è¿­ä»£å™¨èŒƒå›´é‡è½½æ—¶ï¼ŒèŒƒå›´ [first, last) åº”æœ‰æ•ˆä¸”ä¸åº”æŒ‡å‘åŒä¸€ vector ä¸­çš„å…ƒç´ ã€‚ åˆ†é…æ–°å†…å®¹å¯èƒ½å¯¼è‡´æ‰€æœ‰ç°æœ‰çš„è¿­ä»£å™¨ã€å¼•ç”¨å’ŒæŒ‡é’ˆå¤±æ•ˆã€‚ ç¤ºä¾‹ä»£ç  123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;vector&gt;int main() &#123; std::vector&lt;int&gt; vec; // ä½¿ç”¨åˆå§‹å€¼èµ‹å€¼ vec.assign(4, 100); for (int i : vec) &#123; std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; // è¾“å‡º: 100 100 100 100 &#125; std::cout &lt;&lt; &quot; &quot;; // ä½¿ç”¨è¿­ä»£å™¨èµ‹å€¼ std::vector&lt;int&gt; anotherVec&#123;1, 2, 3, 4, 5&#125;; vec.assign(anotherVec.begin(), anotherVec.end()); for (int i : vec) &#123; std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; // è¾“å‡º: 1 2 3 4 5 &#125; std::cout &lt;&lt; &quot; &quot;; // ä½¿ç”¨åˆå§‹åŒ–åˆ—è¡¨èµ‹å€¼ vec.assign(&#123;10, 20, 30&#125;); for (int i : vec) &#123; std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; // è¾“å‡º: 10 20 30 &#125; std::cout &lt;&lt; &quot; &quot;; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¸åŒçš„ assign æ–¹æ³•æ¥è®¾ç½® vector çš„å†…å®¹ã€‚æ¯ç§æ–¹æ³•éƒ½æ¸…é™¤åŸæœ‰å†…å®¹ï¼Œå¹¶æ ¹æ®æä¾›çš„æ–°å€¼è®¾ç½® vectorã€‚"},{"title":"ç¬¬ 378 åœºå‘¨èµ›","path":"/wiki/LeetCode/å‘¨èµ›/ç¬¬ 378 åœºå‘¨èµ›.html","content":"æ€»ç»“ éšç€2023å¹´çš„å²æœˆæ¸æ¸èµ°å‘å°¾å£°ï¼Œæœ€åä¸€åœºå‘¨èµ›ä¹Ÿæ‚„ç„¶è½å¹•ã€‚è™½ç„¶æˆ‘æ²¡æœ‰åŠ å…¥è¿™åœºæ—¶å…‰çš„èˆè¹ˆï¼Œä½†å®ƒçš„ç»“æŸä¹Ÿæ ‡å¿—ç€ä¸€ä¸ªæ–°çš„å¼€å§‹ã€‚æˆ‘æ»¡æ€€æœŸå¾…åœ°å±•æœ›ç€æœªæ¥ï¼Œå¸Œæœ›åœ¨æ–°çš„æ—¥å­é‡Œï¼Œèƒ½å¤Ÿè¸å…¥æ¯ä¸€åœºå‘¨èµ›çš„å¾ç¨‹ï¼Œä¸æ—¶é—´èµ›è·‘ï¼Œä¸æŒ‘æˆ˜å…±èˆã€‚2024ï¼ŒåŠ æ²¹ï¼ é¢˜ç›®åç§°1 é¢˜ç›®ä¼ é€é—¨ï¼š é¢˜ç›®åç§°2 é¢˜ç›®ä¼ é€é—¨ï¼š é¢˜ç›®åç§°3 é¢˜ç›®ä¼ é€é—¨ï¼š é¢˜ç›®åç§°4 é¢˜ç›®ä¼ é€é—¨ï¼š"},{"title":"emplace_back","path":"/wiki/C++/vector/emplace_back.html","content":"std::vector çš„ emplace_back æ–¹æ³•æ˜¯ C++11 å¼•å…¥çš„ä¸€é¡¹åŠŸèƒ½ï¼Œå®ƒç”¨äºåœ¨å‘é‡çš„æœ«å°¾ç›´æ¥æ„é€ æ–°å…ƒç´ ï¼Œè€Œä¸æ˜¯å…ˆæ„é€ ç„¶åå¤åˆ¶æˆ–ç§»åŠ¨åˆ°å‘é‡ä¸­ã€‚è¿™å¯ä»¥æé«˜æ•ˆç‡ï¼Œå°¤å…¶æ˜¯å¯¹äºé‚£äº›ä¸æ”¯æŒå¤åˆ¶æˆ–æ•ˆç‡è¾ƒä½çš„å¤åˆ¶æ“ä½œçš„å¯¹è±¡ã€‚ åŸºæœ¬ç”¨æ³• emplace_back(args...)ï¼šæ­¤æ–¹æ³•æ¥å—ä¸å…ƒç´ ç±»å‹æ„é€ å‡½æ•°ç›¸åŒçš„å‚æ•°é›†ï¼Œå¹¶åœ¨å‘é‡æœ«å°¾ç›´æ¥æ„é€ ä¸€ä¸ªæ–°å…ƒç´ ã€‚è¿™æ„å‘³ç€å®ƒå¯ä»¥é¿å…é¢å¤–çš„å¤åˆ¶æˆ–ç§»åŠ¨æ“ä½œã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ ç›´æ¥æ„é€ ï¼šä¸ push_back ä¸åŒï¼Œemplace_back ç›´æ¥åœ¨å‘é‡çš„å†…å­˜ç©ºé—´ä¸­æ„é€ å…ƒç´ ï¼Œè¿™å¯ä»¥æé«˜æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§å‹å¯¹è±¡æˆ–æ‹¥æœ‰å¤æ‚ç§»åŠ¨è¯­ä¹‰çš„å¯¹è±¡ã€‚ å‚æ•°è½¬å‘ï¼šå®ƒå°†å‚æ•°å®Œç¾è½¬å‘åˆ°å…ƒç´ çš„æ„é€ å‡½æ•°ï¼Œæ„å‘³ç€å¯ä»¥æ ¹æ®ä¼ é€’çš„å‚æ•°è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ„é€ å‡½æ•°ã€‚ å®¹é‡å˜åŒ–ï¼šå¦‚æœå½“å‰å‘é‡çš„å¤§å°ç­‰äºå®¹é‡ï¼Œemplace_back ä¼šå¼•èµ·å‘é‡çš„é‡æ–°åˆ†é…ï¼Œè¿™å¯èƒ½å¯¼è‡´æ‰€æœ‰ç°æœ‰çš„è¿­ä»£å™¨ã€å¼•ç”¨å’ŒæŒ‡é’ˆå¤±æ•ˆã€‚ å¼‚å¸¸å®‰å…¨æ€§ï¼šå¦‚æœæ„é€ å‡½æ•°æŠ›å‡ºå¼‚å¸¸ï¼Œemplace_back ä¿è¯ä¸ä¼šå¯¼è‡´å†…å­˜æ³„æ¼ã€‚ ç¤ºä¾‹ä»£ç  12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;struct MyClass &#123; MyClass(int x, std::string y) : num(x), str(y) &#123;&#125; int num; std::string str;&#125;;int main() &#123; std::vector&lt;MyClass&gt; vec; // ç›´æ¥åœ¨å‘é‡æœ«å°¾æ„é€ ä¸€ä¸ª MyClass å¯¹è±¡ vec.emplace_back(10, &quot;Hello&quot;); for (const auto&amp; item : vec) &#123; std::cout &lt;&lt; item.num &lt;&lt; &quot;, &quot; &lt;&lt; item.str &lt;&lt; std::endl; &#125; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œemplace_back è¢«ç”¨æ¥ç›´æ¥åœ¨ vector æœ«å°¾æ„é€ ä¸€ä¸ª MyClass å¯¹è±¡ã€‚è¿™é¿å…äº†å…ˆæ„é€ ä¸€ä¸ªä¸´æ—¶å¯¹è±¡ç„¶åå°†å…¶å¤åˆ¶æˆ–ç§»åŠ¨åˆ°å‘é‡ä¸­çš„æƒ…å†µã€‚ ä¸push_backçš„åŒºåˆ« push_back å’Œ emplace_back éƒ½æ˜¯ç”¨äºå‘å®¹å™¨ï¼ˆå¦‚ std::vectorï¼‰ä¸­æ·»åŠ å…ƒç´ çš„æˆå‘˜å‡½æ•°ï¼Œä½†å®ƒä»¬åœ¨æ·»åŠ æ–°å…ƒç´ æ—¶çš„æ–¹å¼å’Œæ€§èƒ½æœ‰æ‰€ä¸åŒã€‚ push_back: è¿™ä¸ªå‡½æ•°ç”¨äºåœ¨å®¹å™¨çš„æœ«å°¾æ·»åŠ ä¸€ä¸ªæ–°å…ƒç´ ã€‚å½“ä½¿ç”¨ push_back æ—¶ï¼Œå®ƒä¼šåˆ›å»ºè¯¥å…ƒç´ çš„å‰¯æœ¬æˆ–ç§»åŠ¨ï¼Œè¿™å–å†³äºæä¾›çš„å‚æ•°ã€‚å¦‚æœå‚æ•°æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œé‚£ä¹ˆ push_back ä¼šè°ƒç”¨è¯¥å¯¹è±¡çš„æ‹·è´æ„é€ å‡½æ•°æˆ–ç§»åŠ¨æ„é€ å‡½æ•°ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´é¢å¤–çš„æ€§èƒ½å¼€é”€ï¼Œç‰¹åˆ«æ˜¯å½“å¯¹è±¡è¾ƒå¤§æˆ–å¤æ‚æ—¶ã€‚ emplace_back: è¿™ä¸ªå‡½æ•°ä¹Ÿç”¨äºåœ¨å®¹å™¨æœ«å°¾æ·»åŠ æ–°å…ƒç´ ï¼Œä½†å®ƒçš„å·¥ä½œæ–¹å¼ç•¥æœ‰ä¸åŒã€‚emplace_back ä¼šç›´æ¥åœ¨å®¹å™¨çš„æœ«å°¾æ„é€ å…ƒç´ ï¼Œè€Œä¸æ˜¯é¦–å…ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶å¯¹è±¡ç„¶åæ‹·è´æˆ–ç§»åŠ¨åˆ°å®¹å™¨ä¸­ã€‚å®ƒé€šè¿‡æ¥å—æ„é€ å‡½æ•°çš„å‚æ•°æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå·²ç»æ„é€ å¥½çš„å¯¹è±¡ã€‚è¿™æ„å‘³ç€ä½¿ç”¨ emplace_back å¯ä»¥å‡å°‘ä¸å¿…è¦çš„æ‹·è´æˆ–ç§»åŠ¨æ“ä½œï¼Œä»è€Œæé«˜æ•ˆç‡ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œemplace_back é€šå¸¸æä¾›æ›´å¥½çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æ·»åŠ å¤æ‚å¯¹è±¡åˆ°å®¹å™¨ä¸­æ—¶ï¼Œå› ä¸ºå®ƒå‡å°‘äº†æ‹·è´å’Œç§»åŠ¨çš„æ¬¡æ•°ã€‚ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½¿ç”¨ push_back å’Œ emplace_back çš„æ•ˆæœå¯èƒ½æ˜¯ç›¸åŒçš„ï¼Œå°¤å…¶æ˜¯å¯¹äºç®€å•æˆ–å°å‹æ•°æ®ç±»å‹ã€‚"},{"title":"insert","path":"/wiki/C++/vector/insert.html","content":"åœ¨ C++ ä¸­ï¼Œvector ç±»å‹çš„ insert æ–¹æ³•æ˜¯ä¸€ä¸ªé‡è¦çš„æˆå‘˜å‡½æ•°ï¼Œç”¨äºåœ¨æŒ‡å®šä½ç½®æ’å…¥å…ƒç´ ã€‚ä¸‹é¢å°†è¯¦ç»†ä»‹ç»è¿™ä¸ªæ–¹æ³•çš„åŸºæœ¬ç”¨æ³•ã€ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ï¼Œä»¥åŠæä¾›ä¸€ä¸ªç¤ºä¾‹ä»£ç ã€‚ åŸºæœ¬ç”¨æ³• std::vector çš„ insert æ–¹æ³•å…è®¸åœ¨å‘é‡ä¸­çš„ç‰¹å®šä½ç½®æ’å…¥ä¸€ä¸ªæˆ–å¤šä¸ªå…ƒç´ ã€‚è¿™ä¸ªæ–¹æ³•æ¥æ”¶çš„ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼ŒæŒ‡ç¤ºæ’å…¥ä½ç½®ã€‚å…¶ä½™å‚æ•°å–å†³äºæ’å…¥æ“ä½œçš„ç±»å‹ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ ä½ç½®æŒ‡å®šï¼šinsert æ–¹æ³•éœ€è¦ä¸€ä¸ªè¿­ä»£å™¨æ¥æŒ‡å®šæ’å…¥çš„ä½ç½®ã€‚å¦‚æœä½ç½®è¿­ä»£å™¨ä¸åˆæ³•ï¼ˆæ¯”å¦‚è¶…å‡ºäº†å‘é‡çš„å½“å‰èŒƒå›´ï¼‰ï¼Œç¨‹åºå¯èƒ½ä¼šå´©æºƒã€‚ æ€§èƒ½è€ƒè™‘ï¼šåœ¨ vector ä¸­é—´æ’å…¥å…ƒç´ å¯èƒ½å¯¼è‡´åé¢æ‰€æœ‰å…ƒç´ çš„ç§»åŠ¨ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªå¼€é”€è¾ƒå¤§çš„æ“ä½œï¼Œç‰¹åˆ«æ˜¯å¯¹äºå«æœ‰å¤§é‡å…ƒç´ çš„ vectorã€‚ å®¹é‡è°ƒæ•´ï¼šå¦‚æœéœ€è¦çš„è¯ï¼Œinsert æ“ä½œä¼šå¢åŠ  vector çš„å®¹é‡ï¼Œä»¥å®¹çº³æ–°å…ƒç´ ã€‚ å¤šç§é‡è½½ï¼šinsert æ–¹æ³•æœ‰å¤šç§é‡è½½å½¢å¼ï¼Œå¯ä»¥æ’å…¥å•ä¸ªå…ƒç´ ã€æ’å…¥å¦ä¸€ä¸ªå®¹å™¨ä¸­çš„å…ƒç´ èŒƒå›´ï¼Œç”šè‡³æ’å…¥å¤šä¸ªé‡å¤çš„å…ƒç´ ã€‚ ç¤ºä¾‹ä»£ç  1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;int main() &#123; std::vector&lt;int&gt; vec = &#123;10, 20, 30, 40&#125;; // æ’å…¥å•ä¸ªå…ƒç´  auto it = vec.begin() + 2; // åœ¨ç¬¬ä¸‰ä¸ªå…ƒç´ ä¹‹å‰æ’å…¥ vec.insert(it, 25); // æ’å…¥å¤šä¸ªé‡å¤å…ƒç´  vec.insert(vec.begin() + 1, 3, 15); // åœ¨ç¬¬äºŒä¸ªå…ƒç´ ä½ç½®æ’å…¥ä¸‰ä¸ª15 // è¾“å‡ºç»“æœ for (int num : vec) &#123; std::cout &lt;&lt; num &lt;&lt; &quot; &quot;; &#125; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ç¬¬ä¸‰ä¸ªå…ƒç´ å‰æ’å…¥äº†ä¸€ä¸ªå€¼ä¸º 25 çš„å…ƒç´ ï¼Œç„¶ååœ¨ç¬¬äºŒä¸ªå…ƒç´ çš„ä½ç½®æ’å…¥äº†ä¸‰ä¸ªå€¼ä¸º 15 çš„å…ƒç´ ã€‚æ³¨æ„åœ¨æ’å…¥å…ƒç´ åï¼Œè¿­ä»£å™¨å¯èƒ½ä¼šå¤±æ•ˆï¼Œå› æ­¤åœ¨æ’å…¥åé‡æ–°è·å–è¿­ä»£å™¨çš„ä½ç½®æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚ vectorä¸­insertå¦ä¸€ä¸ªvector å¦‚æœè¦ä½¿ç”¨ std::vector çš„ insert æ–¹æ³•æ’å…¥å¦ä¸€ä¸ª vectorï¼Œå¯ä»¥é€šè¿‡æŒ‡å®šæ’å…¥èŒƒå›´çš„æ–¹å¼æ¥å®Œæˆã€‚è¿™é€šå¸¸æ¶‰åŠåˆ°æä¾›ä¸€ä¸ªæ’å…¥ç‚¹ï¼ˆé€šè¿‡è¿­ä»£å™¨æŒ‡å®šï¼‰ä»¥åŠè¢«æ’å…¥ vector çš„å¼€å§‹å’Œç»“æŸè¿­ä»£å™¨ã€‚ ä½¿ç”¨èŒƒå›´æ’å…¥çš„åŸºæœ¬è¯­æ³•å¦‚ä¸‹ï¼š 1vector.insert(position, startIterator, endIterator); position æ˜¯ä¸€ä¸ªæŒ‡å‘åŸ vector ä¸­çš„ä½ç½®çš„è¿­ä»£å™¨ï¼Œè¡¨ç¤ºæ–°å…ƒç´ æ’å…¥çš„ä½ç½®ã€‚ startIterator å’Œ endIterator åˆ†åˆ«æ˜¯è¢«æ’å…¥ vector çš„å¼€å§‹å’Œç»“æŸè¿­ä»£å™¨ï¼Œå®šä¹‰äº†è¦æ’å…¥çš„å…ƒç´ èŒƒå›´ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ è¿­ä»£å™¨å¤±æ•ˆï¼šåœ¨ insert æ“ä½œåï¼ŒåŸ vector çš„è¿­ä»£å™¨å¯èƒ½ä¼šå¤±æ•ˆï¼Œç‰¹åˆ«æ˜¯å¦‚æœå‘ç”Ÿå†…å­˜é‡æ–°åˆ†é…æ—¶ã€‚ æ€§èƒ½å½±å“ï¼šæ’å…¥æ“ä½œä¼šå¯¼è‡´ä»æ’å…¥ç‚¹åˆ° vector æœ«å°¾çš„æ‰€æœ‰å…ƒç´ è¢«ç§»åŠ¨ï¼Œå› æ­¤åœ¨å¤§å‹ vector ä¸­æ‰§è¡Œæ’å…¥æ“ä½œå¯èƒ½ä¼šå½±å“æ€§èƒ½ã€‚ è‡ªæˆ‘æ’å…¥ï¼šè¦æ³¨æ„ä¸è¦å°è¯•å°† vector çš„éƒ¨åˆ†å†…å®¹æ’å…¥åˆ°è‡ªèº«ä¸­ï¼Œè¿™å¯èƒ½å¯¼è‡´æœªå®šä¹‰çš„è¡Œä¸ºã€‚ ç¤ºä¾‹ä»£ç  1234567891011121314151617#include &lt;iostream&gt;#include &lt;vector&gt;int main() &#123; std::vector&lt;int&gt; vec1 = &#123;1, 2, 3, 4&#125;; std::vector&lt;int&gt; vec2 = &#123;5, 6, 7, 8&#125;; // åœ¨ vec1 çš„ç¬¬ä¸‰ä¸ªå…ƒç´ å‰æ’å…¥ vec2 çš„æ‰€æœ‰å…ƒç´  vec1.insert(vec1.begin() + 2, vec2.begin(), vec2.end()); // è¾“å‡º vec1 çš„å†…å®¹ for (int num : vec1) &#123; std::cout &lt;&lt; num &lt;&lt; &quot; &quot;; &#125; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œvec1 åˆå§‹åŒ…å«å…ƒç´  &#123;1, 2, 3, 4&#125;ï¼Œç„¶åæˆ‘ä»¬åœ¨å…¶ç¬¬ä¸‰ä¸ªå…ƒç´ å‰æ’å…¥äº† vec2 ä¸­çš„æ‰€æœ‰å…ƒç´ ï¼Œæœ€ç»ˆ vec1 çš„å†…å®¹å˜ä¸º &#123;1, 2, 5, 6, 7, 8, 3, 4&#125;ã€‚"},{"title":"2023å¹´11æœˆæ¯æ—¥ä¸€é¢˜","path":"/wiki/LeetCode/æ¯æ—¥ä¸€é¢˜/2023å¹´11æœˆæ¯æ—¥ä¸€é¢˜.html","content":"2023-11-22 é¢˜ç›®ä¼ é€é—¨ï¼š2304. ç½‘æ ¼ä¸­çš„æœ€å°è·¯å¾„ä»£ä»· - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“æ¯”è¾ƒç®€å•çš„dpåˆ·è¡¨é¢˜ï¼š 1234567891011121314151617181920212223242526#include&lt;bits/stdc++.h&gt;using namespace std;class Solution &#123;public: int minPathCost(vector&lt;vector&lt;int&gt;&gt;&amp; grid, vector&lt;vector&lt;int&gt;&gt;&amp; moveCost) &#123; int m = grid.size(), n = grid[0].size(); vector&lt;vector&lt;int&gt;&gt; dp(m, vector&lt;int&gt;(n, 0)); for(int i=0;i&lt;n;++i) dp[0][i] = grid[0][i]; for(int i=1;i&lt;m;++i)&#123; for(int j=0;j&lt;n;++j)&#123; for(int k=0;k&lt;n;++k)&#123; if(k==0) dp[i][j] = dp[i-1][k] + moveCost[grid[i-1][k]][j] + grid[i][j]; else dp[i][j] = min(dp[i][j],dp[i-1][k] + moveCost[grid[i-1][k]][j] + grid[i][j]); &#125; &#125; &#125; int maxx = dp[m-1][0]; for(int i=0;i&lt;n;++i) maxx = min(maxx,dp[m-1][i]); return maxx; &#125;&#125;;int main()&#123; vector&lt;vector&lt;int&gt;&gt; grid = &#123;&#123;5,3&#125;,&#123;4,0&#125;,&#123;2,1&#125;&#125;,moveCost = &#123;&#123;9,8&#125;,&#123;1,5&#125;,&#123;10,12&#125;,&#123;18,6&#125;,&#123;2,4&#125;,&#123;14,3&#125;&#125;; cout&lt;&lt;Solution().minPathCost(grid,moveCost)&lt;&lt;endl; return 0;&#125; 2023-11-24 é¢˜ç›®ä¼ é€é—¨ï¼š2824. ç»Ÿè®¡å’Œå°äºç›®æ ‡çš„ä¸‹æ ‡å¯¹æ•°ç›® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ éå¸¸åŸºæœ¬çš„ä¸€é“ç­¾åˆ°é¢˜ç›® 123456789101112131415161718192021#include&lt;bits/stdc++.h&gt;using namespace std;class Solution &#123;public: int countPairs(vector&lt;int&gt;&amp; nums, int target) &#123; int n = nums.size(),cnt=0; for(int i=0;i&lt;n;++i)&#123; for(int j=i+1;j&lt;n;++j)&#123; if(nums[i]+nums[j] &lt; target) ++cnt; &#125; &#125; return cnt; &#125;&#125;;int main() &#123; vector&lt;int&gt; nums = &#123;-1, 1, 2, 3, 1&#125;; int target = 2; cout&lt;&lt;Solution().countPairs(nums, target); return 0;&#125;"},{"title":"vector åŸºç¡€","path":"/wiki/C++/vector/vector åŸºç¡€.html","content":"åœ¨ C++ ä¸­ï¼Œvector æ˜¯ä¸€ä¸ªåŸºäºæ¨¡æ¿çš„åºåˆ—å®¹å™¨ï¼Œå®ƒå°è£…äº†å¯ä»¥åŠ¨æ€æ”¹å˜å¤§å°çš„æ•°ç»„ã€‚ä»¥ä¸‹æ˜¯å…³äº vector çš„è¯¦ç»†è§£é‡Šï¼š åŸºæœ¬ç”¨æ³• å®šä¹‰å’Œåˆå§‹åŒ–: vector&lt;T&gt; å®šä¹‰ä¸€ä¸ªç±»å‹ä¸º T çš„å‘é‡ã€‚ä¾‹å¦‚ï¼Œvector&lt;int&gt; v; åˆ›å»ºä¸€ä¸ªç©ºçš„æ•´æ•°å‘é‡ã€‚ä½ ä¹Ÿå¯ä»¥ç”¨åˆå§‹åŒ–åˆ—è¡¨ vector&lt;int&gt; v = &#123;1, 2, 3&#125;; åˆ›å»ºå¹¶åˆå§‹åŒ–å‘é‡ã€‚ æ·»åŠ å…ƒç´ : ä½¿ç”¨ push_back(value) åœ¨å‘é‡çš„æœ«å°¾æ·»åŠ å…ƒç´ ã€‚ è®¿é—®å…ƒç´ : é€šè¿‡ operator[] æˆ– at(index) è®¿é—®å…ƒç´ ã€‚at æ–¹æ³•åœ¨è¶Šç•Œæ—¶æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œ operator[] ä¸è¿›è¡Œè¾¹ç•Œæ£€æŸ¥ã€‚ å¤§å°å’Œå®¹é‡: ä½¿ç”¨ size() æ¥è·å–å‘é‡ä¸­çš„å…ƒç´ ä¸ªæ•°ï¼Œcapacity() è·å–å‘é‡çš„å½“å‰å®¹é‡ã€‚ è¿­ä»£å™¨: æä¾›è¿­ä»£å™¨ï¼ˆå¦‚ begin(), end()ï¼‰æ¥éå†å‘é‡ä¸­çš„å…ƒç´ ã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ åŠ¨æ€å¤§å°: ä¸æ™®é€šæ•°ç»„ä¸åŒï¼Œvector å¯ä»¥æ ¹æ®éœ€è¦åŠ¨æ€å¢é•¿å’Œæ”¶ç¼©ã€‚ å†…å­˜ç®¡ç†: å½“æ–°å…ƒç´ æ·»åŠ åˆ° vector ä½¿å¾—å½“å‰å®¹é‡ä¸è¶³æ—¶ï¼Œvector ä¼šè‡ªåŠ¨é‡æ–°åˆ†é…å†…å­˜ä»¥å®¹çº³æ›´å¤šå…ƒç´ ã€‚ æ€§èƒ½: vector æä¾›å¯¹å°¾éƒ¨å…ƒç´ çš„å¿«é€Ÿè®¿é—®å’Œæ·»åŠ ï¼Œä½†åœ¨ä¸­é—´æˆ–å¼€å§‹æ’å…¥å…ƒç´ å¯èƒ½è¾ƒæ…¢ï¼Œå› ä¸ºå¯èƒ½æ¶‰åŠå…ƒç´ çš„ç§»åŠ¨ã€‚ è¿ç»­å­˜å‚¨: vector çš„å…ƒç´ å­˜å‚¨åœ¨è¿ç»­çš„å†…å­˜ä½ç½®ä¸Šï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥åƒä½¿ç”¨æ•°ç»„ä¸€æ ·ï¼Œé€šè¿‡æŒ‡é’ˆç®—æœ¯æ“ä½œ vector çš„å…ƒç´ ã€‚ ç¤ºä¾‹ä»£ç  1234567891011121314151617181920#include &lt;iostream&gt;#include &lt;vector&gt;int main() &#123; std::vector&lt;int&gt; vec; vec.push_back(10); vec.push_back(20); vec.push_back(30); // ä½¿ç”¨ç´¢å¼•è®¿é—®å…ƒç´  std::cout &lt;&lt; &quot;ç¬¬ä¸€ä¸ªå…ƒç´ : &quot; &lt;&lt; vec[0] &lt;&lt; std::endl; // ä½¿ç”¨è¿­ä»£å™¨éå†å‘é‡ for(auto it = vec.begin(); it != vec.end(); ++it) &#123; std::cout &lt;&lt; *it &lt;&lt; &#x27; &#x27;; &#125; std::cout &lt;&lt; std::endl; return 0;&#125; è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åˆ›å»º vectorï¼Œå‘å…¶ä¸­æ·»åŠ å…ƒç´ ï¼Œè®¿é—®å…ƒç´ ä»¥åŠä½¿ç”¨è¿­ä»£å™¨éå† vectorã€‚"},{"title":"resize","path":"/wiki/C++/vector/resize.html","content":"åŸºæœ¬ç”¨æ³• åœ¨ C++ ä¸­ï¼Œstd::vector ç±»çš„ resize æ–¹æ³•ç”¨äºæ”¹å˜å‘é‡çš„å¤§å°ã€‚å½“ä½ è°ƒç”¨ resize(n) æ—¶ï¼Œå®ƒä¼šå°†å‘é‡çš„å¤§å°è°ƒæ•´ä¸º nã€‚å¦‚æœ n å¤§äºå½“å‰å‘é‡çš„å¤§å°ï¼Œåˆ™æ–°å…ƒç´ å°†è¢«æ·»åŠ åˆ°å‘é‡çš„æœ«å°¾ï¼Œè¿™äº›æ–°å…ƒç´ ä¼šè¢«åˆå§‹åŒ–ä¸ºé»˜è®¤å€¼ã€‚å¦‚æœ n å°äºå½“å‰å‘é‡çš„å¤§å°ï¼Œå‘é‡å°†è¢«ç¼©å‡ï¼Œå¤šä½™çš„å…ƒç´ ä¼šè¢«ä¸¢å¼ƒã€‚ ç‰¹ç‚¹å’Œæ³¨æ„äº‹é¡¹ æ”¹å˜å¤§å°çš„å½±å“ï¼šå½“ resize å¢åŠ å‘é‡å¤§å°æ—¶ï¼Œæ–°æ·»åŠ çš„å…ƒç´ ä¼šè¢«é»˜è®¤åˆå§‹åŒ–ã€‚å¯¹äºåŸºæœ¬æ•°æ®ç±»å‹ï¼ˆå¦‚ intã€double ç­‰ï¼‰ï¼Œè¿™æ„å‘³ç€æ–°å…ƒç´ çš„åˆå§‹å€¼ä¸ç¡®å®šã€‚å¯¹äºç±»å¯¹è±¡ï¼Œå°†è°ƒç”¨é»˜è®¤æ„é€ å‡½æ•°ã€‚ æ•ˆç‡è€ƒè™‘ï¼šé¢‘ç¹è°ƒç”¨ resize å¯èƒ½å½±å“æ€§èƒ½ï¼Œå› ä¸ºæ¯æ¬¡å¤§å°æ”¹å˜å¯èƒ½æ¶‰åŠå†…å­˜åˆ†é…å’Œå…ƒç´ å¤åˆ¶æˆ–é”€æ¯ã€‚ å®‰å…¨æ€§ï¼šä¸ reserve æ–¹æ³•ä¸åŒï¼Œresize ä¼šæ”¹å˜å‘é‡çš„å®é™…å…ƒç´ æ•°é‡ï¼Œè€Œ reserve åªæ”¹å˜å®¹é‡ã€‚ é‡è½½ç‰ˆæœ¬ï¼šresize è¿˜æœ‰ä¸€ä¸ªé‡è½½ç‰ˆæœ¬ resize(n, value)ï¼Œå¯ä»¥æŒ‡å®šæ–°æ·»åŠ å…ƒç´ çš„åˆå§‹å€¼ã€‚ ç¤ºä¾‹ä»£ç  1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;vector&gt;int main() &#123; std::vector&lt;int&gt; v = &#123;1, 2, 3&#125;; // å¢åŠ å¤§å°åˆ° 5ï¼Œé»˜è®¤åˆå§‹åŒ–æ–°å…ƒç´  v.resize(5); for (int i : v) std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; // è¾“å‡º: 1 2 3 0 0 std::cout &lt;&lt; &quot; &quot;; // å‡å°å¤§å°åˆ° 2ï¼Œç§»é™¤å¤šä½™å…ƒç´  v.resize(2); for (int i : v) std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; // è¾“å‡º: 1 2 std::cout &lt;&lt; &quot; &quot;; // å†æ¬¡å¢åŠ å¤§å°ï¼Œå¹¶æŒ‡å®šæ–°å…ƒç´ çš„åˆå§‹å€¼ä¸º 99 v.resize(4, 99); for (int i : v) std::cout &lt;&lt; i &lt;&lt; &quot; &quot;; // è¾“å‡º: 1 2 99 99 std::cout &lt;&lt; &quot; &quot;; return 0;&#125; åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ resize æ¥å¢åŠ å’Œå‡å°‘å‘é‡çš„å¤§å°ï¼Œä»¥åŠå¦‚ä½•æŒ‡å®šæ–°å…ƒç´ çš„åˆå§‹åŒ–å€¼ã€‚"},{"title":"2024å¹´01æœˆæ¯æ—¥ä¸€é¢˜","path":"/wiki/LeetCode/æ¯æ—¥ä¸€é¢˜/2024å¹´01æœˆæ¯æ—¥ä¸€é¢˜.html","content":"2024-01-01 é¢˜ç›®ä¼ é€é—¨ï¼š1599. ç»è¥æ‘©å¤©è½®çš„æœ€å¤§åˆ©æ¶¦ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æ–°å¹´å¿«ä¹ğŸ‡ğŸ‡ğŸ‡ï¼ï¼ï¼ï¼Œæ–°å¹´ç¬¬ä¸€é¢˜å°±æ˜¯ä¹‹å‰åšè¿‡çš„ï¼Œæ¨¡æ‹Ÿå³å¯ã€‚é¦–å…ˆå…ˆå¾ªç¯æ¯ä¸ªæ—¶é—´ç‚¹ï¼Œä½¿ç”¨ä¸€ä¸ªå˜é‡previè®°å½•è¯¥æ—¶é—´ç‚¹ä¸Šä¸€ä¸ªæ—¶é—´ç‚¹åè¿˜å‰©ä¸‹æ²¡ä¸Šæ‘©å¤©è½®çš„é¡¾å®¢æ•°é‡ï¼Œç„¶åå½“å‰æ—¶é—´ç‚¹çš„é¡¾å®¢æ•°å°±æ˜¯ä¹‹å‰å‰©ä¸‹çš„åŠ ä¸Šæ–°æ¥çš„ï¼Œè¿™é‡Œå¤§äº4è¿˜æ˜¯å°äºç­‰äº4åˆ†ç±»è®¨è®ºä¸€ä¸‹ã€‚æœ€åå¦‚æœæœ€åä¸€ä¸ªæ—¶é—´ç‚¹å·²ç»è¿‡äº†çš„è¯previè¿˜æœ‰å‰©ä½™ï¼Œåˆ™ç»§ç»­è½¬ç›´åˆ°å°†previè½¬ç©ºï¼Œä¸­é—´åˆ¤æ–­ä¸€ä¸‹è½¬å¤šå°‘æ¬¡çš„æ—¶å€™èƒ½å¤Ÿæœ‰æœ€å¤§åˆ©æ¶¦å³å¯ï¼š Pythonä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233class Solution: def minOperationsMaxProfit(self, customers: List[int], boardingCost: int, runningCost: int) -&gt; int: res = 0 ans = [] serv = 0 for idx,customer in enumerate(customers): if customer + res &gt; 4: res += (customer-4) serv += 4 ans.append(serv * boardingCost - (idx+1) * runningCost) else: serv += (res+customer) res = 0 ans.append(serv * boardingCost - (idx+1) * runningCost) while res: idx += 1 if res &gt; 4: serv += 4 res -= 4 ans.append(serv * boardingCost - (idx+1) * runningCost) else: serv += res res = 0 ans.append(serv * boardingCost - (idx+1) * runningCost) now,loc = 0,-1 # return ans for i in range(len(ans)): if now &lt; ans[i]: now = ans[i] loc = i+1 return -1 if loc == -1 else loc C++ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; public: int minOperationsMaxProfit(vector&lt;int&gt;&amp; customers, int boardingCost, int runningCost) &#123; int previ = 0; int ans = 0,nw = 0; int ans_cnt=-1,cnt=0; for (auto customer:customers) &#123; int tmp = customer + previ; cnt++; if (tmp &gt; 4) &#123; nw += 4*boardingCost - runningCost; previ = tmp - 4; if (nw &gt; ans) ans = nw,ans_cnt = cnt; ans = max(ans, nw); &#125; else &#123; nw += tmp*boardingCost - runningCost; previ = 0; if (nw &gt; ans) ans = nw,ans_cnt = cnt; &#125; &#125; while (previ) &#123; cnt++; if(previ &gt; 4) &#123; nw += 4*boardingCost - runningCost; previ -= 4; if (nw &gt; ans) ans = nw,ans_cnt = cnt; &#125; else &#123; nw += previ*boardingCost - runningCost; previ = 0; if (nw &gt; ans) ans = nw,ans_cnt = cnt; &#125; &#125; return ans_cnt; &#125; &#125;; 2024-01-02 é¢˜ç›®ä¼ é€é—¨ï¼š466. ç»Ÿè®¡é‡å¤ä¸ªæ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ 2024-01-03 é¢˜ç›®ä¼ é€é—¨ï¼š2487. ä»é“¾è¡¨ä¸­ç§»é™¤èŠ‚ç‚¹ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“é“¾è¡¨çš„é¢˜ç›®ï¼Œå……åˆ†æš´éœ²äº†æˆ‘å¯¹C++ä¸€äº›ç‰¹æ€§ä»¥åŠæŒ‡é’ˆç›¸å…³å†…å®¹è¿˜ä¸æ˜¯éå¸¸çš„ç†Ÿç»ƒã€‚ 1234567891011121314151617181920212223242526272829303132333435363738/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* removeNodes(ListNode* head) &#123; ListNode* nw = head; vector&lt;int&gt; arr = &#123;nw-&gt;val&#125;; while (nw-&gt;next) &#123; nw = nw-&gt;next; arr.push_back(nw-&gt;val); &#125; stack&lt;int&gt; ans_arr; int siz = arr.size(); for (int i=siz-1;i&gt;=0;--i) &#123; if (ans_arr.size()==0||arr[i] &gt;= ans_arr.top()) &#123; ans_arr.push(arr[i]); &#125; &#125; ListNode *hhead = new ListNode(), *now = new ListNode(); now = hhead; while (!ans_arr.empty()) &#123; ListNode *tmp = new ListNode(); int nw_val = ans_arr.top(); ans_arr.pop(); tmp-&gt;val = nw_val; now-&gt;next = tmp; now = tmp; &#125; return hhead-&gt;next; &#125;&#125;; æ³¨æ„éœ€è¦éå¸¸æ³¨æ„çš„å°±æ˜¯åœ¨åˆå§‹åŒ–æŒ‡é’ˆçš„æ—¶å€™ä¸€å®šè¦è¿™ä¹ˆå†™ListNode *hhead = new ListNode(), *now = new ListNode(); ä¸ºä»€ä¹ˆä¸èƒ½ListNode *tmp; è¿™é‡Œçš„tmpæ˜¯ä¸€ä¸ªæŒ‡å‘ListNodeç±»å‹çš„æŒ‡é’ˆã€‚ä½†æ˜¯ï¼Œè¿™ä¸ªæŒ‡é’ˆåœ¨ä½¿ç”¨ä¹‹å‰æ²¡æœ‰è¢«åˆ†é…ä»»ä½•å†…å­˜ã€‚è¿™æ„å‘³ç€tmpæŒ‡å‘çš„æ˜¯ä¸€ä¸ªæœªçŸ¥çš„ã€æœªåˆå§‹åŒ–çš„å†…å­˜ä½ç½®ã€‚å½“æ‚¨å°è¯•é€šè¿‡now-&gt;next = tmp;ç»™now-&gt;nextèµ‹å€¼æ—¶ï¼Œæ‚¨å®é™…ä¸Šæ˜¯åœ¨è®©now-&gt;nextæŒ‡å‘ä¸€ä¸ªä¸ç¡®å®šçš„å†…å­˜ä½ç½®ã€‚è¿™æ˜¯éå¸¸å±é™©çš„ï¼Œå› ä¸ºè¿™å—å†…å­˜å¯èƒ½æ˜¯ç©ºçš„ï¼Œæˆ–è€…å·²ç»è¢«å…¶ä»–æ•°æ®å ç”¨ï¼Œä»è€Œå¯¼è‡´æœªå®šä¹‰è¡Œä¸ºæˆ–ç¨‹åºå´©æºƒã€‚ ä¸ºä»€ä¹ˆä¸èƒ½ListNode* tmp = nullptr; å¦‚æœæ‚¨å°†ListNode* tmp = nullptr;å¹¶åœ¨ä¹‹åçš„ä»£ç ä¸­å°è¯•é€šè¿‡tmpæŒ‡é’ˆè®¿é—®æˆ–ä¿®æ”¹æ•°æ®ï¼Œé‚£ä¹ˆè¿™åŒæ ·ä¼šå¯¼è‡´é”™è¯¯ã€‚åŸå› å¦‚ä¸‹ï¼š ç©ºæŒ‡é’ˆè§£å¼•ç”¨: å½“tmpè¢«è®¾ç½®ä¸ºnullptræ—¶ï¼Œå®ƒæŒ‡å‘çš„æ˜¯ç©ºåœ°å€ã€‚ä»»ä½•å°è¯•é€šè¿‡ç©ºæŒ‡é’ˆï¼ˆnullptrï¼‰è®¿é—®æˆ–ä¿®æ”¹æ•°æ®çš„è¡Œä¸ºéƒ½ä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯ï¼Œé€šå¸¸æ˜¯æ®µé”™è¯¯ï¼ˆsegmentation faultï¼‰ã€‚åœ¨æ‚¨çš„ä»£ç ä¸­ï¼Œå¦‚æœtmpæ˜¯nullptrï¼Œé‚£ä¹ˆåƒnow-&gt;next = tmp;è¿™æ ·çš„èµ‹å€¼æ“ä½œæ˜¯å®‰å…¨çš„ï¼Œä½†ä¹‹åçš„tmp-&gt;val = nw_val;å°è¯•è§£å¼•ç”¨nullptrï¼Œè¿™ä¼šå¯¼è‡´é”™è¯¯ã€‚ æœªåˆ†é…å®é™…çš„èŠ‚ç‚¹: åœ¨é“¾è¡¨æ“ä½œä¸­ï¼Œé€šå¸¸éœ€è¦åˆ›å»ºæ–°çš„èŠ‚ç‚¹æ¥å­˜å‚¨æ•°æ®ã€‚å¦‚æœtmpåªæ˜¯ä¸€ä¸ªç©ºæŒ‡é’ˆï¼Œé‚£ä¹ˆå®ƒä¸èƒ½ç”¨äºå­˜å‚¨ä»»ä½•å®é™…çš„æ•°æ®ã€‚æ‚¨éœ€è¦ä¸ºæ¯ä¸ªæ–°èŠ‚ç‚¹åˆ†é…å†…å­˜æ¥å­˜å‚¨æ•°æ®å’ŒæŒ‡å‘ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„æŒ‡é’ˆã€‚ æ€»ç»“ è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ‚¨éœ€è¦åœ¨ä½¿ç”¨tmpä¹‹å‰ä¸ºå…¶åˆ†é…å†…å­˜ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š 1ListNode* tmp = new ListNode(); // åˆ†é…å†…å­˜å¹¶åˆå§‹åŒ– è¿™æ ·ï¼Œtmpä¸å†æ˜¯ä¸€ä¸ªç©ºæŒ‡é’ˆï¼Œè€Œæ˜¯æŒ‡å‘ä¸€ä¸ªæ–°åˆ†é…ä¸”å·²åˆå§‹åŒ–çš„ListNodeå¯¹è±¡ã€‚è¿™å…è®¸æ‚¨å®‰å…¨åœ°ä½¿ç”¨tmpæ¥å­˜å‚¨æ•°æ®å¹¶å°†å…¶åŠ å…¥åˆ°é“¾è¡¨ä¸­ã€‚ 2024-01-04 é¢˜ç›®ä¼ é€é—¨ï¼š2397. è¢«åˆ—è¦†ç›–çš„æœ€å¤šè¡Œæ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“æš´åŠ›æœç´¢æ¿å­é¢˜ç›®ã€‚ 1234567891011121314151617181920212223242526272829303132class Solution &#123;public: int maximumRows(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int numSelect) &#123; int ans = 0; int m = matrix.size(),n = matrix[0].size(); vector&lt;bool&gt; cols(n,false); auto judge = [&amp;](int x) &#123; int now_ans = 0; for(int i=0;i&lt;n;++i)&#123; if (matrix[x][i]==1 &amp;&amp; cols[i]==false) return false; &#125; return true; &#125;; function&lt;void(int,int)&gt; dfs = [&amp;](int idx,int pre) &#123; if (idx==numSelect) &#123; int nw = 0; for(int i=0;i&lt;m;++i)&#123; if (judge(i)) nw += 1; &#125; ans = max(ans,nw); return; &#125; for (int i=pre+1;i&lt;n;++i) &#123; cols[i] = true; dfs(idx+1, i); cols[i] = false; &#125; &#125;; dfs(0,-1); return ans; &#125;&#125;; 2024-01-05 é¢˜ç›®ä¼ é€é—¨ï¼š1944. é˜Ÿåˆ—ä¸­å¯ä»¥çœ‹åˆ°çš„äººæ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åœ¨è¯»å®Œé¢˜ç›®ä»¥åŠçœ‹å®Œæ•°æ®èŒƒå›´åä¸éš¾æƒ³åˆ°åº”è¯¥ç”¨å•è°ƒæ ˆçš„æ–¹æ³•è§£å†³è¿™é“é¢˜ï¼Œåå‘éå†æ•°ç»„ï¼Œå•è°ƒæ ˆç»´æŠ¤ä¸€ä¸ªé¡¶å°åº•å¤§çš„æ ˆï¼Œä»£è¡¨å½“å‰å…ƒç´ å¯èƒ½å¯ä»¥çœ‹è§çš„å³è¾¹çš„äººã€‚ æˆ‘ä»¬åªéœ€è¦åœ¨æ¯æ¬¡åœ¨åˆ¤æ–­å½“å‰å…ƒç´ æ—¶ï¼Œç»Ÿè®¡æˆ‘ä»¬è¦è¿›è¡Œå¤šå°‘æ¬¡å¼¹æ ˆæ“ä½œã€‚å°±æ˜¯æˆ‘ä»¬èƒ½å¤Ÿçœ‹åˆ°çš„äººçš„æ•°é‡ï¼Œä½†æ˜¯æœ€åè¿˜æœ‰ä¸€ä¸ªåœ°æ–¹éœ€è¦æ³¨æ„ä¸€ä¸‹ï¼Œè§ä¸‹é¢çº¢è‰²ã€‚ æ³¨æ„è¿™é‡Œè¿˜æœ‰ä¸€ä¸ªç»†èŠ‚ï¼Œå¼¹å®Œæ ˆåï¼Œéœ€è¦åˆ¤æ–­å½“å‰æ ˆæ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ä¸ºç©ºï¼Œæˆ‘ä»¬èƒ½çœ‹åˆ°çš„äººè¿˜è¦+1ï¼ˆè™½ç„¶æ¯”æˆ‘ä»¬é«˜ä½†æ˜¯èƒ½çœ‹åˆ°ï¼‰ 12345678910111213141516171819class Solution &#123;public: vector&lt;int&gt; canSeePersonsCount(vector&lt;int&gt;&amp; heights) &#123; stack&lt;int&gt; stk; int n = heights.size(); vector&lt;int&gt; ans(n,0); for(int i=n-1;i&gt;=0;--i)&#123; int tmp = 0; while(!stk.empty() &amp;&amp; heights[stk.top()] &lt; heights[i]) &#123; stk.pop(); tmp++; &#125; if (stk.empty()) ans[i] = tmp; else ans[i] = tmp+1; stk.push(i); &#125; return ans; &#125;&#125;; 2024-01-06 é¢˜ç›®ä¼ é€é—¨ï¼š2807. åœ¨é“¾è¡¨ä¸­æ’å…¥æœ€å¤§å…¬çº¦æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸ç®€å•çš„ç­¾åˆ°é¢˜ï¼Œå¤ä¹ ä¸€ä¸‹é“¾è¡¨å†™æ³•å’Œgcdå†™æ³•ã€‚ 1234567891011121314151617181920212223242526272829/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* insertGreatestCommonDivisors(ListNode* head) &#123; function&lt;int(int,int)&gt; ggcd=[&amp;](int a,int b) &#123; return a%b==0?b:ggcd(b,a%b); &#125;; ListNode *nw = head; if (nw-&gt;next == nullptr) return head; ListNode *nwnxt = nw-&gt;next; while (nwnxt != nullptr) &#123; int val = ggcd(max(nw-&gt;val,nwnxt-&gt;val),min(nw-&gt;val,nwnxt-&gt;val)); ListNode *tmp = new ListNode(val, nwnxt); nw-&gt;next = tmp; nw = nwnxt; nwnxt = nwnxt-&gt;next; &#125; return head; &#125;&#125;; 2024-01-07 é¢˜ç›®ä¼ é€é—¨ï¼š383. èµé‡‘ä¿¡ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å»ºç«‹26ä¸ªæ¡¶ï¼Œç»Ÿè®¡æ¯ä¸ªå­—ç¬¦ä¸ªæ•°å³å¯ã€‚ç­¾åˆ°é¢˜ï¼š 12345678910111213class Solution &#123;public: bool canConstruct(string ransomNote, string magazine) &#123; if (ransomNote.size() &gt; magazine.size()) return false; vector&lt;int&gt; cnt(26,0); for(auto note:magazine) cnt[note-&#x27;a&#x27;]++; for(auto note:ransomNote)&#123; cnt[note-&#x27;a&#x27;]--; if (cnt[note-&#x27;a&#x27;] &lt; 0) return false; &#125; return true; &#125;&#125;; 2024-01-08 é¢˜ç›®ä¼ é€é—¨ï¼š447. å›æ—‹é•–çš„æ•°é‡ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“unordered_mapå“ˆå¸Œé¢˜ï¼ŒO(n2)O(n^2)O(n2)å¤æ‚åº¦ï¼Œå¯¹äºæ¯ä¸ªä½ç½®ï¼Œéå†æ‰€æœ‰ä½ç½®ï¼Œä½¿ç”¨ä¸€ä¸ªå“ˆå¸Œè¡¨å­˜å‚¨ä¸è¯¥ä½ç½®ç›¸è·ç‰¹å®šè·ç¦»ä¸‹æœ‰å“ªäº›ä½ç½®ï¼ˆå“ˆå¸Œè¡¨ç´¢å¼•æ˜¯è·ç¦»ï¼‰ï¼Œæœ€åå°±å¯ä»¥æ ¹æ®è¿™ä¸ªå“ˆå¸Œè¡¨è®¡ç®—ä»¥è¯¥ç‚¹ä¸ºä¸­å¿ƒçš„å›æ—‹é•–æ•°é‡ã€‚ ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819class Solution &#123;public: int numberOfBoomerangs(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; int ans = 0,n=points.size(); for(int i=0;i&lt;n;++i)&#123; unordered_map&lt;int,int&gt; cnt; for(int j=0;j&lt;n;++j)&#123; if (i == j) continue; int dis = (points[i][0]-points[j][0]) * (points[i][0]-points[j][0]) + (points[i][1]-points[j][1]) * (points[i][1]-points[j][1]); if(cnt.find(dis)==cnt.end()) cnt[dis] = 1; else cnt[dis] ++; &#125; for(auto ele:cnt) &#123; ans += ele.second * (ele.second-1); &#125; &#125; return ans; &#125;&#125;; 2024-01-09 é¢˜ç›®ä¼ é€é—¨ï¼š 2024-01-14 é¢˜ç›®ä¼ é€é—¨ï¼š83. åˆ é™¤æ’åºé“¾è¡¨ä¸­çš„é‡å¤å…ƒç´  - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ é“¾è¡¨éå†ç­¾åˆ°é¢˜ç›®ï¼Œä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* deleteDuplicates(ListNode* head) &#123; ListNode *nw = head; while(nw!= nullptr&amp;&amp; nw-&gt;next!= nullptr)&#123; ListNode *nxt = nw-&gt;next; while(nxt!= nullptr&amp;&amp;nw-&gt;val == nxt-&gt;val) nxt = nxt-&gt;next; nw-&gt;next = nxt; nw = nw-&gt;next; &#125; return head; &#125;&#125;; 2024-01-15 é¢˜ç›®ä¼ é€é—¨ï¼š82. åˆ é™¤æ’åºé“¾è¡¨ä¸­çš„é‡å¤å…ƒç´  II - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ é“¾è¡¨éå†é¢˜ç›®ï¼Œæ˜¯æ˜¨å¤©é¢˜ç›®çš„åŠ å¼ºç‰ˆ,ä¸‹é¢ç»™å‡ºåªéå†ä¸€éçš„åšæ³•ï¼Œéœ€è¦æ³¨æ„çš„ç»†èŠ‚æ˜¯ï¼š å¤´èŠ‚ç‚¹ä¹Ÿå¯èƒ½è¢«åˆ é™¤ï¼Œæ‰€ä»¥è¦å¼€ä¸€ä¸ªheadä¹‹å‰çš„ç‚¹ã€‚ éœ€è¦åˆ¤æ–­ä¸‹ä¸€ä¸ªå’Œä¸‹ä¸‹ä¸ªèŠ‚ç‚¹æ˜¯å¦å­˜åœ¨ï¼Œåªæœ‰éƒ½å­˜åœ¨æ‰å¯èƒ½å‡ºç°ç›¸ç­‰çš„æƒ…å†µã€‚ æœ€åä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) &#123;&#125; * ListNode(int x) : val(x), next(nullptr) &#123;&#125; * ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* deleteDuplicates(ListNode* head) &#123; ListNode *headpre = new ListNode(0, head); ListNode *nw = headpre; while (nw-&gt;next &amp;&amp; nw-&gt;next-&gt;next) &#123; if (nw-&gt;next-&gt;val == nw-&gt;next-&gt;next-&gt;val) &#123; int x = nw-&gt;next-&gt;val; while (nw-&gt;next &amp;&amp; nw-&gt;next-&gt;val == x) &#123; nw-&gt;next = nw-&gt;next-&gt;next; &#125; &#125; else &#123; nw = nw-&gt;next; &#125; &#125; return headpre-&gt;next; &#125;&#125;; 2024-01-16 é¢˜ç›®ä¼ é€é—¨ï¼š2719. ç»Ÿè®¡æ•´æ•°æ•°ç›® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“æ•°ä½DPçš„é¢˜ç›® 2024-01-17 é¢˜ç›®ä¼ é€é—¨ï¼š2744. æœ€å¤§å­—ç¬¦ä¸²é…å¯¹æ•°ç›® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åŒé‡å¾ªç¯ç›´æ¥è§£å†³é—®é¢˜ã€‚ä»£ç å¦‚ä¸‹ï¼š 12345678910111213class Solution &#123;public: int maximumNumberOfStringPairs(vector&lt;string&gt;&amp; words) &#123; int n = words.size(); int ans = 0; for(int i=0;i&lt;n;++i)&#123; for(int j=i+1;j&lt;n;++j)&#123; if(words[i][0] == words[j][1] &amp;&amp; words[i][1] == words[j][0]) ans++; &#125; &#125; return ans; &#125;&#125;; 2024-01-20 é¢˜ç›®ä¼ é€é—¨ï¼š2788. æŒ‰åˆ†éš”ç¬¦æ‹†åˆ†å­—ç¬¦ä¸² - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ç­¾åˆ°é¢˜ï¼ˆå¯¹äºPythonæ¥è¯´å“ˆå“ˆï¼‰ï¼ŒCçš„è¯ä¸»è¦å¯èƒ½éœ€è¦ä½¿ç”¨stringstreamä»¥åŠgetlineå‡½æ•°ï¼Œå…·ä½“è§æˆ‘çš„Cæ•´ç†ã€‚ æœ€ç»ˆä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516class Solution &#123;public: vector&lt;string&gt; splitWordsBySeparator(vector&lt;string&gt;&amp; words, char separator) &#123; vector&lt;string&gt; res; for (string &amp;word : words) &#123; stringstream ss(word); string sub; while (getline(ss, sub, separator)) &#123; if (!sub.empty()) &#123; res.push_back(sub); &#125; &#125; &#125; return res; &#125;&#125;; 2024-01-21 é¢˜ç›®ä¼ é€é—¨ï¼š410. åˆ†å‰²æ•°ç»„çš„æœ€å¤§å€¼ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“DPé¢˜ç›®ï¼Œè®¾ç½®dpäºŒç»´æ•°ç»„dp[n+1][k+1]dp[n+1][k+1]dp[n+1][k+1]å…¶ä¸­nnnè¡¨ç¤ºæ•°ç»„é•¿åº¦ï¼Œkkkè¡¨ç¤ºåˆ†å‰²æ¬¡æ•°ã€‚å®šä¹‰dp[i][j]dp[i][j]dp[i][j]çš„å«ä¹‰æ˜¯ä»ç¬¬1ä¸ªæ•°åˆ°ç¬¬iiiä¸ªæ•°åˆ†æˆkkkæ®µåçš„æœ€å¤§å€¼ã€‚é‚£ä¹ˆä¸éš¾æƒ³åˆ°çŠ¶æ€è½¬ç§»æ–¹ç¨‹åº”è¯¥è¡¨ç¤ºä¸ºï¼š dp[j][i]=minâ¡(dp[j][i],maxâ¡(dp[kk][iâˆ’1],nums_sum[j]âˆ’nums_sum[kk]))dp[j][i] = \\min(dp[j][i],\\max(dp[kk][i-1], nums\\_sum[j]-nums\\_sum[kk])) dp[j][i]=min(dp[j][i],max(dp[kk][iâˆ’1],nums_sum[j]âˆ’nums_sum[kk])) å…¶ä¸­nums_sumnums\\_sumnums_sumæ˜¯å‰ç¼€å’Œæ•°ç»„, å› æ­¤nums_sum[j]nums\\_sum[j]nums_sum[j]è¡¨ç¤ºçš„æ˜¯å‰jjjä¸ªæ•°çš„å’Œã€‚ æ¥ä¸‹æ¥å°±æ˜¯dpé™åˆ¶æ¡ä»¶å’Œåˆå§‹çŠ¶æ€çš„å®šä¹‰äº†ï¼Œè§‚å¯Ÿä¸Šè¿°çŠ¶æ€è½¬ç§»æ–¹ç¨‹ï¼Œä¸éš¾å¾—çŸ¥æ–¹ç¨‹æƒ³è¦æ­£ç¡®è¿è¡Œéœ€è¦jâ‰¥ij\\geq ijâ‰¥iä¸”kkâ‰¥iâˆ’1kk\\geq i-1kkâ‰¥iâˆ’1 ä¸”j&gt;kkj &gt; kkj&gt;kkã€‚è¿™æ ·å¦‚æœé‡‡ç”¨é€’æ¨çš„æ–¹æ³•çš„è¯æˆ‘ä»¬å°±å¯ä»¥ç¡®å®šå¾ªç¯çš„é¡ºåºäº†ã€‚ 123for(int i=2; i&lt;=k; ++i)&#123;\tfor(int j=i; j&lt;=n; ++j)&#123; for(int kk=i-1; kk&lt;=j-1; ++kk) æœ€åå°±æ˜¯åˆå§‹æ¡ä»¶çš„ç¡®å®šäº†ï¼Œå…¶å®å°±æ˜¯åˆå§‹åŒ–dp[i][1]=nums_sum[i]dp[i][1] = nums\\_sum[i]dp[i][1]=nums_sum[i] ,ç„¶åå¾ªç¯å°±å¯ä»¥ä»ç¬¬äºŒä¸ªåˆ†å‰²å¼€å§‹å¾ªç¯äº†ã€‚ æ³¨æ„dpæ•°ç»„æœ€å¼€å§‹åˆå§‹åŒ–ä¸€å®šæ˜¯INT_MAX 123456789101112131415161718192021class Solution &#123;public: int splitArray(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); vector&lt;vector&lt;int&gt;&gt; dp(n+1,vector&lt;int&gt;(k+1, INT_MAX)); vector&lt;int&gt; nums_sum(n+1,0); dp[0][1] = 0; for(int i=0;i&lt;n;++i) &#123; dp[i+1][1] = dp[i][1] + nums[i]; nums_sum[i+1] = nums_sum[i] + nums[i]; &#125; for(int i=2; i&lt;=k; ++i)&#123; for(int j=i; j&lt;=n; ++j)&#123; for(int kk=i-1; kk&lt;=j-1; ++kk)&#123; dp[j][i] = min(dp[j][i],max(dp[kk][i-1], nums_sum[j]-nums_sum[kk])); &#125; &#125; &#125; return dp[n][k]; &#125;&#125;; è®°å¿†åŒ–æœç´¢åŒç†ï¼Œé€»è¾‘åè¿‡æ¥å°±è¡Œ,ä¼šæ›´ç®€å•æ˜“æ‡‚ä¸€äº›ï¼š 12345678910111213141516171819class Solution &#123;public: int splitArray(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); vector&lt;vector&lt;int&gt;&gt; dp(n + 1, vector&lt;int&gt;(k + 1, INT_MAX)); dp[0][1] = 0; for (int i = 1; i &lt;= n; ++i) dp[i][1] = dp[i - 1][1] + nums[i - 1]; function&lt;int(int, int)&gt; dfs = [&amp;](int u, int v) &#123; if (v == 1) return dp[u][1]; if (dp[u][v] != INT_MAX) return dp[u][v]; int tmp = INT_MAX; for (int i = v - 1; i &lt; u; ++i) &#123; tmp = min(tmp, max(dfs(i, v - 1), dp[u][1] - dp[i][1])); &#125; return dp[u][v] = tmp; &#125;; return dfs(n, k); &#125;&#125;; è¿˜æ˜¯å»ºè®®ä½¿ç”¨é€’æ¨ï¼Œå› ä¸ºæ•ˆç‡æ›´é«˜ï¼ï¼ï¼ 2024-01-22 é¢˜ç›®ä¼ é€é—¨ï¼š670. æœ€å¤§äº¤æ¢ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜è§£å†³æ–¹æ³•åº”è¯¥è¿˜æ˜¯å¾ˆå¤šçš„ï¼Œä½†æ˜¯å› ä¸ºä¹‹å‰åœ¨å­¦ä¹ å•è°ƒæ ˆï¼Œæ‰€ä»¥è¿™é‡Œç¬¬ä¸€æ—¶é—´æƒ³åˆ°çš„æ˜¯åŸºäºå•è°ƒæ ˆçš„è§£æ³•ã€‚ ä¸»ä½“æ€è·¯å¾ˆç®€å•ï¼Œå°±æ˜¯æˆ‘ä»¬å€’ç€æ‰«æè¿™ä¸ªæ•°çš„æ¯ä¸€ä½ï¼Œç»´æŠ¤ä¸€ä¸ªå•è°ƒæ ˆï¼Œè¿™æ ·æ¯æ¬¡æˆ‘ä»¬æ‰«æçš„æ—¶å€™å°±å¯ä»¥çŸ¥é“å½“å‰ç¬¬iä¸ªæ•°æ˜¯å¦æœ‰ä¸‹ä¸€ä¸ªæ¯”ä»–å¤§çš„æ•°ã€‚å¦‚æœæœ‰æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ•°ç»„ansè®°å½•æ¯”ä»–å¤§çš„æ•°çš„ç´¢å¼•ã€‚æœ€åæ­£ç€æ‰«ä¸€éæ•°ç»„ï¼Œå¦‚æœç¢°åˆ°ç¬¬ä¸€ä¸ªç¬¬iiiä¸ªæ•°çš„ans[i]ä¸­å­˜å‚¨äº†ç´¢å¼•ï¼Œåˆ™è¿›è¡Œäº¤æ¢æ“ä½œå³å¯ã€‚ æ³¨æ„åˆ¤æ–­å‡ºæ ˆçš„æ—¶å€™æ˜¯&gt;&gt;&gt;ä¸æ˜¯&gt;=&gt;=&gt;=ï¼Œè¿™æ˜¯å› ä¸ºå½“å€¼ä¸€æ ·æ—¶ï¼Œæ¢æ›´åé¢çš„æ˜¾ç„¶æ›´ä¼˜ï¼Œæœ€ååˆ¤æ–­å½“å‰æ•°å­˜ä¸å­˜ç´¢å¼•çš„æ—¶å€™ä¸€å®šè¦åˆ¤æ–­å½“å‰æ•°å’Œæ ˆåº•æ•°çš„å¤§å°å…³ç³»ï¼ˆå› ä¸ºæœ‰å¯èƒ½ä¸€æ ·å¤§ï¼Œè¿™æ—¶å°±ä¸éœ€è¦è¿›è¡Œäº¤æ¢ï¼‰ æœ€åä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223class Solution &#123;public: int maximumSwap(int num) &#123; string num_s = to_string(num); int n = num_s.size(); vector&lt;int&gt; stk; vector&lt;int&gt; ans(n,-1); for(int i=n-1;i&gt;=0;--i)&#123; while(!stk.empty() &amp;&amp; num_s[i]-&#x27;0&#x27; &gt; num_s[stk[stk.size()-1]] - &#x27;0&#x27;)stk.pop_back(); if (!stk.empty() &amp;&amp; num_s[i]-&#x27;0&#x27; &lt; num_s[stk[0]] - &#x27;0&#x27;) ans[i] = stk[0]; stk.emplace_back(i); &#125; for(int i=0;i&lt;n;++i)&#123; if (ans[i]!=-1) &#123; int tmp = num_s[ans[i]]-&#x27;0&#x27;; num_s[ans[i]] = num_s[i]; num_s[i] = tmp + &#x27;0&#x27;; break; &#125; &#125; return stoi(num_s); &#125;&#125;; 2023-01-23 é¢˜ç›®ä¼ é€é—¨ï¼š2765. æœ€é•¿äº¤æ›¿å­æ•°ç»„ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ç­¾åˆ°é¢˜ç›®ï¼Œä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223class Solution &#123;public: int alternatingSubarray(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(),pre = nums[0]; int ans = -1; for(int i=1;i&lt;n;++i)&#123; if (nums[i] == pre+1) &#123; int tmp = 2; pre = nums[i]; int dir = -1; while (i+1&lt;n &amp;&amp; pre + dir == nums[i+1])&#123; dir *= -1; i += 1; pre = nums[i]; tmp ++; &#125; ans = max(ans,tmp); &#125; pre = nums[i]; &#125; return ans; &#125;&#125;; 2024-01-24 é¢˜ç›®ä¼ é€é—¨ï¼š2865. ç¾ä¸½å¡” I - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜åŒæ ·ä¹Ÿæ˜¯ä¸€é“å•è°ƒæ ˆçš„é¢˜ç›®ï¼Œè¿˜æ˜¯æœ‰ç‚¹æ„æ€ã€‚ 1 2024-01-25 é¢˜ç›®ä¼ é€é—¨ï¼š2859. è®¡ç®— K ç½®ä½ä¸‹æ ‡å¯¹åº”å…ƒç´ çš„å’Œ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“ä½è¿ç®—ç­¾åˆ°é¢˜ç›®ï¼Œç»Ÿè®¡äºŒè¿›åˆ¶æ•°æœ‰å¤šå°‘ä¸ªç½®ä½ï¼Œåªéœ€è¦&amp;1å’Œå³ç§»å³å¯ã€‚ 123456789101112131415161718192021class Solution &#123;public: int sumIndicesWithKSetBits(vector&lt;int&gt;&amp; nums, int k) &#123; int n = nums.size(); function&lt;int(int)&gt;bitCount = [&amp;](int i)&#123; int nw = 0; while(i)&#123; nw += i&amp;1; i = i&gt;&gt;1; &#125; return nw; &#125;; int ans = 0; for(int i=0;i&lt;n;++i)&#123; if (bitCount(i)==k) &#123; ans += nums[i]; &#125; &#125; return ans; &#125;&#125;; 2024-01-26 é¢˜ç›®ä¼ é€é—¨ï¼š"},{"title":"2024å¹´03æœˆæ¯æ—¥ä¸€é¢˜","path":"/wiki/LeetCode/æ¯æ—¥ä¸€é¢˜/2024å¹´03æœˆæ¯æ—¥ä¸€é¢˜.html","content":"2024-03-01 é¢˜ç›®ä¼ é€é—¨ï¼š2369. æ£€æŸ¥æ•°ç»„æ˜¯å¦å­˜åœ¨æœ‰æ•ˆåˆ’åˆ† - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ éå¸¸åŸºç¡€çš„DPï¼ŒDPæ–¹ç¨‹å¦‚ä¸‹ï¼š 123if (nums[i-1] == nums[i-2]) dp[i] = dp[i]||dp[i-2];if (nums[i-1] == nums[i-2]&amp;&amp;nums[i-2] == nums[i-3]) dp[i] = dp[i]||dp[i-3];if (nums[i-1] == nums[i-2]+1 &amp;&amp; nums[i-2] == nums[i-3]+1) dp[i] = dp[i]||dp[i-3]; å…¶ä¸­dp[i]ä»£è¡¨çš„æ˜¯åˆ°ç¬¬iä¸ªæ•°å‰é¢çš„æ•°èƒ½å¦è¢«åˆ’åˆ†ã€‚åˆå§‹æ¡ä»¶dp[0]=true;dp[1]=falseï¼Œç„¶ådp[2]çš„å–å€¼ï¼Œå–å†³äºç¬¬ä¸€ä¸ªå…ƒç´ å’Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯å¦ç›¸ç­‰ï¼Œä»3å¼€å§‹é€’æ¨ã€‚ æœ€åå®ç°ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516class Solution &#123;public: bool validPartition(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); if (n &lt; 2) return false; vector&lt;bool&gt; dp(n+1,false); dp[0] = true; dp[1] = false; if (nums[0]==nums[1]) dp[2] = true; for(int i=3; i&lt;=n; ++i) &#123; if (nums[i-1] == nums[i-2]) dp[i] = dp[i]||dp[i-2]; if (nums[i-1] == nums[i-2]&amp;&amp;nums[i-2] == nums[i-3]) dp[i] = dp[i]||dp[i-3]; if (nums[i-1] == nums[i-2]+1 &amp;&amp; nums[i-2] == nums[i-3]+1) dp[i] = dp[i]||dp[i-3]; &#125; return dp[n]; &#125;&#125;; 2024-03-02 é¢˜ç›®ä¼ é€é—¨ï¼š2368. å—é™æ¡ä»¶ä¸‹å¯åˆ°è¾¾èŠ‚ç‚¹çš„æ•°ç›® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ DFSæ·±æœï¼Œå¯¹äºæ¯ä¸ªèŠ‚ç‚¹è¿”å›ä»¥å½“å‰èŠ‚ç‚¹ä¸ºå­æ ‘å¯ä»¥è®¿é—®çš„èŠ‚ç‚¹æ•°é‡ã€‚ å®ç°ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021class Solution &#123;public: int reachableNodes(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges, vector&lt;int&gt;&amp; restricted) &#123; vector&lt;bool&gt; vis(n, false); for(auto &amp;node:restricted) vis[node] = true; vector&lt;vector&lt;int&gt;&gt; es(n); for(auto &amp;edge:edges)&#123; es[edge[0]].push_back(edge[1]); es[edge[1]].push_back(edge[0]); &#125; function&lt;int(int,int)&gt; dfs = [&amp;](int u, int fa)&#123; int now = 1; for(auto &amp;v:es[u])&#123; if (vis[v]||v == fa) continue; now += dfs(v, u); &#125; return now; &#125;; return dfs(0, -1); &#125;&#125;; 2024-03-09 é¢˜ç›®ä¼ é€é—¨ï¼š2386. æ‰¾å‡ºæ•°ç»„çš„ç¬¬ K å¤§å’Œ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ 2024-03-10 é¢˜ç›®ä¼ é€é—¨ï¼š299. çŒœæ•°å­—æ¸¸æˆ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æ€è·¯æ¯”è¾ƒç®€å•çš„ä¸€é“é¢˜ï¼Œå…¶å®æˆ‘ä»¬åªéœ€è¦éå†ï¼Œå¯¹äºä¸¤ä¸ªå­—ç¬¦ä¸²ç›¸åŒä½ç½®å¦‚æœä¸€è‡´ä¸ç”¨ç®¡ï¼Œä¸ä¸€æ ·ï¼Œåˆ†åˆ«å­˜å…¥å¯¹åº”çš„10ä¸ªæ¡¶ä¸­ï¼ˆåˆ†åˆ«ä»£è¡¨æ¯ä¸ªå­—ç¬¦ä¸²ä¸­0~9çš„ä¸ªæ•°ï¼‰ï¼Œæœ€åæ¯”è¾ƒå¯¹åº”ä½ç½®æ¡¶çš„å¤§å°å³å¯ã€‚ æ³¨æ„ï¼šC++å­—fwç¬¦å¸¸é‡ä½¿ç”¨''ï¼Œå­—ç¬¦ä¸²å¸¸é‡ä½¿ç”¨&quot;&quot; ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819class Solution &#123; public: string getHint(string secret, string guess) &#123; vector&lt;int&gt; buk_sec(10,0),buk_gue(10,0); int a = 0; for (int i=0;i&lt;secret.size();++i) &#123; if(secret[i]==guess[i]) a++; else &#123; buk_sec[secret[i]-&#x27;0&#x27;]++; buk_gue[guess[i]-&#x27;0&#x27;]++; &#125; &#125; int b = 0; for(int i=0;i&lt;10;++i)&#123; b += min(buk_sec[i],buk_gue[i]); &#125; return to_string(a)+&quot;A&quot;+to_string(b)+&quot;B&quot;; &#125; &#125;; 2024-03-11 é¢˜ç›®ä¼ é€é—¨ï¼š2129. å°†æ ‡é¢˜é¦–å­—æ¯å¤§å†™ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜ä½œä¸ºä¸€é“åŸºç¡€æ¨¡æ‹Ÿé¢˜ï¼Œæ•´ä½“æ€è·¯å¹¶ä¸å¤æ‚ï¼Œæˆ‘å°†æ€è·¯åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€é˜¶æ®µå°†æ¯ä¸ªå•è¯ç¬¬ä¸€ä¸ªå­—æ¯éƒ½å¤§å†™ï¼Œç„¶åå°†æ‰€æœ‰éé¦–å­—æ¯çš„éƒ¨åˆ†éƒ½å°å†™ã€‚ç¬¬äºŒé˜¶æ®µåˆ¤æ–­æ¯ä¸ªå•è¯çš„é•¿åº¦ï¼Œå¦‚æœé•¿åº¦å°äºç­‰äº2ï¼Œåˆ™å°†è¯¥å•è¯é¦–å­—æ¯å°å†™ã€‚ æ³¨æ„è¿™é‡Œè½¬æ¢å¤§å†™å’Œè½¬æ¢å°å†™å¯ä»¥ä½¿ç”¨toupperå’Œtolowerå‡½æ•° å› æ­¤æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 123456789101112131415161718192021222324252627282930class Solution &#123;public: string capitalizeTitle(string title) &#123; int n = title.size(); bool flag = true; // å…ˆå°†æ‰€æœ‰å•è¯çš„æ‰€æœ‰é¦–å­—æ¯å¤§å†™ for(auto &amp;let:title)&#123; if (let == &#x27; &#x27;) &#123; flag = true; continue; &#125; if(flag == true)&#123; flag = false; let=toupper(let); &#125; else &#123; let=tolower(let); &#125; &#125; int len = title.size(); // å†åˆ¤æ–­æ‰€æœ‰å•è¯æ˜¯å¦æ»¡è¶³å°äºç­‰äº2ï¼Œå¦‚æœæ»¡è¶³å°±å°†æœ€å‰é¢çš„å­—ç¬¦å˜ä¸ºå°å†™ for(int i=0;i&lt;len;++i)&#123; if (title[i] == &#x27; &#x27;) continue; int tmp = i; while(tmp&lt;len&amp;&amp;title[tmp]!=&#x27; &#x27;) tmp++; if(tmp-i&lt;=2) title[i] = tolower(title[i]); i = tmp; &#125; return title; &#125;&#125;;"},{"title":"2024å¹´04æœˆæ¯æ—¥ä¸€é¢˜","path":"/wiki/LeetCode/æ¯æ—¥ä¸€é¢˜/2024å¹´04æœˆæ¯æ—¥ä¸€é¢˜.html","content":"2024-04-01 é¢˜ç›®ä¼ é€é—¨ï¼š2810. æ•…éšœé”®ç›˜ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“åŒç«¯é˜Ÿåˆ—æ•°æ®ç»“æ„é¢˜ï¼Œæˆ‘ä»¬æ¢ä¸€ç§æ€è·¯æ¥æƒ³ï¼Œå¦‚æœé‡ä¸Šå­—ç¬¦iï¼Œæ—‹è½¬ä¹‹å‰çš„æ‰€æœ‰å­—ç¬¦ç›¸å½“äºæ¢ä¸€ä¸ªæ–¹å‘è¿›è¡Œæ’å…¥æ“ä½œï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåŒç«¯é˜Ÿåˆ—æ¥æ¨¡æ‹Ÿè¿™ä¸ªæ“ä½œã€‚ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617class Solution &#123;public: string finalString(string s) &#123; deque&lt;char&gt; q; bool head = false; for (auto ch:s)&#123; if(ch!=&#x27;i&#x27;)&#123; if (head) q.push_front(ch); else q.push_back(ch); &#125; else &#123; head = !head; &#125; &#125; string ans = (head ? string&#123;q.rbegin(), q.rend()&#125; : string&#123;q.begin(), q.end()&#125;); return ans; &#125;&#125;; 2024-04-02 é¢˜ç›®ä¼ é€é—¨ï¼š894. æ‰€æœ‰å¯èƒ½çš„çœŸäºŒå‰æ ‘ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜æš´éœ²å‡ºè‡ªå·±å¯¹äºåˆ†æ²»ç®—æ³•è¿˜æ˜¯æœ‰ä¸€äº›é—å¿˜ï¼Œéœ€è¦å¤šåŠ ç»ƒä¹ ã€‚æ•´ä½“æ€è·¯æ¯”è¾ƒç®€å•ï¼Œåœ¨æ¯å±‚é€’å½’ä¸­ï¼Œå¦‚æœå½“å‰ä¸å‰©ä½™èŠ‚ç‚¹ï¼Œåˆ™è¿”å›ç©ºæ•°ç»„ï¼ˆå…¶å®è¿™ä¸ªåˆ¤æ–­åªä¼šåœ¨ç¬¬ä¸€æ¬¡è¿›è¡Œï¼Œåé¢ä¿è¯å·¦å³èŠ‚ç‚¹åˆ†åˆ°çš„ä¸ªæ•°éƒ½ä¸ºå¥‡æ•°ï¼Œå› ä¸ºå¶æ•°è‚¯å®šä¸æ»¡è¶³æ¡ä»¶ï¼‰ï¼Œå¦‚æœåªå‰©1ä¸ªï¼Œåˆ™è‡ªå·±å½“å¶å­èŠ‚ç‚¹ï¼Œå¦åˆ™æšä¸¾å·¦å³ä¸¤è¾¹èŠ‚ç‚¹æ•°é‡ã€‚ç„¶åè¿›è¡Œä¸‹ä¸€è½®é€’å½’ã€‚ä¸‹ä¸€å±‚é€’å½’ä¼šè¿”å›ä¸€ä¸ªvectorï¼Œä»£è¡¨ä¸åŒçš„å·¦å³å­æ ‘ã€‚ç„¶ååªéœ€æ’åˆ—ç»„ä¼šä¸€ä¸‹ä¾¿å¯å¾—åˆ°è¿™ä¸€å±‚çš„æ‰€æœ‰å­æ ‘å½¢çŠ¶ï¼Œå°è£…æˆvectorå¾€ä¸Šè¿”å›å³å¯ã€‚ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627282930313233/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;TreeNode*&gt; allPossibleFBT(int n) &#123; vector&lt;TreeNode*&gt; ans; if (n % 2 == 0) return ans; if (n == 1) &#123; ans = &#123;new TreeNode(0)&#125;; return ans; &#125; for(int i=1; i&lt;n; i+=2)&#123; vector&lt;TreeNode*&gt; left_ans = allPossibleFBT(i); vector&lt;TreeNode*&gt; right_ans = allPossibleFBT(n-1-i); for(TreeNode* lnode:left_ans)&#123; for(TreeNode* rnode:right_ans)&#123; TreeNode *root = new TreeNode(0, lnode, rnode); ans.push_back(root); &#125; &#125; &#125; return ans; &#125;&#125;; 2024-04-03 é¢˜ç›®ä¼ é€é—¨ï¼š1379. æ‰¾å‡ºå…‹éš†äºŒå‰æ ‘ä¸­çš„ç›¸åŒèŠ‚ç‚¹ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“ç®€å•çš„éå†é¢˜ç›®ï¼Œæˆ‘ä»¬åªéœ€è¦åœ¨é€’å½’éå†çš„æ—¶å€™è®©å…‹éš†æ ‘æ‰§è¡Œå’ŒåŸæ ‘ä¸€æ ·çš„æ“ä½œå³å¯ã€‚åœæ­¢æ¡ä»¶å°±æ˜¯å½“å…‹éš†æ ‘èŠ‚ç‚¹å¯¹åº”çš„åŸæ ‘ä½ç½®çš„èŠ‚ç‚¹ç­‰äºç›®æ ‡èŠ‚ç‚¹æ—¶è¿”å›å…‹éš†æ ‘èŠ‚ç‚¹æŒ‡é’ˆã€‚ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* getTargetCopy(TreeNode* original, TreeNode* cloned, TreeNode* target) &#123; if (target==original) return cloned; if (original-&gt;left!=nullptr)&#123; TreeNode* tmp = getTargetCopy(original-&gt;left,cloned-&gt;left, target); if(tmp != nullptr) return tmp; &#125; if (cloned-&gt;right!=nullptr)&#123; TreeNode* tmp = getTargetCopy(original-&gt;right,cloned-&gt;right, target); if(tmp != nullptr) return tmp; &#125; return static_cast&lt;TreeNode*&gt;(nullptr); &#125;&#125;; 2024-04-04 é¢˜ç›®ä¼ é€é—¨ï¼š2192. æœ‰å‘æ— ç¯å›¾ä¸­ä¸€ä¸ªèŠ‚ç‚¹çš„æ‰€æœ‰ç¥–å…ˆ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“è¾ƒä¸ºæ˜æ˜¾çš„æ‹“æ‰‘æ’åºæ¿å­é¢˜ç›®ï¼Œè¿™é‡Œåœ¨åˆå¹¶ç¥–å…ˆçš„æ—¶å€™ä½¿ç”¨äº†vectorçš„insertæ–¹æ³•ã€‚è¯¦æƒ…ç”¨æ³•å¯è§C++-&gt;vector-&gt;insertéƒ¨åˆ†çš„ä»‹ç»ã€‚ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; getAncestors(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges) &#123; vector&lt;int&gt; in(n,0); vector&lt;vector&lt;int&gt;&gt; anc(n); vector&lt;vector&lt;int&gt;&gt; e(n); for(auto &amp; edge:edges)&#123; in[edge[1]]++; e[edge[0]].push_back(edge[1]); &#125; queue&lt;int&gt; que; for(int i=0;i&lt;n;++i)&#123; if (in[i]==0) que.push(i); &#125; while (!que.empty()) &#123; int u = que.front(); que.pop(); for(auto &amp;v:e[u])&#123; anc[v].push_back(u); anc[v].insert(anc[v].end(),anc[u].begin(),anc[u].end()); sort(anc[v].begin(),anc[v].end()); auto nwend = unique(anc[v].begin(),anc[v].end()); anc[v].erase(nwend, anc[v].end()); in[v]--; if (in[v]==0) que.push(v); &#125; &#125; return anc; &#125;&#125;; 2024-04-05 é¢˜ç›®ä¼ é€é—¨ï¼š1026. èŠ‚ç‚¹ä¸å…¶ç¥–å…ˆä¹‹é—´çš„æœ€å¤§å·®å€¼ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è‡ªåº•å‘ä¸Šè¿›è¡ŒDFSï¼Œå¯¹äºå½“å‰èŠ‚ç‚¹ï¼Œè°ƒç”¨dfsåè¿”å›ä»¥æ‰€æœ‰å„¿å­ä¸ºæ ¹çš„å­æ ‘çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ï¼Œç„¶åæ›´æ–°ä»¥å½“å‰èŠ‚ç‚¹ä¸ºæ ¹çš„å­æ ‘çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ã€‚åœ¨é€’å½’çš„è¿‡ç¨‹ä¸­ï¼Œç»´æŠ¤æœ€å¤§å·®å€¼ã€‚æœ€å¤§å·®å€¼ansansanså¯ä»¥è¡¨è¿°ä¸ºï¼š ans=maxâ¡(maxx,ans)ans = \\max(maxx,ans) ans=max(maxx,ans) maxx=maxâ¡(abs(å½“å‰èŠ‚ç‚¹å€¼âˆ’å½“å‰èŠ‚ç‚¹ä¸ºæ ¹å­æ ‘æœ€å¤§å€¼),abs(å½“å‰èŠ‚ç‚¹å€¼âˆ’å½“å‰èŠ‚ç‚¹ä¸ºæ ¹å­æ ‘æœ€å°å€¼))maxx = \\max(abs(å½“å‰èŠ‚ç‚¹å€¼-å½“å‰èŠ‚ç‚¹ä¸ºæ ¹å­æ ‘æœ€å¤§å€¼),abs(å½“å‰èŠ‚ç‚¹å€¼-å½“å‰èŠ‚ç‚¹ä¸ºæ ¹å­æ ‘æœ€å°å€¼)) maxx=max(abs(å½“å‰èŠ‚ç‚¹å€¼âˆ’å½“å‰èŠ‚ç‚¹ä¸ºæ ¹å­æ ‘æœ€å¤§å€¼),abs(å½“å‰èŠ‚ç‚¹å€¼âˆ’å½“å‰èŠ‚ç‚¹ä¸ºæ ¹å­æ ‘æœ€å°å€¼)) å…¶ä¸­maxxä»£è¡¨æ¯ä¸ªèŠ‚ç‚¹ä¸ºæ ¹çš„å­æ ‘çš„æœ€å¤§å·®å€¼ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819202122232425262728293031323334/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) &#123;&#125; * &#125;; */class Solution &#123;public: int maxAncestorDiff(TreeNode* root) &#123; int maxx = 0; function&lt;pair&lt;int,int&gt;(TreeNode*)&gt; dfs = [&amp;](TreeNode* u) &#123; pair&lt;int,int&gt; tmp = make_pair(u-&gt;val,u-&gt;val); if (u-&gt;left!=nullptr) &#123; pair&lt;int,int&gt; temp = dfs(u-&gt;left); tmp.first = min(min(temp.first, temp.second), tmp.first); tmp.second= max(max(temp.first, temp.second),tmp.second); &#125; if (u-&gt;right!=nullptr) &#123; pair&lt;int,int&gt; temp = dfs(u-&gt;right); tmp.first = min(min(temp.first, temp.second), tmp.first); tmp.second= max(max(temp.first, temp.second),tmp.second); &#125; maxx = max(maxx,max(abs(tmp.first - u-&gt;val),abs(tmp.second - u-&gt;val))); return tmp; &#125;; dfs(root); return maxx; &#125;&#125;; 2024-04-06 é¢˜ç›®ä¼ é€é—¨ï¼š1483. æ ‘èŠ‚ç‚¹çš„ç¬¬ K ä¸ªç¥–å…ˆ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æœ¬é¢˜ç›®æ˜¯ä¸€é“ä½¿ç”¨å€å¢æ€æƒ³çš„DPé¢˜ç›®ã€‚å®šä¹‰ancs[i][j]ä»£è¡¨ièŠ‚ç‚¹çš„ç¬¬2j2^j2jä¸ªç¥–å…ˆï¼Œç„¶åè¿›è¡Œåˆ·è¡¨å³å¯ã€‚ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 12345678910111213141516171819202122232425262728293031323334class TreeAncestor &#123;public: vector&lt;vector&lt;int&gt;&gt; ancs; constexpr static int LOG = 16; TreeAncestor(int n, vector&lt;int&gt;&amp; parent) &#123; ancs = vector&lt;vector&lt;int&gt;&gt;(n,vector&lt;int&gt;(LOG, -1)); for (int i=0; i&lt;n; ++i) &#123; ancs[i][0] = parent[i]; &#125; for (int i=1;i&lt;LOG;++i) &#123; for (int j=0; j&lt;n; ++j)&#123; if (ancs[j][i-1] != -1)&#123; ancs[j][i] = ancs[ancs[j][i-1]][i-1]; &#125; &#125; &#125; &#125; int getKthAncestor(int node, int k) &#123; for(int i=LOG; i&gt;=0; --i)&#123; if ((k&gt;&gt;i)&amp;1) &#123; node = ancs[node][i]; if (node==-1) return -1; &#125; &#125; return node; &#125;&#125;;/** * Your TreeAncestor object will be instantiated and called as such: * TreeAncestor* obj = new TreeAncestor(n, parent); * int param_1 = obj-&gt;getKthAncestor(node,k); */ 2024-04-07 é¢˜ç›®ä¼ é€é—¨ï¼š1600. ç‹ä½ç»§æ‰¿é¡ºåº - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜å…¶å®å°±æ˜¯ä¸€ä¸ªå¤šå‰æ ‘çš„å‰åºéå†ï¼Œä½†æ˜¯å› ä¸ºä½¿ç”¨çš„æ˜¯å­—ç¬¦ä¸²ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨åˆ°unordered_setä»¥åŠunordered_mapç­‰ç›¸å…³STLï¼ˆä½¿ç”¨æ–¹æ³•è§C++æ–‡æ¡£ï¼‰: å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041class ThroneInheritance &#123;private: unordered_map&lt;string, vector&lt;string&gt;&gt; edges; unordered_set&lt;string&gt; dead; string king;public: ThroneInheritance(string kingName) &#123; king = kingName; &#125; void birth(string parentName, string childName) &#123; edges[parentName].push_back(childName); &#125; void death(string name) &#123; dead.insert(name); &#125; vector&lt;string&gt; getInheritanceOrder() &#123; vector&lt;string&gt; ans; function&lt;void(string)&gt; dfs = [&amp;](string u) &#123; if (!dead.count(u)) ans.push_back(u); if (edges.count(u)) &#123; for (auto v:edges[u])&#123; dfs(v); &#125; &#125; &#125;; dfs(king); return ans; &#125;&#125;;/** * Your ThroneInheritance object will be instantiated and called as such: * ThroneInheritance* obj = new ThroneInheritance(kingName); * obj-&gt;birth(parentName,childName); * obj-&gt;death(name); * vector&lt;string&gt; param_3 = obj-&gt;getInheritanceOrder(); */ 2024-04-08 é¢˜ç›®ä¼ é€é—¨ï¼š2009. ä½¿æ•°ç»„è¿ç»­çš„æœ€å°‘æ“ä½œæ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å‡è®¾xxxæ˜¯ä¿®æ”¹åçš„è¿ç»­æ•°å­—çš„æœ€å¤§å€¼ï¼Œåˆ™ä¿®æ”¹åçš„è¿ç»­æ•°å­—çš„èŒƒå›´ä¸ºé—­åŒºé—´ [xâˆ’n+1,x][xâˆ’n+1,x][xâˆ’n+1,x]ï¼Œå…¶ä¸­ nnn æ˜¯ nums çš„é•¿åº¦ã€‚åœ¨ä¿®æ”¹å‰ï¼Œå¯¹äºå·²ç»åœ¨ [xâˆ’n+1,x][xâˆ’n+1,x][xâˆ’n+1,x] ä¸­çš„æ•°ï¼Œæˆ‘ä»¬æ— éœ€ä¿®æ”¹ã€‚é‚£ä¹ˆï¼Œxxx å–å¤šå°‘ï¼Œå¯ä»¥ä½¿æ— éœ€ä¿®æ”¹çš„æ•°æœ€å¤šå‘¢ï¼Ÿ ç”±äºå…ƒç´ çš„ä½ç½®ä¸å½±å“ç­”æ¡ˆï¼Œä¸”è¦æ±‚æ‰€æœ‰å…ƒç´ äº’ä¸ç›¸åŒï¼Œæˆ‘ä»¬å¯ä»¥å°† nums ä»å°åˆ°å¤§æ’åºï¼Œå¹¶å»æ‰é‡å¤å…ƒç´ ã€‚è®¾ a ä¸ºnums æ’åºå»é‡åçš„æ•°ç»„ã€‚å°† a[i] ç”»åœ¨ä¸€æ¡æ•°è½´ä¸Šï¼Œæœ¬é¢˜ç›¸å½“äºæœ‰ä¸€ä¸ªé•¿åº¦ä¸º n çš„æ»‘åŠ¨çª—å£ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—çª—å£å†…æœ€å¤šå¯ä»¥åŒ…å«å¤šå°‘ä¸ªæ•°è½´ä¸Šçš„ç‚¹ã€‚ æœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314class Solution &#123;public: int minOperations(vector&lt;int&gt;&amp; nums) &#123; sort(nums.begin(),nums.end()); int n = nums.size(); int now_n = unique(nums.begin(), nums.end()) - nums.begin(); int ans = 0, r = 0; for (int l=0; l&lt;now_n; ++l) &#123; while (r&lt;now_n &amp;&amp; nums[r]-nums[l] &lt; n) r++; ans = max(r-l, ans); &#125; return n - ans; &#125;&#125;; 2024-04-09 é¢˜ç›®ä¼ é€é—¨ï¼š2529. æ­£æ•´æ•°å’Œè´Ÿæ•´æ•°çš„æœ€å¤§è®¡æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ çº¯ç­¾åˆ°é¢˜ å®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011class Solution &#123;public: int maximumCount(vector&lt;int&gt;&amp; nums) &#123; int a = 0,b = 0; for(auto&amp;num:nums)&#123; if (num&gt;0) a++; if (num&lt;0) b++; &#125; return max(a, b); &#125;&#125;; 2024-04-10 é¢˜ç›®ä¼ é€é—¨ï¼š1702. ä¿®æ”¹åçš„æœ€å¤§äºŒè¿›åˆ¶å­—ç¬¦ä¸² - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜é¢˜è§£å»ºè®®çœ‹çµç¥çš„æ¨ç†æ–¹æ³•ï¼Œè®²è§£çš„ååˆ†é€å½»ã€‚ é¢˜è§£ä¼ é€é—¨ï¼šè´ªå¿ƒï¼Œç®€æ´å†™æ³•ï¼ˆPython/Java/C++/Go/JS/Rustï¼‰ æœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920class Solution &#123;public: string maximumBinaryString(string binary) &#123; int n = binary.size(); int j = 0; for (int i = 0; i &lt; n; i++) &#123; if (binary[i] == &#x27;0&#x27;) &#123; while (j &lt;= i || (j &lt; n &amp;&amp; binary[j] == &#x27;1&#x27;)) &#123; j++; &#125; if (j &lt; n) &#123; binary[j] = &#x27;1&#x27;; binary[i] = &#x27;1&#x27;; binary[i + 1] = &#x27;0&#x27;; &#125; &#125; &#125; return binary; &#125;&#125;; 2024-04-11 é¢˜ç›®ä¼ é€é—¨ï¼š1766. äº’è´¨æ ‘ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜å°±æ˜¯ä¸€é“DFSé¢˜ç›®ï¼Œå› ä¸ºå–å€¼éå¸¸å°ï¼Œæ‰€ä»¥å¯ä»¥å…ˆè¿›è¡Œé¢„å¤„ç†ï¼Œå…ˆæŠŠ50ä»¥å†…æ‰€æœ‰äº’è´¨çš„æ•°é¢„å¤„ç†å‡ºæ¥ã€‚ç”±äºæ ¹èŠ‚ç‚¹åˆ°ä»»æ„èŠ‚ç‚¹çš„æœç´¢è·¯å¾„å°±æ˜¯è¯¥èŠ‚ç‚¹çš„ç¥–å…ˆèŠ‚ç‚¹çš„é›†åˆï¼Œæ‰€ä»¥æœç´¢è·¯å¾„ä¸Šæœ€è¿‘çš„ä¸å…¶äº’è´¨çš„å°±æ˜¯ç­”æ¡ˆã€‚åœ¨æœç´¢éå†æ ‘å¤„ç†ç­”æ¡ˆçš„æ—¶å€™ï¼Œæœ‰è®¸å¤šä¿¡æ¯å¯ä»¥å¤ç”¨ã€‚ æœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solution &#123;private: vector&lt;vector&lt;int&gt;&gt; gcds; vector&lt;vector&lt;int&gt;&gt; tmp; vector&lt;vector&lt;int&gt;&gt; g; vector&lt;int&gt; dep; vector&lt;int&gt; ans;public: void dfs(vector&lt;int&gt; &amp;nums, int x, int depth) &#123; dep[x] = depth; for (int val : gcds[nums[x]]) &#123; if (tmp[val].empty()) &#123; continue; &#125; int las = tmp[val].back(); if (ans[x] == -1 || dep[las] &gt; dep[ans[x]]) &#123; ans[x] = las; &#125; &#125; tmp[nums[x]].push_back(x); for(int val : g[x]) &#123; if (dep[val] == -1) &#123; // è¢«è®¿é—®è¿‡çš„ç‚¹depä¸ä¸º-1 dfs(nums, val, depth + 1); &#125; &#125; tmp[nums[x]].pop_back(); &#125; vector&lt;int&gt; getCoprimes(vector&lt;int&gt;&amp; nums, vector&lt;vector&lt;int&gt;&gt;&amp; edges) &#123; int n = nums.size(); // åˆå§‹åŒ– gcds.resize(51); tmp.resize(51); ans.resize(n, -1); dep.resize(n, -1); g.resize(n); for (int i = 1; i &lt;= 50; i++) &#123; for (int j = 1; j &lt;= 50; j++) &#123; if (gcd(i, j) == 1) &#123; gcds[i].push_back(j); &#125; &#125; &#125; for (const auto &amp;val : edges) &#123; g[val[0]].push_back(val[1]); g[val[1]].push_back(val[0]); &#125; dfs(nums, 0, 1); return ans; &#125;&#125;; 2024-04-12 é¢˜ç›®ä¼ é€é—¨ï¼š2923. æ‰¾åˆ°å† å†› I - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æœ‰ç‚¹åƒæ‹“æ‰‘æ’åºç¬¬ä¸€æ­¥ï¼Œç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„å…¥åº¦ã€‚è¿™é‡Œæˆ‘ä»¬è®¾å®šAæ¯”Bå¼ºï¼Œè¡¨ç¤ºæœ‰ä¸€æ¡è¾¹ç”±AæŒ‡å‘Bã€‚æœ€åæˆ‘ä»¬è¿”å›å…¥åº¦ä¸º0çš„èŠ‚ç‚¹å³å¯ã€‚ æœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718class Solution &#123;public: int findChampion(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int n = grid.size(); vector&lt;int&gt; rank(n,0); for(int i=0; i&lt;n; ++i)&#123; for(int j=0; j&lt;n; ++j)&#123; if (grid[i][j] == 1) &#123; rank[j] ++; &#125; &#125; &#125; for (int i=0; i&lt;n; ++i)&#123; if (rank[i]==0) return i; &#125; return -1; &#125;&#125;; 2024-04-13 é¢˜ç›®ä¼ é€é—¨ï¼š2924. æ‰¾åˆ°å† å†› II - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸æ˜¨å¤©çš„é¢˜ç›®æ€è·¯å®Œå…¨ä¸€æ ·ï¼Œæœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415class Solution &#123;public: int findChampion(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges) &#123; vector&lt;int&gt; ins(n, 0); for(auto &amp;edge:edges) &#123; ins[edge[1]]++; &#125; int cnt = 0, ans = -1; for(int i=0;i&lt;n;++i) &#123; if (ins[i]==0) cnt++,ans=i; &#125; if (cnt == 1) return ans; return -1; &#125;&#125;; 2024-04-14 é¢˜ç›®ä¼ é€é—¨ï¼š705. è®¾è®¡å“ˆå¸Œé›†åˆ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ STLÂ unordered_setÂ ç»ƒä¹ é¢˜ï¼Œæœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617class MyHashSet &#123;private: unordered_set&lt;int&gt; myset;public: MyHashSet() &#123;&#125; void add(int key) &#123;myset.insert(key);&#125; void remove(int key) &#123;myset.erase(key);&#125; bool contains(int key) &#123;return myset.find(key) != myset.end();&#125;&#125;;/** * Your MyHashSet object will be instantiated and called as such: * MyHashSet* obj = new MyHashSet(); * obj-&gt;add(key); * obj-&gt;remove(key); * bool param_3 = obj-&gt;contains(key); */ 2024-04-15 é¢˜ç›®ä¼ é€é—¨ï¼š706. è®¾è®¡å“ˆå¸Œæ˜ å°„ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ STLÂ unordered_mapÂ ç»ƒä¹ é¢˜ï¼Œæœ€ç»ˆå®ç°çš„ä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617181920class MyHashMap &#123;private: unordered_map&lt;int, int&gt; mp;public: void put(int key, int value) &#123;mp[key] = value;&#125; int get(int key) &#123; if (mp.find(key)!=mp.end()) return mp[key]; return -1; &#125; void remove(int key) &#123;mp.erase(key);&#125;&#125;;/** * Your MyHashMap object will be instantiated and called as such: * MyHashMap* obj = new MyHashMap(); * obj-&gt;put(key,value); * int param_2 = obj-&gt;get(key); * obj-&gt;remove(key); */"},{"title":"2023å¹´12æœˆæ¯æ—¥ä¸€é¢˜","path":"/wiki/LeetCode/æ¯æ—¥ä¸€é¢˜/2023å¹´12æœˆæ¯æ—¥ä¸€é¢˜.html","content":"2023-12-01 é¢˜ç›®ä¼ é€é—¨ï¼š2661. æ‰¾å‡ºå æ¶‚å…ƒç´  - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æœ¬é¢˜ä¸»è¦å°±æ˜¯ä¸€ä¸ªå“ˆå¸Œè¡¨çš„æ€æƒ³ï¼Œå…ˆä½¿ç”¨ä¸€ä¸ªmapæ•°æ®ç»“æ„å°†æ¯ä¸ªå…ƒç´ å’Œä»–çš„äºŒç»´ä½ç½®å¯¹åº”èµ·æ¥ï¼Œè¿™æ ·å¯ä»¥å®ç°O(1)æŸ¥è¯¢ï¼Œç„¶åè®¾ç½®ä¸¤ä¸ªæ•°ç»„å¤§å°ä¸ºæ¯è¡Œæ¯åˆ—ï¼Œè®°å½•å½“å‰è¡Œåˆ—è¿˜å‰©çš„æ²¡æŸ“è‰²çš„æ ¼å­çš„æ•°é‡ï¼Œç„¶åéå†arrä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œæ›´æ–°å…ƒç´ å¯¹åº”è¡Œåˆ—å‰©ä½™æœªæŸ“è‰²æ ¼å­çš„ä¸ªæ•°ã€‚å½“å‘ç°å½“å‰å…ƒç´ å¯¹åº”è¡Œåˆ—æœ‰ä¸€ä¸ªæœªæŸ“è‰²æ ¼å­å‰©ä½™é‡ä¸º0æ—¶ï¼Œè¾“å‡ºå³å¯ã€‚ 1234567891011121314151617181920class Solution &#123;public: int firstCompleteIndex(vector&lt;int&gt;&amp; arr, vector&lt;vector&lt;int&gt;&gt;&amp; mat) &#123; int m = mat.size(), n =mat[0].size(); vector&lt;int&gt; row(m,n); vector&lt;int&gt; col(n,m); map&lt;int,pair&lt;int,int&gt;&gt; mp; for(int i=0;i&lt;m;++i)&#123; for(int j=0;j&lt;n;++j)&#123; mp[mat[i][j]] = pair&lt;int, int&gt;(i,j); &#125; &#125; for(int i=0;i&lt;m*n;++i)&#123; int x = mp[arr[i]].first, y = mp[arr[i]].second; row[x]--; col[y]--; if (row[x]==0||col[y]==0) return i; &#125; return m*n-1; &#125;&#125;; 2023-12-02 é¢˜ç›®ä¼ é€é—¨ï¼š1094. æ‹¼è½¦ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸ç»å…¸çš„å·®åˆ†æ•°ç»„é¢˜ï¼Œå…ˆå¯¹ä¸Šä¸‹è½¦ç«™ç‚¹è¿›è¡Œæ’åºï¼Œç„¶åç»´æŠ¤ä¸€ä¸ªä»¥ç«™ç‚¹ä¸ºç´¢å¼•çš„å·®åˆ†æ•°ç»„ï¼Œå‰ç¼€å’Œä»£è¡¨è½¦åˆ°è¾¾å½“å‰ç«™ç‚¹æ—¶ï¼Œè½¦ä¸Šçš„ä¹˜å®¢æ•°ï¼Œä¹˜å®¢æ•°å¤§äºcapacityå³ä¸è¡Œï¼Œå¦åˆ™å°±å¯ä»¥ã€‚ 1234567891011121314151617181920212223class Solution &#123;public: bool carPooling(vector&lt;vector&lt;int&gt;&gt;&amp; trips, int capacity) &#123; vector&lt;int&gt; pass_now(1001,0); // è¿™é‡Œéœ€è¦æ’ä¸€ä¸ªåº sort(trips.begin(),trips.end(),[](vector&lt;int&gt; &amp;a,vector&lt;int&gt; &amp;b)&#123; if(a[1] == b[1])return a[2]&lt;b[2]; else return a[1]&lt;b[1]; &#125;); int max_dis = 0; for(auto &amp;trip:trips)&#123; pass_now[trip[1]] += trip[0]; pass_now[trip[2]] -= trip[0]; max_dis = max(max_dis,trip[2]); &#125; int now = 0; for(int i=0;i&lt;=max_dis;i++)&#123; now += pass_now[i]; if(now&gt;capacity)return false; &#125; return true; &#125;&#125;; 2023-12-03 é¢˜ç›®ä¼ é€é—¨ï¼š1423. å¯è·å¾—çš„æœ€å¤§ç‚¹æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è„‘ç­‹æ€¥è½¬å¼¯é¢˜ç›®ï¼Œæ—¢ç„¶è¦è®©æˆ‘ä»¬æ±‚ä¸¤è¾¹å–çš„æœ€å¤§ï¼Œé‚£ä¹ˆå°±æ˜¯è®©æˆ‘ä»¬åè¿‡æ¥å–ä¸­é—´çš„æœ€å°ã€‚è¿™æ ·å°±ä»å–ä¸è¿ç»­çš„æ•°å˜æˆå–è¿ç»­çš„äº†ã€‚ 123456789101112131415161718class Solution &#123;public: int maxScore(vector&lt;int&gt;&amp; cardPoints, int k) &#123; int sum_point = 0,n = cardPoints.size(); for(auto &amp;cardPoint:cardPoints)sum_point+=cardPoint; int res = n-k; int minn,capa=0,now=0; for(int i=0;i&lt;n;++i)&#123; if (capa&lt;res) now += cardPoints[i], capa += 1; else &#123; if(i == res) minn = now; now = now - cardPoints[i-res] + cardPoints[i]; minn = min(minn,now); &#125; &#125; return sum_point - minn; &#125;&#125;; 2023-12-04 é¢˜ç›®ä¼ é€é—¨ï¼š1038. ä»äºŒå‰æœç´¢æ ‘åˆ°æ›´å¤§å’Œæ ‘ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä»Šå¤©çš„é¢˜è¿˜æ˜¯æœ‰ç‚¹æ„æ€ï¼Œå€Ÿæœºå­¦ä¹ ä¸€ä¸‹C++æŒ‡é’ˆç‰ˆæœ¬çš„äºŒå‰æ ‘å¦‚ä½•ä¹¦å†™, é¢˜ç›®è¦æ±‚æˆ‘ä»¬å°†æ¯ä¸ªèŠ‚ç‚¹çš„å€¼æ›¿æ¢ä¸ºå€¼å¤§äºç­‰äºå½“å‰èŠ‚ç‚¹å€¼çš„å’Œï¼Œé‚£ä¹ˆè¿™ä¸ªæ—¶å€™æˆ‘ä»¬å¯ä»¥ç¨å¾®æ€è€ƒä¸€ä¸‹äºŒå‰æ ‘çš„æ€§è´¨ï¼Œä¸éš¾å‘ç°ï¼Œæˆ‘ä»¬è¿›è¡Œåå‘ä¸­åºéå†æ—¶ï¼Œç”Ÿæˆçš„éå†åºåˆ—å°±æ˜¯ä»å¤§åˆ°å°çš„ä¸€ä¸ªæ’åºã€‚é‚£ä¹ˆæˆ‘ä»¬æŒ‰ç…§è¿™ä¸ªé¡ºåºæ›´æ–°æ¯ä¸€ä¸ªèŠ‚ç‚¹å³å¯ã€‚ 123456789101112131415161718192021222324/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) &#123;&#125; * &#125;; */class Solution &#123;public: int sumnow = 0; TreeNode* bstToGst(TreeNode* root) &#123; if (root!=nullptr) &#123; if (root-&gt;right!=nullptr) bstToGst(root-&gt;right); sumnow += root-&gt;val; root-&gt;val = sumnow; if (root-&gt;left!=nullptr) bstToGst(root-&gt;left); &#125; return root; &#125;&#125;; 2023-12-05 é¢˜ç›®ä¼ é€é—¨ï¼š2477. åˆ°è¾¾é¦–éƒ½çš„æœ€å°‘æ²¹è€— - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä»Šå¤©çš„é¢˜ç›®è¿˜æ˜¯æœ‰ç‚¹æ„æ€ï¼Œæ„Ÿè§‰æ˜¯ä¹‹å‰ä¸€ä¸ªå‘¨èµ›æ²¡åšå‡ºæ¥çš„é¢˜ç›®ï¼Œå› ä¸ºé¢˜ç›®ä¸­è¿˜æ˜¯æœ‰ä¸€äº›ç»†èŠ‚éœ€è¦æ³¨æ„ï¼Œè¿™é‡Œå°±ç¨å¾®æ¢³ç†ä¸€ä¸‹ã€‚ é¦–å…ˆå­¦ä¹ äº†C++å†…åµŒå‡½æ•°çš„å†™æ³•ã€‚ æ¨¡æ¿å†™æ³•å¤§æ¦‚å¦‚ä¸‹æ‰€ç¤ºï¼š 1function&lt;int(int, int)&gt; dfs = [&amp;](int u,int fa) -&gt; int &#123; ä¸Šé¢çš„ä»£ç ï¼Œå®šä¹‰äº†ä¸€ä¸ªåä¸º dfs çš„å‡½æ•°ï¼Œå®ƒæ¥å—ä¸¤ä¸ªæ•´æ•°å‚æ•° u å’Œ faï¼Œè¿”å›ä¸€ä¸ªæ•´æ•°å€¼ã€‚è¿™ä¸ªå‡½æ•°æ˜¯ä¸€ä¸ªåŒ¿åå‡½æ•°ï¼ˆå³æ²¡æœ‰åç§°çš„å‡½æ•°ï¼‰ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ¨¡æ¿å‡½æ•°ï¼Œæ¨¡æ¿å‚æ•° int(int, int) è¡¨ç¤ºè¯¥å‡½æ•°æ¥å—ä¸¤ä¸ªæ•´æ•°å‚æ•°å¹¶è¿”å›ä¸€ä¸ªæ•´æ•°å€¼ã€‚ ä»£ç ä¸­çš„ -&gt; ç¬¦å·è¡¨ç¤ºå‡½æ•°çš„è¿”å›ç±»å‹ï¼Œå®ƒä½äºå‡½æ•°å®šä¹‰çš„æœ«å°¾ã€‚int(int, int) æ˜¯å‡½æ•°çš„å‚æ•°ç±»å‹ï¼Œint è¡¨ç¤ºè¿”å›å€¼ç±»å‹ï¼Œint å’Œ int åˆ†åˆ«è¡¨ç¤ºä¸¤ä¸ªå‚æ•°çš„ç±»å‹ã€‚ [&amp;](int u,int fa) -&gt; int è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªå·¦å€¼å¼•ç”¨æ•è·çš„åŒ¿åå‡½æ•°ï¼Œå®ƒæ•è·äº†å‡½æ•°å¤–éƒ¨çš„å˜é‡ u å’Œ fa çš„å¼•ç”¨ã€‚è¿™ä½¿å¾—åœ¨å‡½æ•°å†…éƒ¨å¯ä»¥ä¿®æ”¹è¿™äº›å˜é‡çš„å€¼ï¼Œè€Œä¸ä¼šå½±å“åˆ°å‡½æ•°å¤–çš„å˜é‡ã€‚ æ€»ä¹‹ï¼Œè¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º dfs çš„åŒ¿åå‡½æ•°ï¼Œå®ƒæ¥å—ä¸¤ä¸ªæ•´æ•°å‚æ•° u å’Œ faï¼Œè¿”å›ä¸€ä¸ªæ•´æ•°å€¼ã€‚è®°ä½ä»¥åéƒ½è¿™ä¹ˆå†™å°±å¯¹å•¦ã€‚(è¿˜æœ‰éœ€è¦æ³¨æ„çš„å°±æ˜¯ï¼Œæœ€å&#125;åéœ€è¦åŠ ;) æ¥ä¸‹æ¥å°±æ˜¯æœ¬é¢˜çš„ä¸€äº›è§£é¢˜æ„Ÿæƒ³äº†ï¼Œå› ä¸ºæ˜¯æ ‘å½¢ç»“æ„ï¼Œæ‰€ä»¥ä¸éš¾æƒ³åˆ°ä¼šç”¨é€’å½’è¿™ç§ç®—æ³•ï¼Œåœ¨æœ¬é¢˜ä¸­é€’å½’æˆ‘ä»¬å›æº¯çš„æ—¶å€™ä¼ é€’å­æ ‘å¤§å°ã€‚åŒæ—¶æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå˜é‡ç”¨äºå­˜å‚¨æœ€ç»ˆçš„è€—æ²¹é‡ï¼Œ æœ¬é¢˜å¤§è‡´æ€è·¯å°±æ˜¯ï¼Œå¯¹äºå½“å‰èŠ‚ç‚¹åœ¨ä½¿ç”¨é€’å½’å·²çŸ¥å…¶å­æ ‘å¤§å°åï¼Œå†ç”¨è€—æ²¹é‡å˜é‡åŠ ä¸Šå½“å‰èŠ‚ç‚¹æŒ‡å‘å…¶çˆ¶äº²èŠ‚ç‚¹é‚£æ¡è¾¹ä¸Šçš„è€—æ²¹é‡ï¼Œè¯¥è€—æ²¹é‡è®¡ç®—æ–¹å¼å¦‚ä¸‹ï¼š oil=ceil((size+1)/seats)oil = ceil((size+1)/seats) oil=ceil((size+1)/seats) å…¶ä¸­sizeä¸ºå½“å‰èŠ‚ç‚¹å­æ ‘å¤§å°ï¼Œceilæ˜¯å‘ä¸Šå–æ•´æ“ä½œ æœ€åä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718192021222324252627class Solution &#123;public: long long minimumFuelCost(vector&lt;vector&lt;int&gt;&gt;&amp; roads, int seats) &#123; vector&lt;vector&lt;int&gt;&gt; edge(roads.size()+1); for(auto &amp;road:roads) &#123; int u = road[0],v = road[1]; edge[u].push_back(v); edge[v].push_back(u); &#125; long long ans = 0; function&lt;int(int, int)&gt; dfs = [&amp;](int u,int fa) -&gt; int &#123; if (edge[u].size()==1&amp;&amp;u!=0)&#123; ans += 1; return 1; &#125; int size = 0; for (auto &amp;v:edge[u])&#123; if (v == fa) continue; size += dfs(v,u); &#125; if (u!=0) ans += (size) / seats + 1; // ceil((size+1)/seats) return size+1; &#125;; dfs(0,-1); return ans; &#125;&#125;; 2023-12-06 é¢˜ç›®ä¼ é€é—¨ï¼š2646. æœ€å°åŒ–æ—…è¡Œçš„ä»·æ ¼æ€»å’Œ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä»Šå¤©çš„é¢˜ç›®è¿˜æ˜¯æœ‰ç‚¹æœ‰æ„æ€ï¼Œä¸€é“æ ‘å½¢DPè®°å½•ä¸€ä¸‹ã€‚é¦–å…ˆæˆ‘ä»¬éœ€è¦æŠ“ä½ä¸€ä¸ªè¦ç‚¹å°±æ˜¯ï¼Œå› ä¸ºæ˜¯åœ¨æ ‘ä¸Šï¼Œæ‰€ä»¥è·¯å¾„æ˜¯å”¯ä¸€çš„ã€‚æ‰€ä»¥è§£æœ¬é¢˜çš„ç¬¬ä¸€æ­¥æ˜¯ç»Ÿè®¡èµ°å®Œæ‰€æœ‰çš„tripæ—¶ï¼Œæ ‘ä¸Šçš„æ¯ä¸ªèŠ‚ç‚¹è¢«èµ°è¿‡å¤šå°‘æ¬¡ã€‚ç¬¬ä¸€æ­¥å°±æ˜¯ä¸€ä¸ªç®€å•çš„dfsæœç´¢ï¼Œå½“æœç´¢åˆ°æ­£ç¡®çš„è·¯å¾„åï¼Œå›æº¯æ—¶å°†è·¯å¾„ä¸Šæ¯ä¸ªèŠ‚ç‚¹ç»è¿‡çš„æ¬¡æ•°+1ã€‚ ç»è¿‡ç¬¬ä¸€æ­¥åï¼Œæˆ‘ä»¬å°±å¯ä»¥é‡æ–°è®¡ç®—æ¯ä¸ªç‚¹çš„ä»£ä»·ï¼Œå°±æ˜¯ç”¨åŸæ¥æ¯ä¸ªç‚¹çš„ä»·æ ¼ä¹˜ä¸Šæ¬¡æ•°ã€‚ç„¶åå°±è¿›å…¥ä¸€ä¸ªæ ‡å‡†çš„æ ‘å½¢DPæŸ“è‰²é—®é¢˜äº†ã€‚å®šä¹‰dpæ•°ç»„dp[i][j]å…¶ä¸­iä»£è¡¨çš„æ˜¯å½“å‰èŠ‚ç‚¹ï¼Œjå–å€¼èŒƒå›´æ˜¯0ï¼Œ1ã€‚0ä»£è¡¨çš„æ˜¯å½“å‰èŠ‚ç‚¹ä¸ä¼˜æƒ ï¼Œ1ä»£è¡¨çš„æ˜¯å½“å‰èŠ‚ç‚¹æŸ“è‰²ã€‚çŠ¶æ€è½¬ç§»æ–¹ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š dp[u][0]=(âˆ‘min(dp[v][0],dp[v][1]))+cost[u]dp[u][0] = (\\sum min(dp[v][0],dp[v][1]))+ cost[u] dp[u][0]=(âˆ‘min(dp[v][0],dp[v][1]))+cost[u] dp[u][1]=(âˆ‘dp[v][0])+cost[u]/2dp[u][1] = (\\sum dp[v][0]) + cost[u]/2 dp[u][1]=(âˆ‘dp[v][0])+cost[u]/2 å…¶ä¸­væ˜¯uçš„å„¿å­ æ›´æ–°å°±æ˜¯å’Œä¼ ç»Ÿæ ‘å½¢DPä¸€æ ·æ˜¯åœ¨è¿›è¡Œé€’å½’åå›æº¯çš„æ—¶å€™æ›´æ–°ã€‚ æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: int minimumTotalPrice(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges, vector&lt;int&gt;&amp; price, vector&lt;vector&lt;int&gt;&gt;&amp; trips) &#123; vector&lt;int&gt; nums(n+1,0); vector&lt;vector&lt;int&gt;&gt; edge(n+1); for(auto &amp;tmp:edges)&#123; int u = tmp[0], v = tmp[1]; edge[u].push_back(v); edge[v].push_back(u); &#125; function&lt;bool(int,int,int)&gt; dfs = [&amp;](int u,int fa,int tar) &#123; if (u == tar)&#123; nums[u]++; return true; &#125; for(auto &amp;v:edge[u])&#123; if (v==fa) continue; if (dfs(v,u,tar)) &#123; nums[u]+=1; return true; &#125; &#125; return false; &#125;; for(auto &amp;trip:trips) &#123; dfs(trip[0],-1,trip[1]); &#125; vector&lt;vector&lt;int&gt;&gt; dp(n+1,vector&lt;int&gt;(2,0)); function &lt;void(int,int)&gt; dfs_dp = [&amp;](int u,int fa) &#123; dp[u][0] = price[u]*nums[u]; dp[u][1] = price[u]*nums[u]/2; for(auto &amp;v:edge[u])&#123; if (v==fa) continue; dfs_dp(v,u); dp[u][0] += min(dp[v][0],dp[v][1]); dp[u][1] += dp[v][0]; &#125; &#125;; dfs_dp(0,-1); return min(dp[0][0],dp[0][1]); &#125;&#125;; 2023-12-07 é¢˜ç›®ä¼ é€é—¨ï¼š1466. é‡æ–°è§„åˆ’è·¯çº¿ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æ­¤é¢˜å°±æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„æ ‘çš„éå†é¢˜ç›®ï¼Œæˆ‘ä»¬åªéœ€è¦åˆ¤æ–­éå†è¿‡ç¨‹ä¸­ï¼Œè¾¹çš„æ–¹å‘ï¼Œç„¶åå†³å®šæ˜¯å¦è¦åè½¬å³å¯ã€‚ æ³¨æ„æœ¬é¢˜ä¸­pairç›¸å…³çš„å†™æ³•ï¼Œå‹å…¥vectorçš„æ—¶å€™ä½¿ç”¨çš„æ˜¯{}ï¼Œforå¾ªç¯æå–å‡ºæ¥çš„æ—¶å€™ä½¿ç”¨çš„æ˜¯[] 123456789101112131415161718192021class Solution &#123;public: int minReorder(int n, vector&lt;vector&lt;int&gt;&gt;&amp; connections) &#123; vector&lt;vector&lt;pair&lt;int,int&gt;&gt;&gt; edge(n+1); for(auto &amp;c:connections)&#123; int a = c[0], b = c[1]; edge[a].push_back(&#123;b,1&#125;); edge[b].push_back(&#123;a,0&#125;); &#125; int ans = 0; function&lt;void(int,int)&gt; dfs = [&amp;](int u,int fa)&#123; for(auto &amp;[v,type]:edge[u])&#123; if(v==fa) continue; ans += type; dfs(v,u); &#125; &#125;; dfs(0,-1); return ans; &#125;&#125;; 2023-12-08 é¢˜ç›®ä¼ é€é—¨ï¼š2008. å‡ºç§Ÿè½¦çš„æœ€å¤§ç›ˆåˆ© - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä»Šå¤©çš„è¿™é“é¢˜é¦–å…ˆè¯»å®Œé¢˜ç›®åå°±å¯ä»¥çŒœå‡ºåº”è¯¥æ˜¯ä¸€é“DPé¢˜ï¼Œç„¶åæˆ‘ä»¬åœ¨è§‚å¯Ÿæ•°æ®è§„æ¨¡ï¼Œè¡Œç¨‹æ•°é‡æœ€å¤§ä¸º3e4ï¼Œç«™ç‚¹å–å€¼èŒƒå›´ä¸º1e5ã€‚æ‰€ä»¥æˆ‘ä»¬è®¾è®¡çš„DPç®—æ³•çš„æ—¶é—´å¤æ‚åº¦åªèƒ½æ˜¯O(n)O(n)O(n)æˆ–O(nlogn)O(nlogn)O(nlogn) æ–¹æ³•ä¸€ï¼šåŠ¨æ€è§„åˆ’+äºŒåˆ†æŸ¥æ‰¾ å› ä¸ºè¿™é“é¢˜å¯¹é¡ºåºæœ‰ä¸€äº›è¦æ±‚ï¼Œæ‰€ä»¥ä¸éš¾æƒ³åˆ°å¯èƒ½ä¼šä½¿ç”¨æ’åºæˆ–è€…äºŒåˆ†è¿™ç±»ç®—æ³•ã€‚ å½“ç„¶æˆ‘ä»¬è¿˜æ˜¯å…ˆè®¾è®¡dpçŠ¶æ€è½¬ç§»æ–¹ç¨‹ï¼Œæ–¹ç¨‹å¦‚ä¸‹æ‰€ç¤ºï¼š dp[i]=max(dp[iâˆ’1],dp[j]+val[i])dp[i] = max(dp[i-1],dp[j]+val[i]) dp[i]=max(dp[iâˆ’1],dp[j]+val[i]) å…¶ä¸­ç´¢å¼•å·ä»£è¡¨çš„æ˜¯æ¯ä¸ªäººçš„ç¼–å·ï¼ˆé‡æ–°æ’åºè¿‡çš„ï¼Œä¾ç»ˆç‚¹å¤§å°ä»å°åˆ°å¤§è¿›è¡Œæ’åºï¼‰ï¼Œval[i]val[i]val[i]ä»£è¡¨çš„æ˜¯å½“å‰åºå·ä¸ºiçš„äººèƒ½å¤Ÿèµšçš„é’±ã€‚ jjjçš„é€‰æ‹©æ˜¯é‡‡ç”¨äºŒåˆ†æŸ¥è¯¢ç»ˆç‚¹çš„æ–¹æ³•æ‰¾åˆ°æ¯”iiiçš„èµ·ç‚¹å°çš„æœ€å¤§çš„jjjçš„ç»ˆç‚¹ã€‚ï¼ˆå­¦ä¹ äº†upperboundçš„ä¹¦å†™æ–¹æ³•ï¼Œåœ¨C++æ•™ç¨‹åˆé›†ä¸­æœ‰è®°è½½ï¼‰ å› æ­¤è¿™é“é¢˜å°±æ¯”è¾ƒå¥½è§£å†³äº†ï¼š å…ˆæŒ‰ç…§ç»ˆç‚¹ä»å°åˆ°å¤§æ’åº éå†æ‰€æœ‰çš„äººï¼Œéµå¾ªä¸Šé¢çš„è½¬ç§»æ–¹ç¨‹è¿›è¡ŒçŠ¶æ€è½¬ç§» è½¬ç§»çš„è¿‡ç¨‹ä¸­ï¼Œè¿›è¡ŒäºŒåˆ†å¯»æ‰¾j æœ€ç»ˆä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718class Solution &#123;public: long long maxTaxiEarnings(int n, vector&lt;vector&lt;int&gt;&gt;&amp; rides) &#123; sort(rides.begin(),rides.end(), [](const vector&lt;int&gt; &amp;a, const vector&lt;int&gt; &amp;b)&#123; if(a[1]==b[1])return a[0] &lt; b[0]; return a[1] &lt; b[1]; &#125;); int p_num = rides.size(); vector&lt;long long&gt; dp(p_num+1); for(int i=0;i&lt;p_num;++i)&#123; int j = upper_bound(rides.begin(), rides.begin() + i, rides[i][0], [](int x, const vector&lt;int&gt; &amp;r)&#123; return x &lt; r[1]; &#125;) - rides.begin(); dp[i+1] = max(dp[i], dp[j]+rides[i][1]-rides[i][0]+rides[i][2]); &#125; return dp[p_num]; &#125;&#125;; æ–¹æ³•äºŒï¼šåŠ¨æ€è§„åˆ’+å“ˆå¸Œè¡¨ æ–¹æ³•ä¸€å¯èƒ½å­˜åœ¨ä¸ç›´è§‚ï¼ˆdpæ•°ç»„ç´¢å¼•æ˜¯äººï¼‰ä»¥åŠç®—æ³•æ—¶é—´å¤æ‚åº¦ç¨é«˜çš„é—®é¢˜ã€‚æˆ‘ä»¬å…¶å®ä½¿ç”¨åŠ¨æ€è§„åˆ’ç»“åˆå“ˆå¸Œè¡¨çš„æ–¹æ³•å¯ä»¥å°†ç®—æ³•æ—¶é—´å¤æ‚åº¦ä¼˜åŒ–åˆ°O(n)O(n)O(n)å¹¶ä¸”è½¬ç§»æ–¹ç¨‹ä¹Ÿä¼šæ˜¾å¾—æ›´åŠ ç›´è§‚ã€‚ æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå“ˆå¸Œè¡¨rideMap[end]ï¼Œè®°å½•ç»ˆç‚¹ä¸ºendçš„æ‰€æœ‰ä¹˜å®¢ä¿¡æ¯ï¼Œä¸åŒäºä¹‹å‰çš„æ–¹æ³•è¿™é‡Œdp[i]ä»£è¡¨åˆ°è¾¾ç¬¬iiiä¸ªåœ°ç‚¹æ—¶èƒ½è·å¾—çš„æœ€å¤§åˆ©æ¶¦ã€‚å› æ­¤åˆå§‹æƒ…å†µå°±æ˜¯dp[0]=0ã€‚å¯¹äºæ¯ä¸ªåœ°ç‚¹iæœ‰ä¸¤ç§å¯èƒ½çš„è½¬ç§»ï¼š iiiåœ°ç‚¹æ²¡äººä¸‹è½¦ï¼Œåˆ™dp[i]=dp[iâˆ’1]dp[i]=dp[i-1]dp[i]=dp[iâˆ’1] æœ‰äººä¸‹è½¦ï¼Œæœ€å¤§åˆ©æ¶¦ä¸ºdp[i]=max(dp[startj]+end[j]âˆ’start[j]+tip[j])dp[i]=max(dp[start_j]+end[j]-start[j]+tip[j])dp[i]=max(dp[startjâ€‹]+end[j]âˆ’start[j]+tip[j]) ç†è§£å®Œæ•´ä¸ªè¿‡ç¨‹æœ€ç»ˆçš„ä»£ç å°±æ˜¯ï¼š 1234567891011121314151617class Solution &#123;public: long long maxTaxiEarnings(int n, vector&lt;vector&lt;int&gt;&gt;&amp; rides) &#123; vector&lt;long long&gt; dp(n+1); unordered_map&lt;int, vector&lt;vector&lt;int&gt;&gt;&gt; rideMap; for(const auto &amp;ride: rides) &#123; rideMap[ride[1]].push_back(ride); &#125; for(int i = 1; i &lt;= n; ++i)&#123; dp[i] = dp[i-1]; for(const auto &amp;ride : rideMap[i]) &#123; dp[i] = max(dp[i], dp[ride[0]] + ride[1] - ride[0] + ride[2]); &#125; &#125; return dp[n]; &#125;&#125;; 2023-12-09 é¢˜ç›®ä¼ é€é—¨ï¼š2048. ä¸‹ä¸€ä¸ªæ›´å¤§çš„æ•°å€¼å¹³è¡¡æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™ä¸ªé¢˜æ‰“ä¸€ä¸ªè¡¨ï¼Œç”¨ä¸€ä¸ªå¯çˆ±çš„äºŒåˆ†å°±å¯ä»¥è§£å†³ï¼Œï¼ˆäºŒåˆ†ç›´æ¥è°ƒç”¨upper_boundå‡½æ•°ï¼‰ 123456789101112131415161718192021222324class Solution &#123;public: const vector&lt;int&gt; balance &#123; 1, 22, 122, 212, 221, 333, 1333, 3133, 3313, 3331, 4444, 14444, 22333, 23233, 23323, 23332, 32233, 32323, 32332, 33223, 33232, 33322, 41444, 44144, 44414, 44441, 55555, 122333, 123233, 123323, 123332, 132233, 132323, 132332, 133223, 133232, 133322, 155555, 212333, 213233, 213323, 213332, 221333, 223133, 223313, 223331, 224444, 231233, 231323, 231332, 232133, 232313, 232331, 233123, 233132, 233213, 233231, 233312, 233321, 242444, 244244, 244424, 244442, 312233, 312323, 312332, 313223, 313232, 313322, 321233, 321323, 321332, 322133, 322313, 322331, 323123, 323132, 323213, 323231, 323312, 323321, 331223, 331232, 331322, 332123, 332132, 332213, 332231, 332312, 332321, 333122, 333212, 333221, 422444, 424244, 424424, 424442, 442244, 442424, 442442, 444224, 444242, 444422, 515555, 551555, 555155, 555515, 555551, 666666, 1224444 &#125;; int nextBeautifulNumber(int n) &#123; return *upper_bound(balance.begin(), balance.end(), n); &#125;&#125;; 2023-12-10 é¢˜ç›®ä¼ é€é—¨ï¼š70. çˆ¬æ¥¼æ¢¯ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åˆšå¥½å’ŒåŠ¨æ€è§„åˆ’ï¼ˆåŸºç¡€ç‰ˆï¼‰ç¬¬ä¸€é¢˜ä¸€æ ·ï¼Œç›´æ¥æŠ„è¿‡æ¥å³å¯ã€‚ è®°å¿†åŒ–æœç´¢ç‰ˆï¼š 12345678910111213class Solution &#123;public: int climbStairs(int n) &#123; vector&lt;int&gt; dp(n+1,-1); dp[0] = 1;dp[1] = 1; function&lt;int(int)&gt; dfs = [&amp;](int now)&#123; if (dp[now]!=-1) return dp[now]; dp[now-1] = dfs(now-1); dp[now-2] = dfs(now-2); return dp[now-1] + dp[now-2]; &#125;; return dfs(n); &#125;&#125;; é€’æ¨ç‰ˆï¼š 1234567891011class Solution &#123;public: int climbStairs(int n) &#123; vector&lt;int&gt; dp(n+1,0); dp[0] = 1;dp[1] = 1; for(int i=2;i&lt;=n;++i)&#123; dp[i] = dp[i-1]+dp[i-2]; &#125; return dp[n]; &#125;&#125;; 2023-12-11 é¢˜ç›®ä¼ é€é—¨ï¼š1631. æœ€å°ä½“åŠ›æ¶ˆè€—è·¯å¾„ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜æ³¨æ„é¢˜ç›®ä¸è¦è¯»é”™ï¼Œå…¶å®å°±æ˜¯ä¸€é“æœ€çŸ­è·¯æ¿å­é¢˜ï¼Œæ­£å¥½å€ŸåŠ©è¿™ä¸ªæœºä¼šç†Ÿæ‚‰ä¸€ä¸‹Dijkstraçš„C++å†™æ³•ã€‚ æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 123456789101112131415161718192021222324252627282930313233struct DIS &#123; int x, y, val; DIS(int _x,int _y, int _val): x(_x), y(_y), val(_val) &#123;&#125; bool operator&lt; (const DIS&amp; that) const&#123; return that.val &lt; val; &#125;&#125;;class Solution &#123;public: int minimumEffortPath(vector&lt;vector&lt;int&gt;&gt;&amp; heights) &#123; int m = heights.size(), n = heights[0].size(); vector&lt;vector&lt;bool&gt;&gt; vis(m,vector&lt;bool&gt;(n, false)); vector&lt;vector&lt;int&gt;&gt; dis(m, vector&lt;int&gt;(n, INT_MAX)); priority_queue&lt;DIS&gt; q; dis[0][0] = 0; q.emplace(0,0,0); vector&lt;vector&lt;int&gt;&gt; dirs = &#123;&#123;0,1&#125;,&#123;1,0&#125;,&#123;-1,0&#125;,&#123;0,-1&#125;&#125;; while(!q.empty())&#123; auto [x,y,val] = q.top();q.pop(); if (vis[x][y]) continue; vis[x][y] = true; for(auto &amp;dir:dirs)&#123; int nx = x + dir[0], ny = y + dir[1]; if(nx&gt;=0 &amp;&amp; nx&lt;m &amp;&amp; ny&gt;=0 &amp;&amp; ny&lt;n &amp;&amp; dis[nx][ny] &gt; max(dis[x][y],abs(heights[x][y]-heights[nx][ny])))&#123; dis[nx][ny] = max(dis[x][y],abs(heights[x][y]-heights[nx][ny])); q.emplace(nx,ny,dis[nx][ny]); &#125; &#125; &#125; return dis[m-1][n-1]; &#125;&#125;; ä¸Šè¿°ä»£ç ä½¿ç”¨äº†structè¿™å°±ä¸æ˜¯å¾ˆæ­£ç»ŸC++ï¼Œæ‰€ä»¥æˆ‘ä»¬å½“ç„¶ä¹Ÿå¯ä»¥å†™æˆç±»çš„å½¢å¼ï¼š 12345678910111213141516171819202122232425262728293031323334353637class DIS &#123;public: int x, y, val; // é»˜è®¤ä¸ºç§æœ‰æˆå‘˜ // æ„é€ å‡½æ•° DIS(int _x, int _y, int _val) : x(_x), y(_y), val(_val) &#123;&#125; // æ¯”è¾ƒæ“ä½œç¬¦ bool operator&lt; (const DIS&amp; that) const &#123; return that.val &lt; val; &#125;&#125;;class Solution &#123;public: int minimumEffortPath(vector&lt;vector&lt;int&gt;&gt;&amp; heights) &#123; int m = heights.size(), n = heights[0].size(); vector&lt;vector&lt;bool&gt;&gt; vis(m,vector&lt;bool&gt;(n, false)); vector&lt;vector&lt;int&gt;&gt; dis(m, vector&lt;int&gt;(n, INT_MAX)); priority_queue&lt;DIS&gt; q; dis[0][0] = 0; q.emplace(0,0,0); vector&lt;vector&lt;int&gt;&gt; dirs = &#123;&#123;0,1&#125;,&#123;1,0&#125;,&#123;-1,0&#125;,&#123;0,-1&#125;&#125;; while(!q.empty())&#123; auto [x,y,val] = q.top();q.pop(); if (vis[x][y]) continue; vis[x][y] = true; for(auto &amp;dir:dirs)&#123; int nx = x + dir[0], ny = y + dir[1]; if(nx&gt;=0 &amp;&amp; nx&lt;m &amp;&amp; ny&gt;=0 &amp;&amp; ny&lt;n &amp;&amp; dis[nx][ny] &gt; max(dis[x][y],abs(heights[x][y]-heights[nx][ny])))&#123; dis[nx][ny] = max(dis[x][y],abs(heights[x][y]-heights[nx][ny])); q.emplace(nx,ny,dis[nx][ny]); &#125; &#125; &#125; return dis[m-1][n-1]; &#125;&#125;; å½“ç„¶ä¸å‡ºæ„å¤–ï¼Œ è¿˜æ˜¯structçš„æ•ˆç‡ä¼šé«˜ä¸€äº›ï¼Œä¹Ÿå»ºè®®ä»¥åéƒ½å†™æˆstructï¼Œåœ¨é‡Œé¢é‡å®šä¹‰å°äºè¿ç®—ç¬¦ã€‚ å…¶ä»–æ³¨æ„äº‹é¡¹ autoå–topä¸­çš„ç»“æ„ä½“å€¼ 1auto [x,y,val] = q.top();q.pop(); é‡å®šä¹‰è¿ç®—ç¬¦ä¸¤ä¸ªconstéƒ½ä¸èƒ½çœç•¥ 123bool operator&lt; (const DIS&amp; that) const &#123;\treturn that.val &lt; val;&#125; intç±»å‹çš„æœ€å¤§å€¼å¯ä»¥ç›´æ¥å†™INT_MAX 2023-12-12â€» é¢˜ç›®ä¼ é€é—¨ï¼š2454. ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´  IV - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æ­¤é¢˜éœ€è¦ç”¨åˆ°å•è°ƒæ ˆçš„ç›¸å…³å†…å®¹,å•è°ƒæ ˆåŸºç¡€è¯¦æƒ…è§ä¸“é¡¹è®­ç»ƒå•è°ƒæ ˆæ¨¡å—ã€‚ ä»¥ä¸‹å†…å®¹æ‘˜è‡ªçµç¥é¢˜è§£ï¼š é¦–å…ˆå›æƒ³ä¸€ä¸‹ï¼Œæ€ä¹ˆæ‰¾ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´ ï¼Œå³å³ä¾§æœ€è¿‘çš„æ›´å¤§å…ƒç´ ã€‚ ä½¿ç”¨è§†é¢‘ä¸­è®²çš„ç¬¬äºŒç§åšæ³•ï¼Œä»å·¦åˆ°å³éå†æ•°ç»„ï¼Œç”¨ä¸€ä¸ªï¼ˆé€’å‡ï¼‰å•è°ƒæ ˆsssç»´æŠ¤éå†è¿‡çš„å…ƒç´ ï¼Œå¦‚æœå½“å‰å…ƒç´  xxx æ¯”æ ˆé¡¶å¤§ï¼Œé‚£ä¹ˆæ ˆé¡¶çš„ä¸‹ä¸€ä¸ªæ›´å¤§å…ƒç´ å°±æ˜¯ xxxï¼Œå¹¶å¼¹å‡ºæ ˆé¡¶ã€‚ åœ¨è¿™ä¸ªåšæ³•ä¸­ï¼Œæ ˆé¡¶å…ƒç´ å¼¹å‡ºåï¼Œå°±æ²¡æœ‰ç”¨äº†ã€‚ä½†å¯¹äºæœ¬é¢˜ï¼Œæˆ‘ä»¬éœ€è¦çš„æ­£æ˜¯å¼¹å‡ºå»çš„å…ƒç´ ï¼ å†ç”¨ä¸€ä¸ªï¼ˆé€’å‡ï¼‰å•è°ƒæ ˆ ttt è®°å½•ä» sss ä¸­å¼¹å‡ºå»çš„å…ƒç´ ã€‚ç»§ç»­å‘åéå†ï¼Œå¦‚æœåˆæ‰¾åˆ°ä¸€ä¸ªå…ƒç´  yyy æ¯” ttt çš„æ ˆé¡¶å¤§ï¼Œé‚£ä¹ˆæ ˆé¡¶çš„ä¸‹ä¸‹ä¸ªæ›´å¤§å…ƒç´ å°±æ˜¯ yyyï¼Œå¹¶å¼¹å‡ºæ ˆé¡¶ã€‚ 1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; secondGreaterElement(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; ans(n, -1), s, t; for (int i = 0; i &lt; n; ++i) &#123; int x = nums[i]; while (!t.empty() &amp;&amp; nums[t.back()] &lt; x)&#123; ans[t.back()] = x; t.pop_back(); &#125; int j = s.size(); while(j &amp;&amp; nums[s[j-1]] &lt; x) j--; t.insert(t.end(), s.begin() + j, s.end()); // æŠŠä» s å¼¹å‡ºçš„è¿™ä¸€æ•´æ®µå…ƒç´ åŠ åˆ° t s.resize(j); // å¼¹å‡ºä¸€æ•´æ®µå…ƒç´  s.push_back(i); // å½“å‰å…ƒç´ ï¼ˆçš„ä¸‹æ ‡ï¼‰åŠ åˆ° s æ ˆé¡¶ &#125; return ans; &#125;&#125;; 2023-12-13 é¢˜ç›®ä¼ é€é—¨ï¼š2697. å­—å…¸åºæœ€å°å›æ–‡ä¸² - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åŒæŒ‡é’ˆç­¾åˆ°é¢˜ç›®ï¼Œä¸¤ä¸ªæŒ‡é’ˆåˆ†åˆ«æŒ‡å‘å­—ç¬¦ä¸²å¤´å°¾ï¼Œæ ‡è®°çš„æ˜¯å›æ–‡ä¸²ç›¸å¯¹åº”çš„ä½ç½®ï¼Œéå†çš„è¿‡ç¨‹ä¸­ï¼Œleftæ¯å‘å³ç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œrightå°±å‘å·¦ç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œè¿™æ ·ä¼šå‡ºç°ä¸¤ç§æƒ…å†µã€‚ å¦‚æœæŒ‡å‘çš„å­—ç¬¦ä¸€æ ·ï¼Œä¸åšä»»ä½•æ“ä½œ å¦‚æœæŒ‡å‘çš„å­—æ¯ä¸åŒï¼Œå°†ä»–ä»¬éƒ½å˜æˆè¿™ä¸¤ä¸ªå­æ¯ä¸­è¾ƒå°çš„é‚£ä¸ªå­—æ¯å³å¯ã€‚ æœ€åè¿”å›æ–°çš„å­—ç¬¦ä¸²ã€‚ æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 12345678910111213class Solution &#123;public: string makeSmallestPalindrome(string s) &#123; int n = s.length(); for(int i=0;i&lt;n/2;++i)&#123; if (s[i]!=s[n-1-i])&#123; if (s[i] &lt; s[n-1-i]) s[n-1-i] =s[i]; else s[i] = s[n-1-i]; &#125; &#125; return s; &#125;&#125;; 2023-12-14 ä»Šå¤©çš„è¿™é“é¢˜éå¸¸çš„æœ‰æ„æ€ï¼Œè¯»å®Œé¢˜ç›®åï¼Œå¤§æ¦‚å°±ä¼šæœ‰ä¸€ä¸ªåŸºæœ¬æ€è·¯ï¼Œå°±æ˜¯èƒ½æ”¾ä¸Šé‚®ç¥¨çš„åœ°æ–¹æˆ‘ä»¬å°½é‡æ”¾ä¸Šé‚®ç¥¨ï¼Œæœ€åæˆ‘ä»¬çœ‹æ•´ä¸ªçŸ©é˜µæœ‰æ²¡æœ‰ç©ºç™½çš„åœ°æ–¹ã€‚ å€Ÿç”¨çµç¥çš„æ€è·¯æ¦‚æ‹¬ä¸€ä¸‹ï¼š ç”±äºé‚®ç¥¨å¯ä»¥äº’ç›¸é‡å ï¼Œè´ªå¿ƒåœ°æƒ³ï¼Œèƒ½æ”¾é‚®ç¥¨å°±æ”¾é‚®ç¥¨ã€‚ éå†æ‰€æœ‰èƒ½æ”¾é‚®ç¥¨çš„ä½ç½®å»æ”¾é‚®ç¥¨ã€‚æ³¨æ„é‚®ç¥¨ä¸èƒ½è¦†ç›–è¢«å æ®çš„æ ¼å­ï¼Œä¹Ÿä¸èƒ½å‡ºç•Œã€‚ æ”¾é‚®ç¥¨çš„åŒæ—¶ï¼Œè®°å½•æ¯ä¸ªç©ºæ ¼å­è¢«å¤šå°‘å¼ é‚®ç¥¨è¦†ç›–ã€‚å¦‚æœå­˜åœ¨ä¸€ä¸ªç©ºæ ¼å­æ²¡è¢«é‚®ç¥¨è¦†ç›–ï¼Œåˆ™è¿”å› falseï¼Œå¦åˆ™è¿”å› trueã€‚ å…¶å®æŠŠä¸Šé¢çš„å¤§ä½“æ€è·¯æƒ³æ˜ç™½äº†ï¼Œæ ¹æ®ä¹‹å‰çš„åšé¢˜ç»éªŒï¼Œè¿™é“é¢˜ä½¿ç”¨å·®åˆ†ä¹Ÿæ¯”è¾ƒæ˜æ˜¾äº†ï¼Œå°±æ˜¯è¿˜æœ‰ä¸€äº›ç»†èŠ‚éœ€è¦æ³¨æ„ä¸€ä¸‹ã€‚ å› ä¸ºè¦ä½¿ç”¨å·®åˆ†ï¼Œæ‰€ä»¥æˆ‘ä»¬æ”¾é‚®ç¥¨ä»å³ä¸‹è§’å¼€å§‹æ”¾ï¼Œè¿™æ ·å¥½ä½¿ç”¨å·®åˆ†O(1)O(1)O(1)åˆ¤æ–­èƒ½å¦å°†é‚®ç¥¨æ”¾åœ¨è¿™é‡Œã€‚ æ”¾é‚®ç¥¨æˆ‘ä»¬ä¹Ÿæ˜¯é‡‡ç”¨ä¸€ä¸ªå·®åˆ†çŸ©é˜µæ¥è®°å½•ï¼Œæœ€åæ±‚äºŒç»´å‰ç¼€å’Œå°±å¯ä»¥è¿˜åŸæœ€ç»ˆçš„é‚®ç¥¨æ”¾ç½®æ–¹æ³•ã€‚ æ³¨æ„ï¼šä»¥åå†™è¿™ç§å·®åˆ†çš„é¢˜ç›®ï¼Œä¸‹æ ‡ä»£è¡¨çš„éƒ½æ˜¯ä»1å¼€å§‹ï¼Œå› ä¸ºå¿…é¡»è¦ç•™ä¸€ä¸ª0ä¿è¯æ±‚å‰ç¼€å’Œè¿™ç±»æ“ä½œçš„ç»Ÿä¸€æ€§ã€‚ æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: bool possibleToStamp(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int stampHeight, int stampWidth) &#123; int n = grid.size(), m = grid[0].size(); vector&lt;vector&lt;int&gt;&gt; s(n+1,vector&lt;int&gt;(m+1,0)); for (int i=0; i&lt;n; ++i) &#123; for(int j=0; j&lt;m; ++j)&#123; s[i+1][j+1] = grid[i][j] + s[i][j+1] + s[i+1][j] - s[i][j]; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; cov(n+2,vector&lt;int&gt;(m+2,0)); for (int i=stampHeight; i&lt;=n; ++i) &#123; for(int j=stampWidth; j&lt;=m; ++j)&#123; int i1 = i - stampHeight + 1; int j1 = j - stampWidth + 1; if (s[i][j] - s[i][j1-1] - s[i1-1][j] + s[i1-1][j1-1] == 0)&#123; cov[i1][j1] ++; cov[i+1][j1] -- ; cov[i1][j+1] --; cov[i+1][j+1] ++; &#125; &#125; &#125; for(int i=1;i&lt;=n;++i)&#123; for(int j=1;j&lt;=m;++j)&#123; cov[i][j] += cov[i-1][j] + cov[i][j-1] - cov[i-1][j-1]; if (grid[i-1][j-1] == 0 &amp;&amp; cov[i][j] == 0) return false; &#125; &#125; return true; &#125;&#125;; 2023-12-15 é¢˜ç›®ä¼ é€é—¨ï¼š2415. åè½¬äºŒå‰æ ‘çš„å¥‡æ•°å±‚ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æ­¤é¢˜è€ƒå¯Ÿçš„æ˜¯äºŒå‰æ ‘çš„å±‚åºéå†ï¼Œå…¶å®å°±æ˜¯ä¸€ç§bfså§ï¼Œé€šè¿‡æœ¬é¢˜å¯ä»¥æ›´ç†Ÿæ‚‰ä¸€ä¸‹C++ä¸­æŒ‡é’ˆå’Œvectorç›¸å…³å†…å®¹ã€‚ æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 123456789101112131415161718192021222324252627282930313233343536/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode() : val(0), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x) : val(x), left(nullptr), right(nullptr) &#123;&#125; * TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* reverseOddLevels(TreeNode* root) &#123; vector&lt;vector&lt;TreeNode*&gt;&gt; que(2); que[0].push_back(root); int now = 0; while (!que[now].empty())&#123; for(auto node:que[now])&#123; if(node-&gt;left) que[1-now].push_back(node-&gt;left); if(node-&gt;right) que[1-now].push_back(node-&gt;right); &#125; if (now) &#123; int siz = que[now].size(); for(int i=0;i&lt;siz/2;++i)&#123; int tmp = que[now][i]-&gt;val; que[now][i]-&gt;val = que[now][siz-1-i]-&gt;val; que[now][siz-1-i]-&gt;val = tmp; &#125; &#125; while(!que[now].empty()) que[now].pop_back(); now = 1-now; &#125; return root; &#125;&#125;; 2023-12-16 é¢˜ç›®ä¼ é€é—¨ï¼š2276. ç»Ÿè®¡åŒºé—´ä¸­çš„æ•´æ•°æ•°ç›® - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿˜æ²¡å¤ªæ•´æ˜ç™½ï¼š 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; secondGreaterElement(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); vector&lt;int&gt; ans(n, -1), s, t; for (int i = 0; i &lt; n; ++i) &#123; int x = nums[i]; while (!t.empty() &amp;&amp; nums[t.back()] &lt; x)&#123; ans[t.back()] = x; t.pop_back(); &#125; int j = s.size(); while(j &amp;&amp; nums[s[j-1]] &lt; x) j--; t.insert(t.end(), s.begin() + j, s.end()); // æŠŠä» s å¼¹å‡ºçš„è¿™ä¸€æ•´æ®µå…ƒç´ åŠ åˆ° t s.resize(j); // å¼¹å‡ºä¸€æ•´æ®µå…ƒç´  s.push_back(i); // å½“å‰å…ƒç´ ï¼ˆçš„ä¸‹æ ‡ï¼‰åŠ åˆ° s æ ˆé¡¶ &#125; return ans; &#125;&#125;; 2023-12-17 é¢˜ç›®ä¼ é€é—¨ï¼š746. ä½¿ç”¨æœ€å°èŠ±è´¹çˆ¬æ¥¼æ¢¯ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸åŸºç¡€çš„DPé¢˜ç›®ï¼Œè¿™é‡Œå°±ä½¿ç”¨è®°å¿†åŒ–æœç´¢è§£å†³äº†ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯costæœ€åå‹å…¥ä¸€ä¸ª0ï¼Œæ¥ä¿è¯æ‰€æœ‰çš„æ“ä½œä¸€è‡´æ€§ï¼ˆä»£è¡¨å·²ç»åˆ°æœ€é«˜ç‚¹äº†ï¼Œå¾€ä¸Šèµ°çš„å¼€é”€ä¸º0ï¼‰ 12345678910111213141516class Solution &#123;public: int minCostClimbingStairs(vector&lt;int&gt;&amp; cost) &#123; int n = cost.size(); cost.emplace_back(0); vector&lt;int&gt; dp(n+1, -1); dp[0] = cost[0]; dp[1] = cost[1]; function&lt;int(int)&gt; dfs = [&amp;](int now)&#123; if (dp[now]!=-1) return dp[now]; int a = dfs(now-1), b = dfs(now-2); dp[now] = cost[now] + min(a,b); return dp[now]; &#125;; return dfs(n); &#125;&#125;; 2023-12-18 é¢˜ç›®ä¼ é€é—¨ï¼š162. å¯»æ‰¾å³°å€¼ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å› ä¸ºé¢˜ç›®è¦æ±‚å®ç°O(logâ¡n)O(\\log n)O(logn)æ—¶é—´å¤æ‚åº¦çš„ç®—æ³•ï¼Œæ‰€ä»¥ä¸éš¾æƒ³åˆ°éœ€è¦ä½¿ç”¨äºŒåˆ†ç®—æ³•ï¼ŒäºŒåˆ†çš„åŸºç¡€çŸ¥è¯†æˆ‘ä»¬å·²ç»åœ¨äºŒåˆ†ä¸“é¢˜æ¿å—è¿›è¡Œäº†è®²è§£ã€‚ æœ¬é¢˜äºŒåˆ†çš„æ€æƒ³å…¶å®å¾ˆç®€å•ï¼Œæˆ‘ä»¬éœ€è¦æ˜ç™½ä¸€ä¸ªé“ç†ï¼Œå°±æ˜¯å³°å€¼ä¸€å®šæ˜¯æ¯”è¾ƒå¤§çš„å€¼ï¼Œæ‰€ä»¥æ¯æ¬¡äºŒåˆ†çš„æ—¶å€™åˆ¤æ–­å½“å‰midä½ç½®ä¸ä»–å·¦å³ä½ç½®æ•°çš„å¤§å°å…³ç³»ï¼Œç„¶åå¾€å¤§çš„åœ°æ–¹æ›´æ–°åŒºé—´å³å¯ã€‚ ä»£ç å¦‚ä¸‹ï¼š 123456789101112131415161718class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; int len = nums.size(); int l = 0, r = len-1; function&lt;long long(int)&gt; getitem = [&amp;](int i)&#123; if (i&lt;=-1||i&gt;=len) return 2*(long long)(INT_MIN); return (long long)(nums[i]); &#125;; while (l &lt;= r) &#123; int mid = l + (r-l)/2; if (getitem(mid)&gt;getitem(mid-1)&amp;&amp;getitem(mid)&gt;getitem(mid+1)) return mid; if (getitem(mid)&lt;getitem(mid+1)) l = mid+1; else r = mid-1; &#125; return -123123; &#125;&#125;; è¿™é‡Œä½¿ç”¨çš„æ˜¯é—­åŒºé—´äºŒåˆ†ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯0ä½ç½®çš„å·¦è¾¹ä»¥åŠlen-1ä½ç½®çš„å³è¾¹å®šä¹‰çš„å³°å€¼å¤§å°éƒ½æ˜¯2*INT_MIN,ä½¿ç”¨ä¸€ä¸ªgetitemå‡½æ•°æ¥å–å€¼ï¼Œå…¶ä¸­éœ€è¦è€ƒè™‘è¿™ç§è¶…å‡ºåŒºé—´èŒƒå›´çš„é—®é¢˜ã€‚ å…¶å®ä¸Šé¢çš„è¿™ç§å†™æ³•å¹¶ä¸æ˜¯å¾ˆäºŒåˆ†ï¼Œå¯ä»¥å†æ”¹è¿›ä¸€ä¸‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼ˆå› ä¸ºæœ€åä¸€å®šæœ‰å³°é¡¶ï¼Œæ‰€ä»¥ç›´æ¥åˆ†ä¸ºä¸å¯èƒ½ä¸ºå³°é¡¶å’Œå¯èƒ½ä¸ºå³°é¡¶ä¸¤ç±»å°±å¯ä»¥åˆ¤æ–­å‡ºæ¥è°æ˜¯å³°é¡¶äº†ï¼‰ï¼š 123456789101112131415161718class Solution &#123;public: int findPeakElement(vector&lt;int&gt;&amp; nums) &#123; int len = nums.size(); int l = 0, r = len-1; function&lt;long long(int)&gt; getitem = [&amp;](int i)&#123; if (i&lt;=-1||i&gt;=len) return 2*(long long)(INT_MIN); return (long long)(nums[i]); &#125;; while (l &lt;= r) &#123; int mid = l + (r-l)/2; // if (getitem(mid)&gt;getitem(mid-1)&amp;&amp;getitem(mid)&gt;getitem(mid+1)) return mid; if (getitem(mid)&lt;getitem(mid+1)) l = mid+1; else r = mid-1; &#125; return l; &#125;&#125;; å¯ä»¥ä»”ç»†ç†è§£ä¸€ä¸‹ä¸ºå•¥æŠŠä¸­é—´é‚£ä¸ªifæ³¨é‡Šæ‰ã€‚ æœ€åè¿”å›lllæ˜¯å› ä¸ºmidè¿˜æ˜¯æœ‰å¯èƒ½æ˜¯å³°é¡¶çš„ï¼Œæ‰€ä»¥åº”è¯¥è¿”å›r+1r+1r+1ï¼Œåˆå› ä¸ºæœ€åç»ˆæ­¢çš„æ—¶å€™r+1=lr+1=lr+1=lï¼Œæ‰€ä»¥è¿”å›lll 2023-12-19 é¢˜ç›®ä¼ é€é—¨ï¼š1901. å¯»æ‰¾å³°å€¼ II - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ åŒæ ·ä¹Ÿæ˜¯äºŒåˆ†ï¼Œåªä¸è¿‡æ˜¯å¯¹æ¯è¡Œçš„æœ€å¤§å€¼è¿›è¡ŒäºŒåˆ†ï¼Œå¾€midå‰åè¡Œæ›´å¤§çš„æœ€å¤§å€¼çš„åœ°æ–¹æ›´æ–°åŒºé—´ã€‚æœ€ç»ˆä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š 123456789101112131415161718class Solution &#123;public: int max_idx(vector&lt;int&gt; nums)&#123; return max_element(nums.begin(), nums.end()) - nums.begin(); &#125; vector&lt;int&gt; findPeakGrid(vector&lt;vector&lt;int&gt;&gt;&amp; mat) &#123; int n = mat.size(); int l = 0, r = n-1; while(l&lt;r)&#123; int mid = l + (r-l)/2; int j = max_idx(mat[mid]); if (mat[mid][j] &gt; mat[mid+1][j]) r = mid; else l = mid+1; &#125; int ans = l; return vector&lt;int&gt;&#123;ans,max_idx(mat[ans])&#125;; &#125;&#125;; 2023-12-20 é¢˜ç›®ä¼ é€é—¨ï¼š2828. åˆ¤åˆ«é¦–å­—æ¯ç¼©ç•¥è¯ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ç­¾åˆ°é¢˜ï¼Œç†Ÿæ‚‰stringçš„åŸºæœ¬ç”¨æ³• 12345678910class Solution &#123;public: bool isAcronym(vector&lt;string&gt;&amp; words, string s) &#123; if(words.size()!=s.size()) return false; for(int i=0;i&lt;words.size();++i)&#123; if (words[i][0]!=s[i]) return false; &#125; return true; &#125;&#125;; 2023-12-21 é¢˜ç›®ä¼ é€é—¨ï¼š2866. ç¾ä¸½å¡” II - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ 2023-12-22 é¢˜ç›®ä¼ é€é—¨ï¼š1671. å¾—åˆ°å±±å½¢æ•°ç»„çš„æœ€å°‘åˆ é™¤æ¬¡æ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ 2023-12-23 é¢˜ç›®ä¼ é€é—¨ï¼š1962. ç§»é™¤çŸ³å­ä½¿æ€»æ•°æœ€å° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸å®¹æ˜“æƒ³çš„è´ªå¿ƒé¢˜ç›®ï¼Œæ¯æ¬¡å–æœ€å¤§å‡åŠå³å¯ã€‚ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—ç»´æŠ¤æœ€å¤§å€¼ã€‚ 12345678910111213141516171819class Solution &#123;public: int minStoneSum(vector&lt;int&gt;&amp; piles, int k) &#123; priority_queue&lt;int&gt; pq; int sum_pile = 0; for(auto &amp;pile:piles) &#123; pq.emplace(pile); sum_pile += pile; &#125; int ans = 0; for(int i=1;i&lt;=k;++i)&#123; int nw = pq.top(); ans += nw/2; pq.pop(); pq.emplace(nw-(nw/2)); &#125; return sum_pile - ans; &#125;&#125;; 2023-12-24 é¢˜ç›®ä¼ é€é—¨ï¼š1954. æ”¶é›†è¶³å¤Ÿè‹¹æœçš„æœ€å°èŠ±å›­å‘¨é•¿ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸æ˜æ˜¾çš„äºŒåˆ†é¢˜ç›®ï¼Œå°†ç»™å®šxè‹¹æœæ€»æ•°è®¡ç®—å…¬å¼æ¨å‡ºå³å¯ï¼Œä½¿ç”¨å·¦é—­å³å¼€äºŒåˆ†æŸ¥æ‰¾ï¼š 12345678910111213141516class Solution &#123;public: long long minimumPerimeter(long long neededApples) &#123; function&lt;long long(long long)&gt; getApple = [&amp;](long long x)&#123; return (x*2+1)*x*(x+1)*2; &#125;; long long l = 0, r = 100000; while(l&lt;r) &#123; long long mid = l + (r-l)/2; long long nwapple = getApple(mid); if (nwapple &gt;= neededApples) r=mid; else l=mid+1; &#125; return l*8; &#125;&#125;; 2023-12-25 é¢˜ç›®ä¼ é€é—¨ï¼š1276. ä¸æµªè´¹åŸæ–™çš„æ±‰å ¡åˆ¶ä½œæ–¹æ¡ˆ - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ å†æ¬¡å¤ä¹ ä¸€ä¸‹äºŒåˆ†é—­åŒºé—´å†™æ³•ã€‚ 12345678910111213141516class Solution &#123;public: vector&lt;int&gt; numOfBurgers(int tomatoSlices, int cheeseSlices) &#123; function&lt;bool(int)&gt; search = [&amp;](int x)&#123; return x*4+(cheeseSlices-x) * 2 &gt;=tomatoSlices?true:false; &#125;; int l = 0, r = cheeseSlices; while(l &lt;= r)&#123; int mid = l+(r-l)/2; if (search(mid)) r = mid-1; else l = mid+1; &#125; return l*4+(cheeseSlices-l)*2 == tomatoSlices?vector&lt;int&gt;&#123;l,cheeseSlices-l&#125;:vector&lt;int&gt;&#123;&#125;; &#125;&#125;; 2023-12-26 é¢˜ç›®ä¼ é€é—¨ï¼š1349. å‚åŠ è€ƒè¯•çš„æœ€å¤§å­¦ç”Ÿæ•° - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ 2023-12-27 é¢˜ç›®ä¼ é€é—¨ï¼š2660. ä¿é¾„çƒæ¸¸æˆçš„è·èƒœè€… - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸€é“éå¸¸ç®€å•çš„ç­¾åˆ°é¢˜ç›®ï¼š 12345678910111213141516class Solution &#123;public: int isWinner(vector&lt;int&gt;&amp; player1, vector&lt;int&gt;&amp; player2) &#123; int n = player1.size(); int p1_sum = player1[0], p2_sum = player2[0]; for(int i=1;i&lt;n;++i)&#123; if (player1[i-1]==10) p1_sum += player1[i]*2; else if (i&gt;1&amp;&amp;player1[i-2]==10) p1_sum += player1[i]*2; else p1_sum += player1[i]; if (player2[i-1]==10) p2_sum += player2[i]*2; else if (i&gt;1&amp;&amp;player2[i-2]==10) p2_sum += player2[i]*2; else p2_sum += player2[i]; &#125; return p1_sum == p2_sum?0:p1_sum&gt;p2_sum?1:2; &#125;&#125;; 2023-12-28 é¢˜ç›®ä¼ é€é—¨ï¼š2735. æ”¶é›†å·§å…‹åŠ› - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ è¿™é“é¢˜é¢˜ç›®æè¿°æœ‰ç‚¹æ­§ä¹‰ï¼Œéœ€è¦ç»“åˆæ ·ä¾‹ç†è§£é¢˜ç›®æ„æ€ï¼Œä½†æ˜¯è¿˜æ˜¯ä¸€é“æœ‰ç‚¹æœ‰æ„æ€çš„æšä¸¾ã€‚ ç†è§£æ¸…æ¥šé¢˜æ„åæˆ‘ä»¬ä¸éš¾å‘ç°ï¼Œæ“ä½œçš„æ¬¡æ•°æ˜¯æœ‰é™çš„ï¼Œæœ€å¤šæ˜¯ç­‰äºç§ç±»æ•°-1ï¼Œç„¶åæˆ‘ä»¬è§‚å¯Ÿæ•°æ®èŒƒå›´&lt;1000ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥é‡‡ç”¨æšä¸¾æ“ä½œæ•°çš„æ–¹å¼è§£å†³è¿™é“é¢˜ç›®ï¼Œä»£ç å¦‚ä¸‹ï¼š 1234567891011121314151617class Solution &#123;public: long long minCost(vector&lt;int&gt;&amp; nums, int x) &#123; int len = nums.size(); vector&lt;int&gt;min_nw = nums; long long ans = 1000000000004; for(int i=0;i&lt;len;++i)&#123; long long tmp = (long long)i*x; for(int j=0;j&lt;len;++j)&#123; min_nw[j] = min(min_nw[j],nums[(j+i)%len]); tmp += min_nw[j]; &#125; ans = min(ans,tmp); &#125; return ans; &#125;&#125;; 2023-12-29 é¢˜ç›®ä¼ é€é—¨ï¼š2706. è´­ä¹°ä¸¤å—å·§å…‹åŠ› - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ç­¾åˆ°é¢˜ï¼Œä»£ç å¦‚ä¸‹ï¼š 12345678class Solution &#123;public: int buyChoco(vector&lt;int&gt;&amp; prices, int money) &#123; sort(prices.begin(),prices.end()); int cost = prices[0] + prices[1]; return cost &gt; money?money:money-cost; &#125;&#125;; 2023-12-30 é¢˜ç›®ä¼ é€é—¨ï¼š1185. ä¸€å‘¨ä¸­çš„ç¬¬å‡ å¤© - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ æ¨¡æ‹Ÿé¢˜ï¼Œæ³¨æ„åˆ¤æ–­é—°å¹´ä»¥åŠé—°å¹´äºŒæœˆä»½çš„æ—¶å€™å³å¯ã€‚ 12345678910111213141516171819202122class Solution &#123;public: string dayOfTheWeek(int day, int month, int year) &#123; auto judge_year = [&amp;](int x)&#123; if(x % 400 == 0 || (x % 4 == 0 &amp;&amp; x % 100 != 0)) return true; return false; &#125;; vector&lt;string&gt; weekDay = &#123;&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;&#125;; vector&lt;int&gt; monthDay = &#123;31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31&#125;; int ans = day; // cal_year int del_year = year-1971; ans += (year-1971)*365; for(int i=1971;i&lt;year;++i)&#123; if (judge_year(i)) ans++; &#125; for(int i=1;i&lt;month;++i) ans += monthDay[i-1]; ans = (month&gt;2&amp;&amp;judge_year(year))?ans+1:ans; int week_day = (4+ans)%7; return weekDay[week_day]; &#125;&#125;; æ³¨æ„ä¸Šä¸€é¢˜Sundayå­˜çš„ä¸‹æ ‡ä¸º0ï¼Œå› ä¸ºè¿™æ ·å¤„ç†æ–¹ä¾¿ä¸€äº›ã€‚ 2023-12-31 é¢˜ç›®ä¼ é€é—¨ï¼š1154. ä¸€å¹´ä¸­çš„ç¬¬å‡ å¤© - åŠ›æ‰£ï¼ˆLeetCodeï¼‰ ä¸Šä¸€é“é¢˜çš„ç®€å•ç‰ˆã€‚ 12345678910111213141516171819class Solution &#123;public: int dayOfYear(string date) &#123; int year = stoi(date.substr(0, 4)); int month = stoi(date.substr(5, 2)); int day = stoi(date.substr(8, 2)); auto judge_year = [&amp;](int x) &#123; if (x%400==0||(x%4==0&amp;&amp;x%100!=0)) return true; return false; &#125;; vector&lt;int&gt; months = &#123;31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31&#125;; int ans = day; for (int i=1;i&lt;month;++i) &#123; ans += months[i-1]; &#125; return (month&gt;2&amp;&amp;judge_year(year))?ans+1:ans; &#125;&#125;;"}]